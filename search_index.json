[["index.html", "Kaggle数据项目实战 优雅的 Bookdown 书籍模版 简介 0.1 已有 Block 0.2 数学公式 0.3 自定义 block", " Kaggle数据项目实战 优雅的 Bookdown 书籍模版 黄湘云 &amp; 叶 飞 2022-04-12 简介 Kaggle成立于2010年，是一个进行数据发掘和预测竞赛的在线平台。从公司的角度来讲，可以提供一些数据，进而提出一个实际需要解决的问题；从参赛者的角度来讲，他们将组队参与项目，针对其中一个问题提出解决方案，最终由公司选出的最佳方案可以获得5K-10K美金的奖金。 除此之外，Kaggle官方每年还会举办一次大规模的竞赛，奖金高达一百万美金，吸引了广大的数据科学爱好者参与其中。从某种角度来讲，大家可以把它理解为一个众包平台，类似国内的猪八戒。但是不同于传统的低层次劳动力需求，Kaggle一直致力于解决业界难题，因此也创造了一种全新的劳动力市场——不再以学历和工作经验作为唯一的人才评判标准，而是着眼于个人技能，为顶尖人才和公司之间搭建了一座桥梁。 0.1 已有 Block 引理 0.1 For any two random variables \\(X_1\\), \\(X_2\\), they both have the same probability distribution if and only if \\[\\varphi _{X_1}(t)=\\varphi _{X_2}(t)\\] 定理 0.1 If \\(X_1\\), …, \\(X_n\\) are independent random variables, and \\(a_1\\), …, \\(a_n\\) are some constants, then the characteristic function of the linear combination \\(S_n=\\sum_{i=1}^na_iX_i\\) is \\[\\varphi _{S_{n}}(t)=\\prod_{i=1}^n\\varphi _{X_i}(a_{i}t)=\\varphi _{X_{1}}(a_{1}t)\\cdots \\varphi _{X_{n}}(a_{n}t)\\] 命题 0.1 The distribution of the sum of independent Poisson random variables \\(X_i \\sim \\mathrm{Pois}(\\lambda_i),\\: i=1,2,\\cdots,n\\) is \\(\\mathrm{Pois}(\\sum_{i=1}^n\\lambda_i)\\). 0.2 数学公式 数学公式加粗可能是最常见的需求之一， elegantbook 宏包提供的文类 elegantbook.cls 已经调用了 bm 宏包 1。有了 bm 宏包，就可以使用 bm 宏包提供的 \\bm{} 命令，而不需要调 \\boldsymbol{} 加粗希腊字母，如将 \\(\\alpha\\) （正常）加粗为 \\(\\bm{\\alpha}\\)（粗体）。为了在 HTML 网页中显示加粗效果，则还不够，默认情况下， MathJax 是不认识 \\bm{} 命令的，所以需要在 header.html 自定义 \\bm{} 命令： &lt;script type=&quot;text/x-mathjax-config&quot;&gt; MathJax.Hub.Config({ TeX: { Macros: { bm: [&quot;{\\\\boldsymbol #1}&quot;,1], } } }); &lt;/script&gt; 进一步地，使用常用的 3 个取消符号 \\(\\bcancel{///}\\) 需要在 header.html 添加 JS 库 cancel.js， &lt;script type=&quot;text/x-mathjax-config&quot;&gt; MathJax.Hub.Config({ TeX: { Macros: { bm: [&quot;{\\\\boldsymbol #1}&quot;,1], }, extensions: [&quot;cancel.js&quot;] } }); &lt;/script&gt; 并在 preamble.tex 文件中添加一行代码加载 cancel 宏包 \\usepackage[makeroom]{cancel} 0.3 自定义 block 基于 Pandoc 自定义 block 是一件很有意思的事情，目前不想让模版过于复杂，仅给出几个最常用的例子。如何自定义可以去看谢益辉的新书 https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html。 要做的还有很多 这是警告 这是提示 这是注意 普通说明 https://github.com/ElegantLaTeX/ElegantBook/blob/6ab10beda81252f0b478e05fa926199301347e4a/elegantbook.cls#L884↩︎ "],["1-vgsales.html", "第 1 章 Video Games Sales 1.1 准备 1.2 缺失值处理 1.3 描述性分析 1.4 探索性分析 1.5 媒体打分与玩家打分的关系 1.6 玩家与媒体分别最喜欢哪个发行商", " 第 1 章 Video Games Sales 1.1 准备 file &lt;- &quot;data/vgsales.csv&quot; df &lt;- read_csv(file) str(df) ## spec_tbl_df [19,600 x 9] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ Rank : num [1:19600] 1 2 3 4 5 6 7 8 9 10 ... ## $ Name : chr [1:19600] &quot;Wii Sports&quot; &quot;Super Mario Bros.&quot; &quot;&quot;.. ## $ Platform : chr [1:19600] &quot;Wii&quot; &quot;NES&quot; &quot;PC&quot; &quot;Wii&quot; ... ## $ Publisher : chr [1:19600] &quot;Nintendo&quot; &quot;Nintendo&quot; &quot;Valve&quot; &quot;Nin&quot;.. ## $ Developer : chr [1:19600] &quot;Nintendo EAD&quot; &quot;Nintendo EAD&quot; &quot;Val&quot;.. ## $ Critic_Score : num [1:19600] 7.7 10 8 8.2 8.6 10 8 9.4 9.1 8.6 ... ## $ User_Score : num [1:19600] 8 8.2 7.5 9.1 4.7 7.8 8.8 8.8 8.1 9.. ## $ Total_Shipped: num [1:19600] 82.9 40.2 40 37.3 36.6 ... ## $ Year : num [1:19600] 2006 1985 2012 2008 2017 ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. Rank = col_double(), ## .. Name = col_character(), ## .. Platform = col_character(), ## .. Publisher = col_character(), ## .. Developer = col_character(), ## .. Critic_Score = col_double(), ## .. User_Score = col_double(), ## .. Total_Shipped = col_double(), ## .. Year = col_double() ## .. ) ## - attr(*, &quot;problems&quot;)=&lt;externalptr&gt; head(df, 3) ## # A tibble: 3 x 9 ## Rank Name Platform Publisher Developer Critic_Score User_Score ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Wii Spo~ Wii Nintendo Nintendo~ 7.7 8 ## 2 2 Super M~ NES Nintendo Nintendo~ 10 8.2 ## 3 3 Counter~ PC Valve Valve Co~ 8 7.5 ## # ... with 2 more variables: Total_Shipped &lt;dbl&gt;, Year &lt;dbl&gt; 数据共包括11列，包含了从1977年~2020年中的游戏销量数据，具体变量说明如下表所示： table_var &lt;- read_excel(&quot;data-intro.xlsx&quot;, sheet = 3) kable(table_var, align = &quot;c&quot;) %&gt;% kable_classic() 变量 说明 Rank 销量排名 Name 游戏名称 Platform 发型平台 Publisher 发行商 Develooper 开发商 Critic_Score 从业人评分 User_Score 用户评分 Total_shipped 总销量(百万套) Year 发型年份 1.2 缺失值处理 summary(df) ## Rank Name Platform ## Min. : 1 Length:19600 Length:19600 ## 1st Qu.: 4899 Class :character Class :character ## Median : 9798 Mode :character Mode :character ## Mean : 9799 ## 3rd Qu.:14698 ## Max. :19598 ## ## Publisher Developer Critic_Score ## Length:19600 Length:19600 Min. : 0.800 ## Class :character Class :character 1st Qu.: 6.100 ## Mode :character Mode :character Median : 7.300 ## Mean : 7.035 ## 3rd Qu.: 8.200 ## Max. :10.000 ## NA&#39;s :9631 ## User_Score Total_Shipped Year ## Min. : 1.000 Min. : 0.0100 Min. :1977 ## 1st Qu.: 6.300 1st Qu.: 0.0500 1st Qu.:2004 ## Median : 7.200 Median : 0.1600 Median :2008 ## Mean : 6.995 Mean : 0.5511 Mean :2008 ## 3rd Qu.: 8.000 3rd Qu.: 0.4600 3rd Qu.:2012 ## Max. :10.000 Max. :82.9000 Max. :2020 ## NA&#39;s :17377 sum(is.na(df)) ## [1] 27010 n_miss(df) ## [1] 27010 数据中有27010个缺失值，而缺失值主要存在与Critic_Score和User_Score，主要原因在于并不是每个用户和从业者都会对游戏进行评分。 需要对其进行一些处理，未打分的我们认为其打分为5.0分，即使用5.0代替所有缺失值。 # 采用每一列的众数替换该列的缺失值 df &lt;- df %&gt;% map_dfc(~replace_na(.x, rstatix::get_mode(.x)[1])) 1.3 描述性分析 描述性统计是一个统计范围，它应用各种技术来描述和总结任何数据集，并研究观察到的数据的一般行为，以促进问题的解决。这可以通过频率表、图形和集中趋势的度量来完成，例如平均值、中位数、众数、离散度量（例如标准偏差、百分位数和四分位数）。 由于2020年只有前半段的数据，我们分析时将2020年的数据剔除，以便更好的分析对比各年份的差异。同时剔除Rank列。 df &lt;- df %&gt;% filter(Year != 2020) %&gt;% select(-Rank) df$Year &lt;- factor(df$Year) 1.3.1 常规分析 1.3.1.1 哪一年的游戏总销量最高 df_shipped &lt;- df %&gt;% select(Year, Total_Shipped) %&gt;% group_by(Year) %&gt;% summarise(count = n()) %&gt;% arrange(desc(count)) p1 &lt;- ggplot(head(df_shipped,10), aes(x = Year, y = count, fill = Year)) + geom_bar(stat = &quot;identity&quot;, alpha = 0.7) + geom_label(aes(label = count), fontface = &quot;bold&quot;, fill = &quot;#006400&quot;, color = &quot;white&quot;, size = 3) + theme_bw() + labs(x = &quot; &quot;, y = &quot; &quot;) + ggtitle(&quot;销量排名前十的年份&quot;) + theme(legend.position = &quot;none&quot;, plot.background = element_rect(color = &quot;black&quot;, size = 1.1), axis.text.x = element_text(face = &quot;bold&quot;), axis.text.y = element_text(face = &quot;bold&quot;), axis.title = element_text(face = &quot;bold&quot;) ) p2 &lt;- ggplot(df_shipped, aes(x = Year, y = count, group = 1)) + geom_point() + geom_line() + theme_bw() + ggtitle(&quot;游戏销量变化&quot;) + labs(x = &quot; &quot;, y = &quot; &quot;) + theme(plot.background = element_rect(color = &quot;black&quot;, size = 1.1), axis.text.x = element_text(face = &quot;bold&quot;, angle = 90)) + geom_curve(x = 40, y = 450, xend = 42, yend = 500, angle = 35, arrow = arrow(length = unit(0.3, &quot;cm&quot;)), color = &quot;red&quot;) + annotate(&quot;text&quot;, x = 42, y = 550, label = &quot;COVID-19&quot;, color = &quot;red&quot;, size = 3) p1/p2 图 1.1: 游戏销量情况 由图1.1可以看出： - 销量排名前十的年份均在21世纪，且2009年销量最高。2009年之后，游戏销量逐渐下滑，在2011年左右趋于平稳。 2018~2019年，游戏销量急剧下滑。猜测原因为新冠肺炎疫情的爆发导致的游戏产能下降、经济下滑，从而大幅影响了游戏的销量。 下面我们将具体看一下各游戏平台的表现。 1.3.1.2 游戏平台排名（销量、游戏数量） df_platform &lt;- df %&gt;% select(Platform, Total_Shipped) %&gt;% group_by(Platform) %&gt;% summarize(amount = sum(Total_Shipped)) %&gt;% arrange(desc(amount)) %&gt;% head(10) p3 &lt;- ggplot(df_platform, aes(x = reorder(Platform, amount), y = amount, fill = Platform)) + geom_bar(stat = &quot;identity&quot;, alpha = 0.7) + labs(x = &quot; &quot;, y = &quot; &quot;) + ggtitle(&quot;游戏平台排名&quot;, subtitle = &quot;平台销量排名&quot;) + coord_flip() + theme_bw() + theme(legend.position = &quot;none&quot;, axis.text = element_text(face = &quot;bold&quot;), plot.title = element_text(face = &quot;bold&quot;), plot.background = element_rect(color = &quot;black&quot;)) df_platform2 &lt;- as.data.frame(table(df$Platform)) %&gt;% rename(Platform = Var1) %&gt;% arrange(desc(Freq)) %&gt;% head(10) p4 &lt;- ggplot(df_platform2, aes(x = reorder(Platform, Freq), y = Freq, fill = Platform)) + geom_bar(stat = &quot;identity&quot;, alpha = 0.7) + labs(x = &quot; &quot;, y = &quot; &quot;) + ggtitle(&quot;游戏平台排名&quot;, subtitle = &quot;平台游戏数量排名&quot;) + coord_flip() + theme_bw() + theme(plot.background = element_rect(color = &quot;black&quot;), legend.position = &quot;none&quot;, plot.title = element_text(face = &quot;bold&quot;), axis.text = element_text(face = &quot;bold&quot;)) p3|p4 图 1.2: 游戏平台排名 由图1.2可以看出： PS2不愧是有史以来最成功的的家用主机，发行在其上的游戏销量排名第一、游戏数量排名第二。 PC游戏仍有一定竞争力。 御三家统治了主机游戏。 下面我们看一下游戏开发商的情况。 1.3.1.3 开发商和发行商排名 df_developer &lt;- df %&gt;% select(Developer, Total_Shipped) %&gt;% group_by(Developer) %&gt;% summarise(amount = sum(Total_Shipped)) %&gt;% arrange(desc(amount)) %&gt;% head(10) p5 &lt;- ggplot(df_developer, aes(x = reorder(Developer, amount), y = amount, fill = Developer)) + geom_bar(stat = &quot;identity&quot;, alpha = 0.7) + coord_flip() + ggtitle(&quot;开发商销量排名&quot;) + labs(x = &quot; &quot;, y = &quot;&quot;) + theme_bw() + theme(legend.position = &quot;none&quot;, plot.background = element_rect(color = &quot;black&quot;)) df_publisher &lt;- df %&gt;% select(Publisher, Total_Shipped) %&gt;% group_by(Publisher) %&gt;% summarise(amount = sum(Total_Shipped)) %&gt;% arrange(desc(amount)) %&gt;% head(10) p6 &lt;- ggplot(df_publisher, aes(x = reorder(Publisher, amount), y = amount, fill = Publisher)) + geom_bar(stat = &quot;identity&quot;, alpha = 0.7) + coord_flip() + ggtitle(&quot;发行商销量排名&quot;) + labs(x = &quot; &quot;, y = &quot;&quot;) + theme_bw() + theme(legend.position = &quot;none&quot;, plot.background = element_rect(color = &quot;black&quot;)) p5|p6 - 任天堂作为开发商和发行商均独占鳌头。 - Game Freak依靠王牌IP精灵宝可梦占据开发商销量第三名。 - 大家耳熟能详的游戏开发商和发行商均有上榜。 1.4 探索性分析 在统计学中，探索性数据分析 (EAD) 是一种分析数据集以总结其主要特征的方法，通常使用可视化方法。 1.4.1 世界最畅销游戏 1.4.1.1 最畅销的5个游戏 那么，1977年~2019年间，到底哪个游戏销量是最高的呢？ options(repr.plot.width = 20, repr.plot.height = 8) df_games &lt;- df %&gt;% select(Name, Total_Shipped) %&gt;% group_by(Name) %&gt;% summarise(amount = sum(Total_Shipped)) %&gt;% arrange(desc(amount)) %&gt;% head(5) p7 &lt;- ggplot(df_games, aes(x = reorder(Name, amount), y = amount, fill = Name)) + geom_col(aes(alpha = 0.9)) + geom_label(aes(label = amount), size = 3, fontface = &quot;bold&quot;, color = &quot;white&quot;) + labs(x = &quot; &quot;, y = &quot; &quot;) + coord_flip() + theme_bw() + theme(legend.position = &quot;none&quot;, plot.background = element_rect(color = &quot;black&quot;, size = 1.1), axis.text.x = element_text( face = &quot;bold&quot;), axis.text.y = element_text(face = &quot;bold&quot;)) p8 &lt;- ggplot(df_games, aes(x = Name, y = amount)) + geom_line(alpha = 0.7, group = 1) + geom_point(aes(fill = Name), shape = 2) + theme_bw()+ theme(legend.position = &quot;none&quot;, plot.background = element_rect(color = &quot;black&quot;), axis.text.x = element_text(face = &quot;bold&quot;)) + labs(x = &quot;&quot;, y = &quot;&quot;) + coord_polar() p7|p8 图 1.3: 游戏总销量排名 由图1.3可知： 游戏销量排名前3的游戏为：Wii Sports、GTA5和我的世界。 GTV5和我的世界在多个游戏平台均有发售，Wii Sports为任天堂平台独占。 任天堂游戏平台发售的游戏占前十的大多数，任天堂就是世界的主宰！ 1.4.1.2 最畅销的5个游戏逐年分布 df_games_top5 &lt;- df %&gt;% filter(Name == &quot;Wii Sports&quot; | Name == &quot;Grand Theft Auto V&quot;| Name == &quot;Minecraft&quot;| Name == &quot;Super Mario Bros.&quot;| Name == &quot;Counter-Strike: Global Offensive&quot;) %&gt;% select(Name, Year, Total_Shipped) ggplot(df_games_top5, aes(x = Year, y = Total_Shipped)) + geom_bar(stat = &quot;identity&quot;, aes(fill = Name, color = Name), alpha = 8) + facet_wrap(~Name) + labs(x = &quot;&quot;, y = &quot;总销量（百万套）&quot;) + theme_bw()+ theme(legend.position = &quot;none&quot;, strip.text.x = element_text( margin = margin(7, 7, 7, 7), size = 7, face = &quot;bold&quot;, color = &quot;white&quot;), strip.background = element_rect(fill = &quot;#B45F04&quot;, color = &quot;black&quot;), plot.title = element_text(face = &quot;bold&quot;), axis.text.x = element_text(face = &quot;bold&quot;, angle = 90, vjust = 0.5), axis.text.y = element_text(face = &quot;bold&quot;)) 1.5 媒体打分与玩家打分的关系 俗话说，“低分信媒体，高分信自己”。如果一款游戏媒体打分低，那肯定不行，但如果一个游戏媒体打高分，也不一定好玩（有可能是塞了钱）。 下面我们就分析一下媒体打分与玩家打分的关系。 df_score &lt;- df %&gt;% select(Name, User_Score, Critic_Score) cor &lt;- cor.test(df_score$User_Score, df_score$Critic_Score, method = &quot;pearson&quot;) p.value &lt;- cor$p.value coef &lt;- cor$estimate ggplot(df_score, aes(x = User_Score, y = Critic_Score)) + geom_smooth(method = lm) 可以看到两个打分的相关系数为0.16，且p值小于0.05，表明两者呈现显著的正相关。看来游戏媒体和玩家对游戏的口味还是一样的，某种程度上说，高分也可以信媒体。 1.6 玩家与媒体分别最喜欢哪个发行商 1.6.1 玩家 那么，玩家最喜欢（打分最高）的游戏发行商是谁呢？ df_player &lt;- df %&gt;% select(Publisher, User_Score) df_player$Publisher &lt;- df_player$Publisher %&gt;% map(~ str_detect(.x,&quot;Sony&quot;) %&gt;% ifelse(&quot;Sony&quot;, .x)) %&gt;% unlist() df_player &lt;- df_player%&gt;% group_by(Publisher) %&gt;% summarise(count = n(), mean_score = mean(User_Score)) %&gt;% filter(count &gt;= 50) %&gt;% select(Publisher, mean_score) %&gt;% arrange(desc(mean_score)) df_player ## # A tibble: 62 x 2 ## Publisher mean_score ## &lt;chr&gt; &lt;dbl&gt; ## 1 Rockstar Games 7.84 ## 2 Microsoft Game Studios 7.77 ## 3 Nintendo 7.77 ## 4 Sierra Entertainment 7.72 ## 5 DreamCatcher Interactive 7.71 ## 6 5pb 7.71 ## 7 Sony 7.70 ## 8 Eidos Interactive 7.70 ## 9 Acclaim Entertainment 7.7 ## 10 Agetec 7.7 ## # ... with 52 more rows 在发行过50个以上游戏的老牌发行商中： R星凭借GTA、荒野大镖客等重量级IP以7.842的评分独占鳌头。 所有发行商的评分均超过7分，说明现代游戏的质量还是有保障的。 1— output: html_document: default pdf_document: default — "],["2-Olympic-history.html", "第 2 章 Olympic history 2.1 介绍 2.2 运动员、国家和时间 2.3 艺术竞赛（The Art Competitions） 2.4 奥林匹克中的女将们 2.5 奖牌榜（Medal Count） 2.6 地理信息地图 2.7 参赛运动员身高体重", " 第 2 章 Olympic history 2.1 介绍 本项目的主要目标是阐明奥运会历史的主要模式，例如运动员、运动、参与国家的数量，哪些国家的运动员最多，赢得奖牌情况，运动员的特性（eg：性别、身体特征等）。 我将一些你可能不知道的奥运历史上特别有趣的方面进行放大化。你知道纳粹德国举办了1936年奥运会，而那届奥运会他们打败了所有人？你知道绘画和诗歌曾经是奥运会项目吗？这些历史小花絮同样是我的关注点。 首先，我们读取数据，并对每列的数据类型进行定义。 file&lt;- &quot;data/olympics/athlete_events.csv&quot; data &lt;- read_csv(file, col_types = cols( ID = col_character(), Name = col_character(), Sex = col_factor(levels = c(&quot;M&quot;,&quot;F&quot;)), Age = col_integer(), Height = col_double(), Weight = col_double(), Team = col_character(), NOC = col_character(), Games = col_character(), Year = col_integer(), Season = col_factor(levels = c(&quot;Summer&quot;,&quot;Winter&quot;)), City = col_character(), Sport = col_character(), Event = col_character(), Medal = col_factor(levels = c(&quot;Gold&quot;,&quot;Silver&quot;,&quot;Bronze&quot;)) )) head(data) ## # A tibble: 6 x 15 ## ID Name Sex Age Height Weight Team NOC Games Year ## &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 1 A Dijiang M 24 180 80 China CHN 1992~ 1992 ## 2 2 A Lamusi M 23 170 60 China CHN 2012~ 2012 ## 3 3 Gunnar Nie~ M 24 NA NA Denm~ DEN 1920~ 1920 ## 4 4 Edgar Lind~ M 34 NA NA Denm~ DEN 1900~ 1900 ## 5 5 Christine ~ F 21 185 82 Neth~ NED 1988~ 1988 ## 6 5 Christine ~ F 21 185 82 Neth~ NED 1988~ 1988 ## # ... with 5 more variables: Season &lt;fct&gt;, City &lt;chr&gt;, Sport &lt;chr&gt;, ## # Event &lt;chr&gt;, Medal &lt;fct&gt; 2.2 运动员、国家和时间 2.2.1 随着时间的推移，运动员、国家和赛事的数量是否发生了变化？ counts &lt;- data %&gt;% filter(Sport != &quot;Art Competitions&quot;) %&gt;% # 去掉艺术类的运动类别 group_by(Year, Season) %&gt;% summarize( Athletes = length(unique(ID)), Nations = length(unique(NOC)), Events = length(unique(Event)) ) counts ## # A tibble: 51 x 5 ## # Groups: Year [35] ## Year Season Athletes Nations Events ## &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1896 Summer 176 12 43 ## 2 1900 Summer 1224 31 90 ## 3 1904 Summer 650 15 95 ## 4 1906 Summer 841 21 74 ## 5 1908 Summer 2024 22 109 ## 6 1912 Summer 2377 27 102 ## 7 1920 Summer 2665 29 153 ## 8 1924 Summer 3067 44 126 ## 9 1924 Winter 313 19 17 ## 10 1928 Summer 2877 46 109 ## # ... with 41 more rows # 作图 # 运动员数量及关键时间点 p1 &lt;- ggplot(counts, aes(x = Year, y = Athletes, group = Season, color = Season)) + geom_point(size = 2) + geom_line() + scale_color_manual(values = c(&quot;darkorange&quot;, &quot;darkblue&quot;)) + # 手动设置图形颜色 xlab(&quot; &quot;) + annotate(&quot;text&quot;, x = c(1932, 1956, 1976, 1980), y = c(2000, 2750, 6800, 4700), label = c( &quot;L.A. 1932&quot;, &quot;Melbourne 1956&quot;, &quot;Montreal 1976&quot;, &quot;Moscow 1980&quot;), size=3) + # 对几个临界拐点进行标记。 # 针对两次世界大战的时间做出标记 annotate(&quot;text&quot;, x = c(1916,1942), y = c(10000,10000), label = c(&quot;WWI&quot;, &quot;WWII&quot;), size = 4, color = &quot;red&quot;) + geom_segment(aes(x = 1914, y = 8000, xend = 1918, yend = 8000), color = &quot;red&quot;, size = 2) + geom_segment(aes(x = 1939,y = 8000, xend = 1945, yend = 8000), color = &quot;red&quot;, size=2) + scale_x_continuous(breaks = seq(1890, 2020, 4)) + scale_y_continuous(breaks = seq(0, 15000, 5000)) + theme_bw() + theme(axis.text.x = element_text(size = 10, angle = 90, vjust = 0.4, face = &quot;bold&quot;)) # 参与国家数量及关键时间点 p2 &lt;- ggplot(counts, aes(x = Year, y = Nations, group = Season, color = Season)) + geom_point(size = 2) + geom_line() + scale_color_manual(values = c(&quot;darkorange&quot;, &quot;darkblue&quot;)) + xlab(&quot;&quot;) + annotate(&quot;text&quot;, x = c(1932, 1976, 1980), y = c(60, 105, 70), label = c(&quot;L.A. 1932&quot;, &quot;Montreal 1976&quot;, &quot;Moscow 1980&quot;)) + scale_x_continuous(breaks = seq(1890, 2020, 4)) + scale_y_continuous(breaks = seq(0, 250, 50)) + theme_bw() + theme(axis.text.x = element_text(size = 10, angle = 90, vjust = 0.4, face = &quot;bold&quot;)) # 参赛项目 p3 &lt;- ggplot(counts, aes(x = Year, y = Events, group = Season, color = Season)) + geom_point(size = 2) + geom_line() + scale_color_manual(values = c(&quot;darkorange&quot;, &quot;darkblue&quot;)) + scale_x_continuous(breaks = seq(1890, 2020, 4)) + scale_y_continuous(breaks = seq(0, 350, 50)) + theme_bw() + theme(axis.text.x = element_text(size = 10, angle = 90, vjust = 0.4, face = &quot;bold&quot;)) grid.arrange(p1, p2, p3, ncol = 1) 图 2.1: 随着时间的推移，运动员、国家和赛事的数量的变化情况 从图2.1 可以看出两次世界大战期间，奥运会基本处于停滞状态（WWI:1912-1920，WWII:1936-1948）。此外，有几届值得注意的奥运会上发生了一些事件，在图形中呈现为明显的下降趋势： L.A., 1932: 1932年洛杉矶奥运会，当时的美国正处于大萧条期间，许多运动员没办法负担到奥运会的差旅费用，导致参加本届奥运会的国家机器运动员数量骤降。 Melbourne, 1956：1956年墨尔本奥运会是事端最多的一届奥运会：1、由于战争立场不同，包括埃及、以色列、伊拉克和黎巴嫩在内的一些中东及非洲国家，西班牙、荷兰、瑞士、哥伦比亚等欧洲国家均抵制本届奥运会；2.由于台湾问题，我国也未参加本届奥运会。 Montreal, 1976：1976年蒙特利尔奥运会，由于发生了抵制运动，25个国家（大部分为非洲国家）未参加本届奥运会。 Moscow, 1980：1980年莫斯科奥运会，由于苏联军队对阿富汗的入侵，包括美国在内的66个国家对本届奥运会进行了抵制，本届奥运会最终仅有80个国家参加，是自1956年以来最少国家参加的一届，而许多参赛的国家也只派一名旗手，以奥运会会旗代替国旗进场。这是奥运历史上最严重的一次危机，从一定程度上威胁了奥林匹克运动的发展。 从2000年开始，奥运会的增长势头（比赛项目额参赛运动员数量）趋于平缓，夏季奥运会迎来了它的饱和点。而冬季奥运会处于虽然还有一定上升空间，但冰雪运动受限于气候和场地，在很多国家并不普吉，所以其涨势并不明显。 2.3 艺术竞赛（The Art Competitions） 2.3.1 运动员、时间、参赛项目 art &lt;- data %&gt;% filter(Sport == &quot;Art Competitions&quot;) %&gt;% select(Name, Sex, Age, Team, NOC, Year, City, Event, Medal) head(art) ## # A tibble: 6 x 9 ## Name Sex Age Team NOC Year City Event Medal ## &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; ## 1 Win Valdemar Aalto~ M 54 Finl~ FIN 1948 Lond~ Art ~ &lt;NA&gt; ## 2 Adolf Gaston Abel M 45 Germ~ GER 1928 Amst~ Art ~ &lt;NA&gt; ## 3 Adolf Gaston Abel M 45 Germ~ GER 1928 Amst~ Art ~ &lt;NA&gt; ## 4 Georges Achille-Fo~ F 55 Fran~ FRA 1924 Paris Art ~ &lt;NA&gt; ## 5 Dsir Antoine Acket M 27 Belg~ BEL 1932 Los ~ Art ~ &lt;NA&gt; ## 6 Dsir Antoine Acket M 27 Belg~ BEL 1932 Los ~ Art ~ &lt;NA&gt; # 基础计算 count_art &lt;- art %&gt;% group_by(Year) %&gt;% summarize( Events = length(unique(Event)), Nations = length(unique(Team)), Artists = length(unique(Name)) ) head(count_art) ## # A tibble: 6 x 4 ## Year Events Nations Artists ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1912 5 12 33 ## 2 1920 5 5 11 ## 3 1924 5 24 189 ## 4 1928 13 19 370 ## 5 1932 13 36 588 ## 6 1936 19 24 527 在最初的奥运会中，还存在艺术竞赛（Art Competition）项目的比拼，准确的说从1912年至1948年间的几届奥运会。 1954年，国际奥委会决定艺术竞赛不再作为奥运会的比赛项目。 虽然艺术竞赛的数据仅占本数据集的1.3%，但考虑到其在奥运会理事上的特殊意义，仍有必要对其进行探索分析。 # 提取有关艺术竞赛的数据 art &lt;- data %&gt;% filter(Sport == &quot;Art Competitions&quot;) %&gt;% select(Name, Sex, Age, Team, NOC, Year, City, Event, Medal) # 计算每年的Events, Nations, Artists数量 counts_art &lt;- art %&gt;% filter(Team != &quot;Unknow&quot;) %&gt;% # 剔除国籍不确定的运动员 group_by(Year) %&gt;% summarize( Events = length(unique(Event)), Nations = length(unique(Team)), Artisit = length(unique(Name)) ) p4 &lt;- ggplot(counts_art, aes(x = Year, y = Events)) + geom_point(size = 2) + geom_line() + xlab(&quot; &quot;) + scale_x_continuous(breaks = seq(min(counts_art[&quot;Year&quot;]), max(counts_art[&quot;Year&quot;]), 4)) + scale_y_continuous(breaks = seq(0, 20, 2)) + theme_bw() + theme(axis.text.x = element_text(size = 10, vjust = 0.4, face = &quot;bold&quot;)) p5 &lt;- ggplot(counts_art, aes(x = Year, y = Nations)) + geom_point(size = 2) + geom_line() + xlab(&quot; &quot;) + scale_x_continuous(breaks = seq(min(counts_art[&quot;Year&quot;]), max(counts_art[&quot;Year&quot;]), 4)) + scale_y_continuous(breaks = seq(0, 40, 5)) + theme_bw() + theme(axis.text.x = element_text(size = 10, vjust = 0.4, face = &quot;bold&quot;)) p6 &lt;- ggplot(counts_art, aes(x = Year, y = Artisit)) + geom_point(size = 2) + geom_line() + xlab(&quot; &quot;) + scale_x_continuous(breaks = seq(min(counts_art[&quot;Year&quot;]), max(counts_art[&quot;Year&quot;]), 4)) + scale_y_continuous(breaks = seq(0, 600, 100)) + theme_bw() + theme(axis.text.x = element_text(size = 10, vjust = 0.4, face = &quot;bold&quot;)) grid.arrange(p4, p5, p6, ncol = 1) 图 2.2: 历届奥运会艺术竞赛随时间变化图（参与国家、参赛运动员、比赛项目） 如图2.2所示，艺术竞赛的数据变化呈不规则的增长趋势。可以看到，与1920年相比，1924年奥运会参与艺术竞赛的国家和运动员数量均有相对较大幅度的增长，这或许是1928年奥运会艺术竞赛比赛项目增多的一个原因。 2.3.2 获得奖牌情况-哪个国家获得的艺术竞赛类奖牌数量最多 # 计算每个国家所获奖牌数量 medal_counts_arts &lt;- art %&gt;% filter(!is.na(Medal)) %&gt;% group_by(Team, Medal) %&gt;% summarize(Count = length(Medal)) # 根据奖牌数量对国家进行排序 levs_art &lt;- medal_counts_arts %&gt;% group_by(Team) %&gt;% summarize(Total = sum(Count)) %&gt;% arrange(Total) %&gt;% select(Team) medal_counts_arts$Team &lt;- factor(medal_counts_arts$Team, levels = levs_art$Team) ggplot(medal_counts_arts, aes(x = Team, y = Count, fill = Medal)) + geom_col() + coord_flip() + scale_y_continuous(breaks = seq(0, 30, 5)) + scale_fill_manual(values = c(&quot;gold1&quot;, &quot;gray70&quot;, &quot;gold4&quot;)) + ggtitle(&quot;艺术竞赛奖牌榜&quot;) + theme(plot.title = element_text(hjust = 0.5)) 图 2.3: 各国艺术竞赛奖牌榜 art_country &lt;- nrow(unique(art[&quot;Team&quot;])) art_country_medal &lt;- nrow(medal_counts_arts %&gt;% summarize(country = length(unique(Team))) ) 共有51个国家参加了奥运会的艺术竞赛类项目，仅有不到一半数量的国家（23）获得了奖牌（如图2.3所示），排名前三位的为德国、法国、意大利。 2.4 奥林匹克中的女将们 现代奥林匹克之父顾拜旦曾今极力反对女性参加奥运会。其后的IOC主席也同样支持这个观点。尽管有多方面的阻力，从第一届奥运会（1896年）开始的每届奥运会均有女性参与其中。所以我们在这里探索一下女性参加奥运会的历史趋势：多少人？从哪里来？她们如何找到途经参加的？ 本部分中，对数据集进行如下处理： 将第@sec:art-com节中讨论过的艺术竞赛数据剔除。 将夏季和冬季奥运会合并为“Olympiads”列，即每四年期内包括一届夏季奥运会和一届冬季奥运会。 让我们开始！ 2.4.1 男女运动员数量比较 # 剔除艺术竞赛项目数据 data &lt;- data %&gt;% filter(Sport != &quot;Art Competition&quot;) # 对Year列数据重新编码（1992年之后，与夏季奥运会匹配） # 处理后，冬季和夏季奥运会举办时间的已匹配 original &lt;- c(1994, 1998, 2002, 2006, 2010, 2014) new &lt;- c(1996, 2000, 2004, 2008, 2012, 2016) for (i in 1:length(original)) { data$Year &lt;- gsub(original[i], new[i], data$Year) } data$Year &lt;- as.integer(data$Year) counts_sex &lt;- data %&gt;% group_by(Year, Sex) %&gt;% summarize(Athletes = length(unique(ID))) counts_sex$Year &lt;- as.integer(counts_sex$Year) ggplot(counts_sex, aes(x = Year, y = Athletes, group = Sex, color = Sex)) + geom_point(size = 2) + geom_line() + scale_color_manual(values = c(&quot;darkblue&quot;, &quot;red&quot;)) + scale_x_continuous(breaks = seq(1896, 2016, 4)) + scale_y_continuous(breaks = seq(0, 9000, 500)) + labs(title = &quot;Number of male and female Olympians over time&quot;) + theme_bw() + theme(plot.title= element_text(hjust = 0.5), axis.text.x = element_text(angle = 90, face = &quot;bold&quot;, vjust = 0.5)) 图 2.4: 历届奥运会南云运动员数量 counts_sex_latest &lt;- counts_sex %&gt;% filter(Year == 2016) counts_sex_latest ## # A tibble: 2 x 3 ## # Groups: Year [1] ## Year Sex Athletes ## &lt;int&gt; &lt;fct&gt; &lt;int&gt; ## 1 2016 M 7788 ## 2 2016 F 6133 如图2.4所示，直到1996年，参加奥运会的女运动员数量的变化趋势都与男运动员相同，此时男运动员的数量达到8000人的最顶点，而此时女运动员的数量还在以一个较高的增长率上升。最近的一届奥运会（2014年索契冬奥会和2016年里约奥运会中），女运动的数量已经超过了0.4405574。 2.4.2 各国参赛男女运动员间数量关系 选择1936，1956，1976，1996，2016五个年份的数据进行分析。这五年的数据互相间隔20年，可以独立的展示独立的回归曲线。 # Count M/F Total per country per Olympics counts_NOC &lt;- data %&gt;% filter(Year %in% c(1936, 1956, 1976, 1996, 2016)) %&gt;% group_by(Year, NOC, Sex) %&gt;% summarize(Count = length(unique(ID))) %&gt;% spread(Sex, Count) %&gt;% # 按照Sex为key，Count为value的规则进行pivot_wider()操作。 mutate(Total = sum(M, F, na.rm = T)) # 计算运动员总数 names(counts_NOC)[3: 4] &lt;- c(&quot;Male&quot;, &quot;Female&quot;) # 将缺失值变为0 counts_NOC$Male[is.na(counts_NOC$Male)] &lt;- 0 counts_NOC$Female[is.na(counts_NOC$Female)] &lt;- 0 counts_NOC$Year &lt;- as.factor(counts_NOC$Year) # 将Year列转化为因子 counts_NOC ## # A tibble: 622 x 5 ## # Groups: Year, NOC [622] ## Year NOC Male Female Total ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1936 AFG 15 0 15 ## 2 1936 ARG 50 1 51 ## 3 1936 AUS 29 4 33 ## 4 1936 AUT 265 27 292 ## 5 1936 BEL 168 8 176 ## 6 1936 BER 5 0 5 ## 7 1936 BOL 2 0 2 ## 8 1936 BRA 67 6 73 ## 9 1936 BUL 33 0 33 ## 10 1936 CAN 101 25 126 ## # ... with 612 more rows ggplot(counts_NOC, aes(x = Male, y = Female, group = Year, color = Year)) + geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;) + geom_smooth(method = &quot;lm&quot;, se = FALSE) 图 2.5: 各国参加奥运会男女运动员比例关系 从图2.5可以看出，与1936-1956年间女运动员的数量增长数量较为缓慢相比，1956-2016年间，女运动员的参赛人数有了明显的提升。从回归曲线（虚线）可以看出，在1996年及2016年，部分国家甚至派出了女性占大多数的参赛代表团。 2.5 奖牌榜（Medal Count） # 按奖牌多少的顺序计算各国奖牌榜 medalCount &lt;- data %&gt;% filter(!is.na(Medal)) %&gt;% filter(Sport != &quot;Art Competitions&quot;) %&gt;% group_by(Team, Medal) %&gt;% summarize(Count = length(Medal)) medalCountLevs &lt;- medalCount %&gt;% group_by(Team) %&gt;% summarize(Total = sum(Count)) %&gt;% arrange(Total) %&gt;% select(Team) %&gt;% tail(25) medalCount$Team &lt;- factor(medalCount$Team, levels = medalCountLevs$Team) medalCount &lt;- medalCount %&gt;% filter(Team != &quot;NA&quot;) ggplot(medalCount, aes(x = Team, y = Count, fill = Medal)) + geom_col() + coord_flip() + scale_fill_manual(values = c(&quot;gold1&quot;, &quot;gray70&quot;, &quot;gold4&quot;)) + ggtitle(&quot;Olympics Medal Tally&quot;) + theme(plot.title = element_text(hjust = 0.5)) 图 2.6: 各国历史奖牌榜前50名的国家 图2.6显示，美国所获的奖牌数最多，而且远多于第二名的苏联。中国排在日本之后，排名第16位。进一步我们看一下中国的奖牌数变化。 medalChina &lt;- data %&gt;% filter(!is.na(Medal)&amp;Sport != &quot;Art Competitions&quot;&amp;Team == &quot;China&quot;) %&gt;% group_by(Year, Medal) %&gt;% summarize(Count = length(Medal)) ggplot(medalChina, aes(x = reorder(Year, -Count), y = Count, fill = Medal)) + geom_col() + scale_fill_manual(values = c(&quot;gold1&quot;, &quot;gray70&quot;, &quot;gold4&quot;)) + xlab(&quot; &quot;) + ylab(&quot;奖牌数&quot;) + theme_bw() 图 2.7: 历届奥运会中国奖牌数量变化 图2.7显示，2008年北京奥运会，中国获得奖牌数最多。1988年汉城奥运会，由于苏联、德国等国家重新参加比赛，竞争明显大于1984年奥运会，导致中国获得奖牌数最少，仅5枚金牌。 2.6 地理信息地图 本部分我们聚焦夏季奥运会，在世界地图上呈现各国参加奥运会人数的变化情况。选取最近的一届2016年奥运会以及分别相隔44年的1972年慕尼黑奥运会和1928年阿姆斯特丹奥运会。 2.6.1 1928年奥运会情况 # 读取NOC数据 noc &lt;- read_csv(&quot;data/olympics/noc_regions.csv&quot;, col_types = cols( NOC = col_character(), region = col_character() )) # 增加regions数据，去除缺失值 dataRegions &lt;- data %&gt;% left_join(noc, by = &quot;NOC&quot;) %&gt;% filter(!is.na(region)) # 将选择的三届奥运会的数据筛选出来 amsterdam &lt;- dataRegions %&gt;% filter(Games== &quot;1928 Summer&quot;) %&gt;% group_by(region) %&gt;% summarize(Amsterdam = length(unique(ID))) munich &lt;- dataRegions %&gt;% filter(Games == &quot;1972 Summer&quot;) %&gt;% group_by(region) %&gt;% summarize(Munich = length(unique(ID))) rio &lt;- dataRegions %&gt;% filter(Games == &quot;2016 Summer&quot;) %&gt;% group_by(region) %&gt;% summarize(Rio = length(unique(ID))) # 建立地图 world &lt;- map_data(&quot;world&quot;) mapdat &lt;- tibble(region = unique(world$region)) # 提取国家列 mapdat &lt;- mapdat %&gt;% left_join(amsterdam, by = &quot;region&quot;) %&gt;% left_join(munich, by = &quot;region&quot;) %&gt;% left_join(rio, by = &quot;region&quot;) mapdat$Amsterdam[is.na(mapdat$Amsterdam)] &lt;- 0 mapdat$Munich[is.na(mapdat$Munich)] &lt;- 0 mapdat$Rio[is.na(mapdat$Rio)] &lt;- 0 world &lt;- left_join(world, mapdat, by = &quot;region&quot;) # 1928 ggplot(world, aes(x = long, y = lat, group = group)) + geom_polygon(aes(fill = Amsterdam)) + labs(title = &quot;Amsterdam 1928&quot;, x = NULL, y = NULL) + theme(axis.ticks = element_blank(), axis.text = element_blank(), panel.background = element_rect(fill = &quot;navy&quot;), plot.title = element_text(hjust = 0.5)) + guides(fill = guide_colorbar(title = &quot;Athletes&quot;)) + scale_fill_gradient(low = &quot;white&quot;, high = &quot;red&quot;) 2.6.2 1972年奥运会情况 ggplot(world, aes(x = long, y = lat, group = group)) + geom_polygon(aes(fill = Munich)) + labs(title = &quot;Munich 1972&quot;, x = NULL, y = NULL) + theme(axis.ticks = element_blank(), axis.text = element_blank(), panel.background = element_rect(fill = &quot;navy&quot;), plot.title = element_text(hjust = 0.5)) + guides(fill = guide_colorbar(title = &quot;Athletes&quot;)) + scale_fill_gradient2(low = &quot;white&quot;, high = &quot;red&quot;) 2.6.3 2016年奥运会情况 ggplot(world, aes(x = long, y = lat, group = group)) + geom_polygon(aes(fill = Rio)) + labs(title = &quot;Rio 2016&quot;, x = NULL, y = NULL) + theme(axis.ticks = element_blank(), axis.text =element_blank(), panel.background = element_rect(fill = &quot;navy&quot;), plot.title = element_text(hjust = 0.5)) + guides(fill = guide_colorbar(title = &quot;Athletes&quot;)) + scale_fill_gradient2(low = &quot;white&quot;, high = &quot;red&quot;) 2.7 参赛运动员身高体重 更高、更快、更强是奥运会的座右铭，而每届奥运会的参赛运动员似乎也比之前奥运会更快更强。要验证这个观点，我们需要通过本数据探索历届奥运会运动员身高及体重的变化趋势。 2.7.1 数据完整性及可用性检测 data %&gt;% group_by(Year, Sex) %&gt;% summarize(Present = length(unique(ID[which(!is.na(Height)&amp;!is.na(Weight))])), Total = length(unique(ID))) %&gt;% mutate(Proportion = Present/Total) %&gt;% ggplot(aes(x = Year, y = Proportion, group = Sex, color = Sex)) + geom_point() + geom_line() + scale_color_manual(values = c(&quot;darkblue&quot;, &quot;red&quot;)) + theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(face = &quot;bold&quot;, angle = 90)) + labs(title = &quot;Height/Weight data completeness from each Olympics&quot;) + scale_x_continuous(breaks = seq(1896, 2016, 4)) 图 2.8: Height/Weight data completeness from each Olympics 图2.8所示，1960年，数据的完整性有一个巨大的飞跃，且从本届奥运会开始，数据的完整性均超过了85%（除1992年外）。鉴于此，我们选取从1960年开始的数据，共包括56年间的15届奥运会。 data &lt;- data %&gt;% filter(!is.na(Height), !is.na(Weight), Year&gt; 1959) 2.7.2 身高体重 pHeight &lt;- ggplot(data, aes(x = as.factor(Year), y = Height, fill = Sex)) + geom_boxplot(alpha = 0.75) + xlab(&quot;Olympiad Year&quot;) + ylab(&quot;Height(cm)&quot;) + scale_fill_manual(values = c(&quot;blue&quot;, &quot;red&quot;)) pWeight &lt;- ggplot(data, aes(x = as.factor(Year), y = Weight, fill = Sex)) + geom_boxplot(alpha = 0.75) + xlab(&quot;Olympiad Year&quot;) + ylab(&quot;Weight(kg)&quot;) + scale_fill_manual(values = c(&quot;blue&quot;, &quot;red&quot;)) grid.arrange(pHeight, pWeight,ncol = 1) 图 2.9: Athlete height &amp; weight over time 图2.9显示，运动员身高体重（包括男女）均呈现稳步上升的趋势。但是，由于不同运动项目要求体型不同，图2.9可能隐藏了一些重要的变化规律。因此，必须进一步深入探索不同项目中身高体重数据变化的趋势。然而，在奥运会的历史上，运动项目是不断变化的，首先，必须筛选出1960~2016年间奥运会都设立的比赛项目。 # 筛选1960年奥运会的项目 events &lt;- data[data$Year == 1960, &quot;Event&quot;] %&gt;% unique %&gt;% .$Event years &lt;- data$Year %&gt;% unique %&gt;% sort %&gt;% tail(-1) for (i in 1:length(years)) { nxt &lt;- data[data$Year == years[i], &quot;Event&quot;] %&gt;% unique %&gt;% .$Event events &lt;- intersect(events, nxt) } # 按照1960年项目对之后的项目进行筛选 data &lt;- data %&gt;% filter(Event %in% events) # get list of sports matching events sportsEvents &lt;- data %&gt;% select(Sport, Event) %&gt;% unique 2.7.3 change in Weight VS change in Height over times across men’s sports # 剔除摔跤、举重、拳击、马术 sportsEvents &lt;- sportsEvents %&gt;% filter(!Sport %in% c(&quot;Wrestling&quot;, &quot;Weightlifting&quot;, &quot;Boxing&quot;, &quot;Equestrianism&quot;)) %&gt;% filter(!Event %in% c(&quot;Figure Skating Mixed Pairs&quot;)) %&gt;% arrange(Sport) # 增加一列 men/women/mixed 区分男女项目 sportsEvents$Sex &lt;- ifelse(grepl(&quot;Women&quot;, sportsEvents$Event), &quot;Women&quot;, &quot;Men&quot;) # 创建循环，进行回归 s.height &lt;- s.weight &lt;- c() for (i in 1:nrow(sportsEvents)) { temp &lt;- data %&gt;% filter(Event == sportsEvents$Event[i]) lm.height &lt;- lm(Height ~ Year, data = temp) lm.weight &lt;- lm(Weight ~ Year, data = temp) s.height[i] &lt;- lm.height$coefficients[&quot;Year&quot;] s.weight[i] &lt;- lm.weight$coefficients[&quot;Year&quot;] } slopes &lt;- tibble(Sport = sportsEvents$Sport, Event = sportsEvents$Event, Sex = sportsEvents$Sex, Height = s.height, Weight = s.weight) "],["3-HR-comma-sep.html", "第 3 章 员工离职分析 3.1 描述性分析 3.2 建模预测1-回归树+混淆矩阵 3.3 建模预测2-朴素贝叶斯 3.4 模型评估及应用 3.5 模型应用 3.6 mlr3建模", " 第 3 章 员工离职分析 3.1 描述性分析 3.1.1 数据概览 hr &lt;- read.csv(&quot;data/HR_comma_sep.csv&quot;) summary(hr) ## satisfaction_level last_evaluation number_project ## Min. :0.0900 Min. :0.3600 Min. :2.000 ## 1st Qu.:0.4400 1st Qu.:0.5600 1st Qu.:3.000 ## Median :0.6400 Median :0.7200 Median :4.000 ## Mean :0.6128 Mean :0.7161 Mean :3.803 ## 3rd Qu.:0.8200 3rd Qu.:0.8700 3rd Qu.:5.000 ## Max. :1.0000 Max. :1.0000 Max. :7.000 ## average_montly_hours time_spend_company Work_accident ## Min. : 96.0 Min. : 2.000 Min. :0.0000 ## 1st Qu.:156.0 1st Qu.: 3.000 1st Qu.:0.0000 ## Median :200.0 Median : 3.000 Median :0.0000 ## Mean :201.1 Mean : 3.498 Mean :0.1446 ## 3rd Qu.:245.0 3rd Qu.: 4.000 3rd Qu.:0.0000 ## Max. :310.0 Max. :10.000 Max. :1.0000 ## left promotion_last_5years sales ## Min. :0.0000 Min. :0.00000 Length:14999 ## 1st Qu.:0.0000 1st Qu.:0.00000 Class :character ## Median :0.0000 Median :0.00000 Mode :character ## Mean :0.2381 Mean :0.02127 ## 3rd Qu.:0.0000 3rd Qu.:0.00000 ## Max. :1.0000 Max. :1.00000 ## salary ## Length:14999 ## Class :character ## Mode :character ## ## ## 观察各个变量的主要描述统计量，可知： 离职率（left）平均将近24%。 对公司的满意度（satisfaction_level）仅有62%左右。 平均每个人参加过的项目数（number_project）仅为3~4个。 员工每月平均工作时间（average_montly_hours）达到201.1小时，按照每月工作20天（去除8天双休）计算，每个员工平均每天工作超过10小时。 3.1.2 员工离职情况与员工满意度、月均工作时间、绩效评估和在职年限的关系 我们通过绘图观察离职员工的特点。 hr$left &lt;- factor(hr$left, levels = c(&quot;0&quot;, &quot;1&quot;)) # 离职率与公司满意度关系 boxSat &lt;- ggplot(hr, aes(x = left, y = satisfaction_level, fill = left)) + geom_boxplot() + theme_bw() + labs(x = &quot;离职情况&quot;, y = &quot;员工满意度&quot;) + guides(fill = guide_legend(title = &quot;离职情况&quot;)) # 离职率与绩效评估的关系 boxEva &lt;- ggplot(hr, aes(x = left, y = last_evaluation, fill = left)) + geom_boxplot() + theme_bw() + labs(x = &quot;离职情况&quot;, y = &quot;绩效评估&quot;) + guides(fill = guide_legend(title = &quot;离职情况&quot;)) # 离职率与月均工作时间的关系 boxMonth &lt;- ggplot(hr, aes(x = left, y = average_montly_hours, fill = left)) + geom_boxplot() + theme_bw()+ labs(x = &quot;离职率&quot;, y = &quot;月均工作时间&quot;) + guides(fill = guide_legend(title = &quot;离职情况&quot;)) # 离职率与工作年限的关系 boxTime &lt;- ggplot(hr, aes(x = left, y = time_spend_company, fill = left)) + geom_boxplot() + theme_bw() + labs(x = &quot;离职率&quot;, y = &quot;在职年限&quot;) + guides(fill = guide_legend(title = &quot;离职情况&quot;)) boxSat/boxEva |boxMonth/boxTime 图 3.1: 员工离职情况与员工满意度、月均工作时间、绩效评估和在职年限的关系。 由图3.1可以看出，离职员工的几个特点： 左上图：离职员工的满意度明显低于未离职的满意度，大都集中于0.4左右。 左下图：离职员工的绩效评估较高。推测离职员工倾向于寻找待遇更好的工作。 右上图：离职员工的月均工作时长较高，大部分超过了平均水平（200小时）。 右下图：工作年限均在4年左右。 3.1.3 员工离职情况与项目参与个数、五年内升职情况和薪资的关系 hr$number_project &lt;- factor(hr$number_project, levels = c(&quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;)) # 离职与参与项目数关系 barProject &lt;- ggplot(hr, aes(x = number_project, fill = left)) + geom_bar(position = &quot;fill&quot;) + # fill为百分比条形图 theme_bw() + labs(x = &quot;参与项目数&quot;, y = &quot;比例&quot;) + guides(fill = guide_legend(title = &quot;离职情况&quot;)) # 离职与升职情况关系 hr$promotion_last_5years[hr$promotion_last_5years == 1] &lt;- &quot;已升职&quot; hr$promotion_last_5years[hr$promotion_last_5years == 0] &lt;- &quot;未升职&quot; bar5years &lt;- ggplot(hr, aes(x = as.factor(promotion_last_5years), fill = left)) + geom_bar(position = &quot;fill&quot;) + theme_bw() + labs(x = &quot;5年内升职情况&quot;, y = &quot;比例&quot;) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + guides(fill = guide_legend(title = &quot;离职情况&quot;)) # 离职与薪资关系 barSalary &lt;- ggplot(hr, aes(x = factor(salary, levels = c(&quot;low&quot;, &quot;medium&quot;, &quot;high&quot;), ordered=TRUE), fill = left)) + geom_bar(position = &quot;fill&quot;) + theme_bw() + labs(x = &quot;薪资情况&quot;, y = &quot;比例&quot;) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + guides(fill = guide_legend(title = &quot;离职情况&quot;)) barProject|bar5years |barSalary 图 3.2: 员工离职情况与项目参与个数、五年内升职情况和薪资的关系。 由图3.2可以看出，离职员工的几个特点： 参与项目过少（2个）与过多（7个）的员工离职率均比较高。且参与项目在3个及以上时，参与项目越多，离职率越高。 5年内未升职的员工离职率较高。 薪资越低，离职率越高。 3.2 建模预测1-回归树+混淆矩阵 建模的思路： 提取所需数据。 定义交叉验证方法。 进行分层抽样，提取出想要的训练集和测试集。 实际建模。 对数据进行预测（利用混淆矩阵的方式）。 3.2.1 提取数据 选择符合条件的样本。通过绩效评估、在职时间和参与项目数筛选出更有代表性的样本数据进行分析。 按照绩效评估、在职时间、参与项目数量 hr_model &lt;- hr %&gt;% filter(last_evaluation &gt;= 0.70 | time_spend_company&gt;=4 | number_project&gt;=5) 3.2.2 确定交叉验证方法 # cv为设置交叉验证方法，number = 5为5折交叉验证。 train_control &lt;- trainControl(method = &quot;cv&quot;, number = 5) 3.2.3 分层抽样 2 # 设定随机种子，确保每次抽样结果一致。 set.seed(1234) # 根据数据因变量进行7:3的分层抽样，返回行索引向量 p = 0.7为按照7：3进行抽样 # 参数list表示返回值是否为列表 index &lt;- createDataPartition(hr_model$left, p = 0.7, list = F) # 以index为索引的数据为训练集 # 剩余的数据为测试集 trainData &lt;- hr_model[index, ] testData &lt;- hr_model[-index, ] 3.2.4 实际建模 使用carte包中的train函数对训练集进行5折交叉验证建立回归树模型。 # left~. 代表因变量left与所有自变量进行建模。 rpartmodel &lt;- train(left~., data = trainData, trControl = train_control, method = &quot;rpart&quot;) 利用建立好的模型rpartmodel对测试集进行预测。 # testdata[-7]剔除left列。 predRpart &lt;- predict(rpartmodel, testData[-7]) 建立混淆矩阵，验证建立的模型。 conPart &lt;- table(predRpart, testData$left) conPart ## ## predRpart 0 1 ## 0 2246 72 ## 1 51 528 混淆矩阵：混淆矩阵的每一列代表了预测类别，每一列的总数表示预测为该类别的数据的数目；每一行代表了数据的真实归属类别，每一行的数据总数表示该类别的数据实例的数目。根据查全率和查准率两个参数判断模型拟合结果是否够好。 混淆矩阵的查准率和查全率是两个重要的参数，具体计算公式如下式(3.1)： \\[\\begin{align} 查准率=\\frac{真正例}{真正例+假正例} \\\\ 查全率=\\frac{真正例}{真正例+假反例} \\tag{3.1} \\end{align}\\] 根据混淆矩阵结果，可以得到回归树模型的： 查准率为91.19 %。 查全率为88 %。 回归模型的拟合效果不错。 3.3 建模预测2-朴素贝叶斯 建模步骤与第3.2小结基本相同，下面只列出代码及结果。 nbModel &lt;- train(left~., data = trainData, trControl = train_control, method = &quot;nb&quot;) predNb &lt;- predict(nbModel, testData[-7]) conNb &lt;- table(predNb, testData$left) conNb ## ## predNb 0 1 ## 0 2248 146 ## 1 49 454 根据公式(3.1)，计算得到朴素贝叶斯模型的： 查准率为90.26 %。 查全率为75.67 %。 通过两种模型的评估，我们发现回归树模型的拟合度比朴素贝叶斯更好，所以接下来我们采用回归数模型进行进一步分析。 3.4 模型评估及应用 本部分使用ROC曲线的方法对模型进行评估。具体步骤如下： 根据建模预测的结果对样例进行排序。 按照排序逐个把样本作为正例进行预测，每次计算出两个重要的值（分别为假正例率和真正例率，具体计算公式见下式(3.2)。 \\[\\begin{align} 假正例率 = \\frac{假正例}{假正例+真反例} \\\\ 真正例率 = \\frac{真正例}{真正例+假反例}(查全率) \\tag{3.2} \\end{align}\\] 分别以计算的两个值作为横纵坐标，就得到了ROC曲线。 ROC曲线的评估方法： 如果一个模型的ROC曲线被另一个模型的ROC曲线完全“包住”，说明后者的性能优于前者。 如果两个ROC曲线发生交叉，则难以一般性的断言两者的优劣。如果一定要进行比较，较为合理的判断依据是比较ROC曲线下的面积（AUC）。一般情况下，如果 3.4.1 ROC曲线绘制 绘制ROC曲线的数据必须是数值型。 predRpart &lt;- as.numeric(as.character(predRpart)) predNb &lt;- as.numeric(predNb) 转换后绘制图形。 # 获取后续绘图使用的信息 rocPart &lt;- roc(testData$left, predRpart) # 计算两个关键值 # 假正例率 specificityRp &lt;- rocPart$specificities # 查全率，即真正利率 sensitivityRp &lt;- rocPart$sensitivities # 获取后续绘图使用的信息 rocNb &lt;- roc(testData$left, predNb) # 计算两个关键值 # 假正例率 specificityNb &lt;- rocNb$specificities # 查全率，即真正利率 sensitivityNb &lt;- rocNb$sensitivities 绘制ROC图形。 # 定义data = NULL声明未用任何数据 pRpart &lt;- ggplot(data = NULL, aes( x = 1 - specificityRp, y = sensitivityRp)) + geom_line(color = &quot;red&quot;) + geom_abline() + annotate(&quot;text&quot;, x = 0.4, y = 0.5, label = paste(&quot;AUC = &quot;, round(rocPart$auc, 3))) + theme_bw() + labs(x = &quot;1 - Specificity&quot;, y = &quot;Sensitivities&quot;) pNb &lt;- ggplot(data = NULL, aes( x = 1 - specificityNb, y = sensitivityNb)) + geom_line(color = &quot;red&quot;) + geom_abline() + annotate(&quot;text&quot;, x = 0.4, y = 0.5, label = paste(&quot;AUC = &quot;, round(rocNb$auc, 3))) + theme_bw() + labs(x = &quot;1 - Specificity&quot;, y = &quot; &quot;) pRpart|pNb 图 3.3: 回归树模型和朴素贝叶斯模型ROC曲线 (ref:fig-ROC) 从AUC值来看，同样是回归树模型的拟合效果好于朴素贝叶斯模型。 3.5 模型应用 使用回归树模型预测分类的概率，绘制交互预测表 # type = &quot;prob&quot;表示结果显示为概率 # predEnd &lt;- predict(rpartmodel, testData[-7], # type = &quot;prob&quot;) # 合并预测结果及概率 # dataEnd &lt;- cbind(round(predEnd, 3), predRpart) # 重命名预测结果表列名。 # names(dataEnd) &lt;- c(&quot;pred.0&quot;, &quot;pred.1&quot;, &quot;pred&quot;) # head(dataEnd) # 生成交互式表格 # datatable(dataEnd) 3.6 mlr3建模 3.6.1 回归树模型 library(mlr3verse) 建立任务 hr &lt;- read.csv(&quot;data/HR_comma_sep.csv&quot;) hr$left &lt;- factor(hr$left) hr$salary &lt;- factor(hr$salary) hr$sales &lt;- factor(hr$sales) hr_model &lt;- hr_model &lt;- hr %&gt;% filter(last_evaluation &gt;= 0.70 | time_spend_company&gt;=4 | number_project&gt;=5) task_hr &lt;- TaskClassif$new(id = &quot;left&quot;, backend = hr_model, target = &quot;left&quot;) task_hr ## &lt;TaskClassif:left&gt; (10394 x 10) ## * Target: left ## * Properties: twoclass ## * Features (9): ## - int (5): Work_accident, average_montly_hours, ## number_project, promotion_last_5years, time_spend_company ## - dbl (2): last_evaluation, satisfaction_level ## - fct (2): salary, sales 定义学习器 learner_rpart &lt;- lrn(&quot;classif.rpart&quot;, predict_type = &quot;prob&quot;) 基础训练+预测 set.seed(1234) # 划分训练集和测试集 train_set &lt;- sample(task_hr$nrow, 0.7 * task_hr$nrow) test_set &lt;- setdiff(seq_len(task_hr$nrow), train_set) # 训练模型 learner_rpart$train(task_hr, row_ids = train_set) # 数据预测 prediction_rpart &lt;- learner_rpart$predict(task_hr, row_ids = test_set) # 建立混淆矩阵 prediction_rpart$confusion ## truth ## response 0 1 ## 0 2483 85 ## 1 17 534 # 评估模型准确性 measure_rpart &lt;- msr(&quot;classif.acc&quot;) prediction_rpart$score(measure_rpart) ## classif.acc ## 0.9672972 重采样 # 自动重采样 ## 定义重采样方法:5折交叉 resampling_rpart &lt;- rsmp(&quot;cv&quot;, folds = 5L) ## 应用重采样方法 rr_rpart &lt;- resample(task_hr, learner_rpart, resampling_rpart) ## INFO [11:16:39.480] [mlr3] Applying learner &#39;classif.rpart&#39; on task &#39;left&#39; (iter 1/5) ## INFO [11:16:39.591] [mlr3] Applying learner &#39;classif.rpart&#39; on task &#39;left&#39; (iter 3/5) ## INFO [11:16:39.651] [mlr3] Applying learner &#39;classif.rpart&#39; on task &#39;left&#39; (iter 5/5) ## INFO [11:16:39.701] [mlr3] Applying learner &#39;classif.rpart&#39; on task &#39;left&#39; (iter 2/5) ## INFO [11:16:39.756] [mlr3] Applying learner &#39;classif.rpart&#39; on task &#39;left&#39; (iter 4/5) ## 每次重采样建模评分 rr_rpart$score(measure_rpart) ## task task_id learner learner_id ## 1: &lt;TaskClassif[50]&gt; left &lt;LearnerClassifRpart[38]&gt; classif.rpart ## 2: &lt;TaskClassif[50]&gt; left &lt;LearnerClassifRpart[38]&gt; classif.rpart ## 3: &lt;TaskClassif[50]&gt; left &lt;LearnerClassifRpart[38]&gt; classif.rpart ## 4: &lt;TaskClassif[50]&gt; left &lt;LearnerClassifRpart[38]&gt; classif.rpart ## 5: &lt;TaskClassif[50]&gt; left &lt;LearnerClassifRpart[38]&gt; classif.rpart ## resampling resampling_id iteration ## 1: &lt;ResamplingCV[20]&gt; cv 1 ## 2: &lt;ResamplingCV[20]&gt; cv 2 ## 3: &lt;ResamplingCV[20]&gt; cv 3 ## 4: &lt;ResamplingCV[20]&gt; cv 4 ## 5: &lt;ResamplingCV[20]&gt; cv 5 ## prediction classif.acc ## 1: &lt;PredictionClassif[20]&gt; 0.9639250 ## 2: &lt;PredictionClassif[20]&gt; 0.9735450 ## 3: &lt;PredictionClassif[20]&gt; 0.9610390 ## 4: &lt;PredictionClassif[20]&gt; 0.9672920 ## 5: &lt;PredictionClassif[20]&gt; 0.9682387 ## 将重采样的模型进行聚合并评分 rr_rpart$aggregate(measure_rpart) ## classif.acc ## 0.9668079 得到的回归树模型最终的拟合准确率为96.75%，拟合效果不错 3.6.2 朴素贝叶斯模型 建立任务 hr &lt;- read.csv(&quot;data/HR_comma_sep.csv&quot;) hr$left &lt;- factor(hr$left) hr$salary &lt;- factor(hr$salary) hr$sales &lt;- factor(hr$sales) hr_model &lt;- hr_model &lt;- hr %&gt;% filter(last_evaluation &gt;= 0.70 | time_spend_company&gt;=4 | number_project&gt;=5) task_hr_nb &lt;- TaskClassif$new(id = &quot;left&quot;, backend = hr_model, target = &quot;left&quot;) task_hr_nb ## &lt;TaskClassif:left&gt; (10394 x 10) ## * Target: left ## * Properties: twoclass ## * Features (9): ## - int (5): Work_accident, average_montly_hours, ## number_project, promotion_last_5years, time_spend_company ## - dbl (2): last_evaluation, satisfaction_level ## - fct (2): salary, sales 选择学习器 learner_nb &lt;- lrn(&quot;classif.naive_bayes&quot;, predict_type = &quot;prob&quot;) 划分训练集和测试集 set.seed(1234) train_set &lt;- sample(task_hr_nb$nrow, task_hr_nb$nrow * 0.7) test_set &lt;- setdiff(seq_len(task_hr_nb$nrow), train_set) 模型训练和预测 # 模型训练 learner_nb$train(task_hr_nb, row_ids = train_set) learner_nb$model # 查看训练好的模型 ## ## Naive Bayes Classifier for Discrete Predictors ## ## Call: ## naiveBayes.default(x = x, y = y) ## ## A-priori probabilities: ## y ## 0 1 ## 0.8074227 0.1925773 ## ## Conditional probabilities: ## Work_accident ## y [,1] [,2] ## 0 0.1813075 0.3853055 ## 1 0.0442541 0.2057326 ## ## average_montly_hours ## y [,1] [,2] ## 0 201.0504 45.49460 ## 1 254.7744 34.45457 ## ## last_evaluation ## y [,1] [,2] ## 0 0.7657457 0.1552908 ## 1 0.8763241 0.1013923 ## ## number_project ## y [,1] [,2] ## 0 3.959993 1.023111 ## 1 5.244825 1.156665 ## ## promotion_last_5years ## y [,1] [,2] ## 0 0.028770855 0.16717611 ## 1 0.002141328 0.04624142 ## ## salary ## y high low medium ## 0 0.10316650 0.44722506 0.44960844 ## 1 0.01641685 0.60314061 0.38044254 ## ## sales ## y accounting hr IT management marketing ## 0 0.04902962 0.04324140 0.08614232 0.04971059 0.05498808 ## 1 0.05424697 0.04782298 0.07994290 0.02997859 0.04710921 ## sales ## y product_mng RandD sales support technical ## 0 0.06179775 0.05720123 0.27221655 0.15253660 0.17313585 ## 1 0.05353319 0.03783012 0.26766595 0.15488936 0.22698073 ## ## satisfaction_level ## y [,1] [,2] ## 0 0.6622302 0.2274002 ## 1 0.4660742 0.3465198 ## ## time_spend_company ## y [,1] [,2] ## 0 3.654069 1.6892539 ## 1 4.559600 0.7978871 # 模型预测 prediction_nb &lt;- learner_nb$predict(task_hr_nb, row_ids = test_set) prediction_nb # 查看预测结果 ## &lt;PredictionClassif&gt; for 3119 observations: ## row_ids truth response prob.0 prob.1 ## 2 1 1 0.0002953563 0.9997046 ## 3 1 1 0.1080414241 0.8919586 ## 4 1 1 0.0031520108 0.9968480 ## --- ## 10388 1 1 0.0423579034 0.9576421 ## 10390 1 0 0.5807408182 0.4192592 ## 10392 1 1 0.0014815943 0.9985184 模型评估 prediction_nb$confusion ## truth ## response 0 1 ## 0 2243 100 ## 1 257 519 measure_nb &lt;- msr(&quot;classif.acc&quot;) prediction_nb$score(measure_nb) # 预测精度 ## classif.acc ## 0.8855402 重采样 resampling_nb &lt;- rsmp(&quot;cv&quot;, folds = 5L) rr_nb &lt;- resample(task_hr_nb, learner_nb, resampling_nb) ## INFO [11:16:41.346] [mlr3] Applying learner &#39;classif.naive_bayes&#39; on task &#39;left&#39; (iter 1/5) ## INFO [11:16:41.697] [mlr3] Applying learner &#39;classif.naive_bayes&#39; on task &#39;left&#39; (iter 3/5) ## INFO [11:16:42.052] [mlr3] Applying learner &#39;classif.naive_bayes&#39; on task &#39;left&#39; (iter 5/5) ## INFO [11:16:42.401] [mlr3] Applying learner &#39;classif.naive_bayes&#39; on task &#39;left&#39; (iter 2/5) ## INFO [11:16:42.730] [mlr3] Applying learner &#39;classif.naive_bayes&#39; on task &#39;left&#39; (iter 4/5) rr_nb$score(measure_nb) ## task task_id learner ## 1: &lt;TaskClassif[50]&gt; left &lt;LearnerClassifNaiveBayes[36]&gt; ## 2: &lt;TaskClassif[50]&gt; left &lt;LearnerClassifNaiveBayes[36]&gt; ## 3: &lt;TaskClassif[50]&gt; left &lt;LearnerClassifNaiveBayes[36]&gt; ## 4: &lt;TaskClassif[50]&gt; left &lt;LearnerClassifNaiveBayes[36]&gt; ## 5: &lt;TaskClassif[50]&gt; left &lt;LearnerClassifNaiveBayes[36]&gt; ## learner_id resampling resampling_id iteration ## 1: classif.naive_bayes &lt;ResamplingCV[20]&gt; cv 1 ## 2: classif.naive_bayes &lt;ResamplingCV[20]&gt; cv 2 ## 3: classif.naive_bayes &lt;ResamplingCV[20]&gt; cv 3 ## 4: classif.naive_bayes &lt;ResamplingCV[20]&gt; cv 4 ## 5: classif.naive_bayes &lt;ResamplingCV[20]&gt; cv 5 ## prediction classif.acc ## 1: &lt;PredictionClassif[20]&gt; 0.8840789 ## 2: &lt;PredictionClassif[20]&gt; 0.8951419 ## 3: &lt;PredictionClassif[20]&gt; 0.8946609 ## 4: &lt;PredictionClassif[20]&gt; 0.8869649 ## 5: &lt;PredictionClassif[20]&gt; 0.8695861 rr_nb$aggregate(measure_nb) ## classif.acc ## 0.8860865 通过两种模型的评估，我们发现回归树模型的拟合度比朴素贝叶斯更好，与传统方法得出的结论一致。 3.6.3 利用mlr3进行ROC曲线绘制 library(mlr3viz) roc_nb &lt;- autoplot(prediction_nb, type = &quot;roc&quot;) roc_rpart &lt;- autoplot(prediction_rpart, type = &quot;roc&quot;) roc_rpart|roc_nb ### 模型应用 使用回归树模型预测分类概率，绘制表格交互表 autoplot(prediction_rpart) # type = &quot;prob&quot;表示结果显示为概率 predEnd &lt;- predict(rpartmodel, testData[-7], type = &quot;prob&quot;) # 合并预测结果及概率 dataEnd &lt;- cbind(round(predEnd, 3), predRpart) # 重命名预测结果表列名。 names(dataEnd) &lt;- c(&quot;pred.0&quot;, &quot;pred.1&quot;, &quot;pred&quot;) # head(dataEnd) # 生成交互式表格 # datatable(dataEnd) 分层抽样法也叫类型抽样法。它是从一个可以分成不同子总体（或称为层）的总体中，按规定的比例从不同层中随机抽取样品（个体）的方法。这种方法的优点是，样本的代表性比较好，抽样误差比较小。缺点是抽样手续较简单随机抽样还要繁杂些。定量调查中的分层抽样是一种卓越的概率抽样方式，在调查中经常被使用。↩︎ "],["4-creditcard.html", "第 4 章 信用卡欺诈识别 4.1 数据变量说明 4.2 数据预处理 4.3 描述性分析 4.4 自动参数调整调参-使用caret包 4.5 kNN建模 4.6 模型评估", " 第 4 章 信用卡欺诈识别 4.1 数据变量说明 变量说明 class变量：0表示非欺诈，1表示非欺诈。 4.2 数据预处理 card &lt;- read_csv(&quot;data/creditcard.csv&quot;) card &lt;- as.data.frame(card) str(card) # 查看数据基本结构和数据类型 ## &#39;data.frame&#39;: 284807 obs. of 31 variables: ## $ Time : num 0 0 1 1 2 2 4 7 7 9 ... ## $ V1 : num -1.36 1.192 -1.358 -0.966 -1.158 ... ## $ V2 : num -0.0728 0.2662 -1.3402 -0.1852 0.8777 ... ## $ V3 : num 2.536 0.166 1.773 1.793 1.549 ... ## $ V4 : num 1.378 0.448 0.38 -0.863 0.403 ... ## $ V5 : num -0.3383 0.06 -0.5032 -0.0103 -0.4072 ... ## $ V6 : num 0.4624 -0.0824 1.8005 1.2472 0.0959 ... ## $ V7 : num 0.2396 -0.0788 0.7915 0.2376 0.5929 ... ## $ V8 : num 0.0987 0.0851 0.2477 0.3774 -0.2705 ... ## $ V9 : num 0.364 -0.255 -1.515 -1.387 0.818 ... ## $ V10 : num 0.0908 -0.167 0.2076 -0.055 0.7531 ... ## $ V11 : num -0.552 1.613 0.625 -0.226 -0.823 ... ## $ V12 : num -0.6178 1.0652 0.0661 0.1782 0.5382 ... ## $ V13 : num -0.991 0.489 0.717 0.508 1.346 ... ## $ V14 : num -0.311 -0.144 -0.166 -0.288 -1.12 ... ## $ V15 : num 1.468 0.636 2.346 -0.631 0.175 ... ## $ V16 : num -0.47 0.464 -2.89 -1.06 -0.451 ... ## $ V17 : num 0.208 -0.115 1.11 -0.684 -0.237 ... ## $ V18 : num 0.0258 -0.1834 -0.1214 1.9658 -0.0382 ... ## $ V19 : num 0.404 -0.146 -2.262 -1.233 0.803 ... ## $ V20 : num 0.2514 -0.0691 0.525 -0.208 0.4085 ... ## $ V21 : num -0.01831 -0.22578 0.248 -0.1083 -0.00943 ... ## $ V22 : num 0.27784 -0.63867 0.77168 0.00527 0.79828 ... ## $ V23 : num -0.11 0.101 0.909 -0.19 -0.137 ... ## $ V24 : num 0.0669 -0.3398 -0.6893 -1.1756 0.1413 ... ## $ V25 : num 0.129 0.167 -0.328 0.647 -0.206 ... ## $ V26 : num -0.189 0.126 -0.139 -0.222 0.502 ... ## $ V27 : num 0.13356 -0.00898 -0.05535 0.06272 0.21942 ... ## $ V28 : num -0.0211 0.0147 -0.0598 0.0615 0.2152 ... ## $ Amount: num 149.62 2.69 378.66 123.5 69.99 ... ## $ Class : num 0 0 0 0 0 0 0 0 0 0 ... summary(card) # 查看数据的主要描述性统计量 ## Time V1 V2 ## Min. : 0 Min. :-56.40751 Min. :-72.71573 ## 1st Qu.: 54202 1st Qu.: -0.92037 1st Qu.: -0.59855 ## Median : 84692 Median : 0.01811 Median : 0.06549 ## Mean : 94814 Mean : 0.00000 Mean : 0.00000 ## 3rd Qu.:139321 3rd Qu.: 1.31564 3rd Qu.: 0.80372 ## Max. :172792 Max. : 2.45493 Max. : 22.05773 ## V3 V4 V5 ## Min. :-48.3256 Min. :-5.68317 Min. :-113.74331 ## 1st Qu.: -0.8904 1st Qu.:-0.84864 1st Qu.: -0.69160 ## Median : 0.1799 Median :-0.01985 Median : -0.05434 ## Mean : 0.0000 Mean : 0.00000 Mean : 0.00000 ## 3rd Qu.: 1.0272 3rd Qu.: 0.74334 3rd Qu.: 0.61193 ## Max. : 9.3826 Max. :16.87534 Max. : 34.80167 ## V6 V7 V8 ## Min. :-26.1605 Min. :-43.5572 Min. :-73.21672 ## 1st Qu.: -0.7683 1st Qu.: -0.5541 1st Qu.: -0.20863 ## Median : -0.2742 Median : 0.0401 Median : 0.02236 ## Mean : 0.0000 Mean : 0.0000 Mean : 0.00000 ## 3rd Qu.: 0.3986 3rd Qu.: 0.5704 3rd Qu.: 0.32735 ## Max. : 73.3016 Max. :120.5895 Max. : 20.00721 ## V9 V10 V11 ## Min. :-13.43407 Min. :-24.58826 Min. :-4.79747 ## 1st Qu.: -0.64310 1st Qu.: -0.53543 1st Qu.:-0.76249 ## Median : -0.05143 Median : -0.09292 Median :-0.03276 ## Mean : 0.00000 Mean : 0.00000 Mean : 0.00000 ## 3rd Qu.: 0.59714 3rd Qu.: 0.45392 3rd Qu.: 0.73959 ## Max. : 15.59500 Max. : 23.74514 Max. :12.01891 ## V12 V13 V14 ## Min. :-18.6837 Min. :-5.79188 Min. :-19.2143 ## 1st Qu.: -0.4056 1st Qu.:-0.64854 1st Qu.: -0.4256 ## Median : 0.1400 Median :-0.01357 Median : 0.0506 ## Mean : 0.0000 Mean : 0.00000 Mean : 0.0000 ## 3rd Qu.: 0.6182 3rd Qu.: 0.66251 3rd Qu.: 0.4931 ## Max. : 7.8484 Max. : 7.12688 Max. : 10.5268 ## V15 V16 V17 ## Min. :-4.49894 Min. :-14.12985 Min. :-25.16280 ## 1st Qu.:-0.58288 1st Qu.: -0.46804 1st Qu.: -0.48375 ## Median : 0.04807 Median : 0.06641 Median : -0.06568 ## Mean : 0.00000 Mean : 0.00000 Mean : 0.00000 ## 3rd Qu.: 0.64882 3rd Qu.: 0.52330 3rd Qu.: 0.39968 ## Max. : 8.87774 Max. : 17.31511 Max. : 9.25353 ## V18 V19 V20 ## Min. :-9.498746 Min. :-7.213527 Min. :-54.49772 ## 1st Qu.:-0.498850 1st Qu.:-0.456299 1st Qu.: -0.21172 ## Median :-0.003636 Median : 0.003735 Median : -0.06248 ## Mean : 0.000000 Mean : 0.000000 Mean : 0.00000 ## 3rd Qu.: 0.500807 3rd Qu.: 0.458949 3rd Qu.: 0.13304 ## Max. : 5.041069 Max. : 5.591971 Max. : 39.42090 ## V21 V22 V23 ## Min. :-34.83038 Min. :-10.933144 Min. :-44.80774 ## 1st Qu.: -0.22839 1st Qu.: -0.542350 1st Qu.: -0.16185 ## Median : -0.02945 Median : 0.006782 Median : -0.01119 ## Mean : 0.00000 Mean : 0.000000 Mean : 0.00000 ## 3rd Qu.: 0.18638 3rd Qu.: 0.528554 3rd Qu.: 0.14764 ## Max. : 27.20284 Max. : 10.503090 Max. : 22.52841 ## V24 V25 V26 ## Min. :-2.83663 Min. :-10.29540 Min. :-2.60455 ## 1st Qu.:-0.35459 1st Qu.: -0.31715 1st Qu.:-0.32698 ## Median : 0.04098 Median : 0.01659 Median :-0.05214 ## Mean : 0.00000 Mean : 0.00000 Mean : 0.00000 ## 3rd Qu.: 0.43953 3rd Qu.: 0.35072 3rd Qu.: 0.24095 ## Max. : 4.58455 Max. : 7.51959 Max. : 3.51735 ## V27 V28 Amount ## Min. :-22.565679 Min. :-15.43008 Min. : 0.00 ## 1st Qu.: -0.070840 1st Qu.: -0.05296 1st Qu.: 5.60 ## Median : 0.001342 Median : 0.01124 Median : 22.00 ## Mean : 0.000000 Mean : 0.00000 Mean : 88.35 ## 3rd Qu.: 0.091045 3rd Qu.: 0.07828 3rd Qu.: 77.17 ## Max. : 31.612198 Max. : 33.84781 Max. :25691.16 ## Class ## Min. :0.000000 ## 1st Qu.:0.000000 ## Median :0.000000 ## Mean :0.001728 ## 3rd Qu.:0.000000 ## Max. :1.000000 round(prop.table(table(card$Class)),4)# 查看数据类别比例 ## ## 0 1 ## 0.9983 0.0017 4.2.1 分层抽样 处理类别不平衡的数据需要了解的几个概念点： 类别不平衡：指分类任务重不同类别的训练样本树木差别很大的情况。 欠抽样：指某类（样本数占比很大）的样本中抽取出与另一类样本（样本数占比很小）个数一样的样本。即从大类别中抽取与小类别数目一样的样本。 过抽样：指针对样本数占比很小的类别，重新塑造一些数据，使其与另一类数据接近。 对数据进行一些基本转化。 # 把Time列转换为小时 card &lt;- card %&gt;% mutate(Time_Hour = round(card[, 1]/3600, 0)) # 把Class列转化为因子型 card$Class &lt;- factor(card$Class) card_1 &lt;- card[card$Class == &quot;1&quot;, ] # 欺诈样本 card_0 &lt;- card[card$Class == &quot;0&quot;, ] # 非欺诈样本 随机抽取与诈骗样本个数相同的非欺诈样本数据，并与元欺诈样本合并为新的数据。此处使用的欠抽样的方法。 set.seed(1234) index &lt;- sample(x = 1:nrow(card_0), size = nrow(card_1)) card_0_new &lt;- card_0[index, ] card_end &lt;- rbind(card_0_new, card_1) # 剔除Time列，用Time_Hour列代替。everything()选择所有的变量 card_end &lt;- card_end[-1] %&gt;% select(Time_Hour, everything()) 按照类别进行分层抽样，建立训练集和测试集。 set.seed(1234) # 按照新数据的目标变量进行8：2 index2 &lt;- createDataPartition(card_end$Class, p = 0.8, list = F) train_data &lt;- card_end[index2, ] # 创建训练集 test_data &lt;- card_end[-index2, ] # 创建测试集 # 验证抽样结果，统计三个数据集中正反样本比例是否一致 table(card_end$Class) ## ## 0 1 ## 492 492 table(train_data$Clas) ## ## 0 1 ## 394 394 table(test_data$Class) ## ## 0 1 ## 98 98 4.2.2 标准化 standard &lt;- preProcess(card_end, method = &quot;range&quot;) card_s &lt;- predict(standard, card_end) train_data2 &lt;- card_s[index2, ] test_data2 &lt;- card_s[-index2, ] 4.3 描述性分析 4.3.1 不同时间诈骗次数-条形图 ggplot(card_1, aes(x = factor(Time_Hour), fill = factor(Time_Hour)))+ geom_bar(stat = &quot;count&quot;) + theme_classic() + labs(x = &quot;Time_Hour&quot;, y = &quot;Count&quot;) + theme(legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 90, vjust = 0.5)) 图 4.1: 不同时间诈骗次数 由图4.1可知： 第一天（024h）的诈骗总次数大于第二天（2548h）。 诈骗发生次数最多的三个时间段分别是： 第二天凌晨2点左右。 第一天上午11点左右。 第一天凌晨2点左右。 4.3.2 不同时间诈骗金额-箱线图 ggplot(card_1, aes(x = factor(Time_Hour), y = Amount, fill = factor(Time_Hour))) + geom_boxplot() + geom_hline(aes(yintercept =250, color = &quot;red&quot;)) + annotate(&quot;text&quot;, x = 6, y = 500, label = &quot;Amount = 250&quot;, color = &quot;red&quot;) + geom_curve(x = 3, y = 450, xend = 5, yend = 250, angle = 25, color = &quot;red&quot;, arrow = arrow(length = unit(0.25, &quot;cm&quot;))) + theme_classic() + labs(x = &quot;Time_Hour&quot;, y = &quot;Amount&quot;) + theme(legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 90, vjust = 0.5)) 图 4.2: 不同时间诈骗金额 由图4.2可知： 诈骗金额最多的一次发生在第二天下午1点作用（34h），诈骗金额达到2000欧元左右。 诈骗金额普遍在250欧元之内。 4.3.3 不同时间平均诈骗金额-条形图 # 提取所需数据 card_1_mean &lt;- card_1 %&gt;% group_by(Time_Hour) %&gt;% summarise(MeanAmount = mean(Amount)) ggplot(card_1_mean, aes(x = factor(Time_Hour), y = MeanAmount, fill = factor(Time_Hour))) + geom_bar(stat = &quot;identity&quot;) + geom_hline(aes(yintercept = 200, color = &quot;red&quot;)) + annotate(&quot;text&quot;, x = 26, y = 240, label = &quot;Mean_Amount = 200&quot;, color = &quot;red&quot;) + geom_curve(x = 23, y = 220, xend = 24, yend = 200, curvature = 0.3, arrow = arrow(length = unit(0.2, &quot;cm&quot;)), color = &quot;red&quot;) + theme_classic() + theme(legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 90, vjust = 0.5)) + labs(x = &quot;Time_Hour&quot;, y = &quot;Mean_Amount&quot;) 图 4.3: 不同时间平均诈骗金额-条形图 如图4.3所示： 平均诈骗金额最多的时间段为第二天下午1点，此时间点包含诈骗金额最多的观测。 总体而言，平均诈骗金额普遍在200欧元以内。 4.4 自动参数调整调参-使用caret包 参数调整是提升模型性能的一个重要过程，而大多数机器学习算法都可以至少调整一个参数。复杂的模型通常可以通过调节多个参数值来调整模型从而达到更好的拟合效果。 e.g.，寻找最合适的k值来调整k近邻模型、调节隐藏层层数和隐藏层的节点数来优化神经网络模型；又如支持向量机模型中的调节核函数以及“软边界”惩罚大小等优化。 值得注意的是，如果对所有可能的调参选项均进行尝试，其复杂度非常大，耗时且不科学，需要一种更系统、科学的方式对模型的参数进行调节。 下表列举了使用caret包进行自动参数调整的模型及其参数： 模型 方法名 参数 k近邻 knn k 朴素贝叶斯 nb fL、usekernel 决策树 C5.0 model、trials、winnow OneR规则学习器 OneR 无 线性回归 lm 无 回归树 rpart cp 模型树 M5 pruned、smoothed、rules 支持向量机（径向基核） svmRadial C, sigma 随机森林 rf mtry 更多可调节参数的详细信息 本案例我们使用knn和随机森林两个模型。 我们用iris数据对自动调参的步骤进行演示。 创建简单的调整的模型 set.seed(1234) m_C50 &lt;- train(Species~., data = iris, method = &quot;C5.0&quot;) m_C50 ## C5.0 ## ## 150 samples ## 4 predictor ## 3 classes: &#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39; ## ## No pre-processing ## Resampling: Bootstrapped (25 reps) ## Summary of sample sizes: 150, 150, 150, 150, 150, 150, ... ## Resampling results across tuning parameters: ## ## model winnow trials Accuracy Kappa ## rules FALSE 1 0.9353579 0.9019696 ## rules FALSE 10 0.9370844 0.9045424 ## rules FALSE 20 0.9325835 0.8976068 ## rules TRUE 1 0.9382311 0.9062975 ## rules TRUE 10 0.9407392 0.9099910 ## rules TRUE 20 0.9385430 0.9066136 ## tree FALSE 1 0.9347127 0.9009924 ## tree FALSE 10 0.9369888 0.9044013 ## tree FALSE 20 0.9332286 0.8985820 ## tree TRUE 1 0.9375860 0.9053246 ## tree TRUE 10 0.9399845 0.9088007 ## tree TRUE 20 0.9392443 0.9076915 ## ## Accuracy was used to select the optimal model using the ## largest value. ## The final values used for the model were trials = 10, model = ## rules and winnow = TRUE. 由上面的结果可以看出，基于model、trials和winnow三个参数，建立并测试了12个决策树（C5.0）模型，每个模型均给出了精度及Kappa统计量，最下方同时展示了最佳候选模型所对应的参数值。其中Kappa统计量用来衡量模型的稳定性： 很差的一致性： &lt;0.2 尚可的一致性： 0.2~0.4 中等的一致性： 0.4~0.6 不错的一致性： 0.6~0.8 很好的一致性： 0.8~1 定制调参 使用trainCotrol()函数创建一些列配置选项，这些选项考虑了包括重抽样策略以及用于选择最佳模型的度量这些模型评价标准的管理。主要专注于两个重要的参数：method和selectionFuncio。 method为冲抽样的方法。 selectionFunction参数可以设定一个函数，用于在各个候选者中选取特定的模型，共3个函数： best函数：默认选项，简单的选择具有最好的某特定度量值的候选者。 oneSE函数：选择最好性能标准差之内的最简单的候选者。 Tolerance函数：选择某个用户制定比例之内最简单的候选者。 set.seed(1234) model_rf &lt;- train(Class~., data = train_data, method = &quot;rf&quot;, trControl = trainControl(method = &quot;cv&quot;, number = 5, selectionFunction = &quot;oneSE&quot;)) model_rf ## Random Forest ## ## 788 samples ## 30 predictor ## 2 classes: &#39;0&#39;, &#39;1&#39; ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 631, 631, 630, 630, 630 ## Resampling results across tuning parameters: ## ## mtry Accuracy Kappa ## 2 0.9276465 0.8552977 ## 16 0.9314521 0.8628921 ## 30 0.9276627 0.8553120 ## ## Accuracy was used to select the optimal model using the one ## SE rule. ## The final value used for the model was mtry = 2. # 进行预测 pred_rf &lt;- predict(model_rf, test_data[-31]) # 建立混淆矩阵 confusionMatrix(data = pred_rf, reference = test_data$Class, positive = &quot;1&quot;) ## Confusion Matrix and Statistics ## ## Reference ## Prediction 0 1 ## 0 98 7 ## 1 0 91 ## ## Accuracy : 0.9643 ## 95% CI : (0.9278, 0.9855) ## No Information Rate : 0.5 ## P-Value [Acc &gt; NIR] : &lt; 2e-16 ## ## Kappa : 0.9286 ## ## Mcnemar&#39;s Test P-Value : 0.02334 ## ## Sensitivity : 0.9286 ## Specificity : 1.0000 ## Pos Pred Value : 1.0000 ## Neg Pred Value : 0.9333 ## Prevalence : 0.5000 ## Detection Rate : 0.4643 ## Detection Prevalence : 0.4643 ## Balanced Accuracy : 0.9643 ## ## &#39;Positive&#39; Class : 1 ## plot(varImp(model_rf)) # 查看变量的重要性 4.5 kNN建模 4.5.1 原理 knn，即邻近分类器，就是把未标记的案例归类为与他们最相似的带有标记的案例所在的类。 算法流程： 依次计算测试样本与哥哥训练样本间的距离（常用欧式距离）； 将这些距离按照升序排列； 选取距离最小的k（3~10）个训练样本点； 确定这k个点中不同类别的占比； 返回这k个点中占比最大的类别作为测试样本的预测分类。 4.5.2 模型建立 # 创建空向量 results &lt;- c() for (i in 3:10){ set.seed(1234) pred_knn &lt;- knn(train_data2[-31], test_data2[-31], train_data2$Class, i) Table &lt;- table(pred_knn, test_data2$Class) # 得到混淆矩阵 accuracy &lt;- sum(diag(Table))/sum(Table) # diag()提取对角线的值 results &lt;- c(results, accuracy) } ggplot(as.data.frame(results), aes(x = 3:10, y = results)) + geom_point()+ geom_line() + theme_bw() + labs(xlab = &quot; &quot;) set.seed(1234) pred_knn &lt;- knn(train = train_data2[-31], test = test_data2[-31], cl = train_data2$Class, k = 4) confusionMatrix(pred_knn,test_data2$Class, positive = &quot;1&quot;) ## Confusion Matrix and Statistics ## ## Reference ## Prediction 0 1 ## 0 97 7 ## 1 1 91 ## ## Accuracy : 0.9592 ## 95% CI : (0.9212, 0.9822) ## No Information Rate : 0.5 ## P-Value [Acc &gt; NIR] : &lt;2e-16 ## ## Kappa : 0.9184 ## ## Mcnemar&#39;s Test P-Value : 0.0771 ## ## Sensitivity : 0.9286 ## Specificity : 0.9898 ## Pos Pred Value : 0.9891 ## Neg Pred Value : 0.9327 ## Prevalence : 0.5000 ## Detection Rate : 0.4643 ## Detection Prevalence : 0.4694 ## Balanced Accuracy : 0.9592 ## ## &#39;Positive&#39; Class : 1 ## 4.6 模型评估 # 建立一个数据框，将两个模型预测的结果和真实值放进去。并展示不同预测值 pred_results &lt;- data.frame(knn = pred_knn, rf = pred_rf, class = test_data$Class) index3 &lt;- which(pred_results$knn != pred_rf) pred_results[index3, ] ## knn rf class ## 25 1 0 0 ## 159 1 0 1 ## 160 0 1 1 ## 168 1 0 1 ## 182 0 1 1 "],["5-Student-performance-level.html", "第 5 章 学生成绩水平分类 5.1 数据变量说明 5.2 描述性分析 5.3 模型建立 5.4 mlr3模型建立", " 第 5 章 学生成绩水平分类 5.1 数据变量说明 变量说明。 变量中最重要的的为Class学生等级变量，是我们建模的目标变量。 edudata &lt;- read_csv(&quot;data/xAPI-Edu-Data.csv&quot;) edudata$Class &lt;- factor(edudata$Class, levels = c(&quot;H&quot;, &quot;M&quot;, &quot;L&quot;)) edudata$gender &lt;- factor(edudata$gender, levels = c(&quot;M&quot;, &quot;F&quot;)) str(edudata) ## spec_tbl_df [480 x 17] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ gender : Factor w/ 2 levels &quot;M&quot;,&quot;F&quot;: 1 1 1 1 1 .. ## $ NationalITy : chr [1:480] &quot;KW&quot; &quot;KW&quot; &quot;KW&quot; &quot;KW&quot; ... ## $ PlaceofBirth : chr [1:480] &quot;KuwaIT&quot; &quot;KuwaIT&quot; &quot;KuwaIT&quot;.. ## $ StageID : chr [1:480] &quot;lowerlevel&quot; &quot;lowerlevel&quot;&quot;.. ## $ GradeID : chr [1:480] &quot;G-04&quot; &quot;G-04&quot; &quot;G-04&quot; &quot;G-0&quot;.. ## $ SectionID : chr [1:480] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ... ## $ Topic : chr [1:480] &quot;IT&quot; &quot;IT&quot; &quot;IT&quot; &quot;IT&quot; ... ## $ Semester : chr [1:480] &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; ... ## $ Relation : chr [1:480] &quot;Father&quot; &quot;Father&quot; &quot;Father&quot;.. ## $ raisedhands : num [1:480] 15 20 10 30 40 42 35 50 12.. ## $ VisITedResources : num [1:480] 16 20 7 25 50 30 12 10 21 .. ## $ AnnouncementsView : num [1:480] 2 3 0 5 12 13 0 15 16 25 ... ## $ Discussion : num [1:480] 20 25 30 35 50 70 17 22 50.. ## $ ParentAnsweringSurvey : chr [1:480] &quot;Yes&quot; &quot;Yes&quot; &quot;No&quot; &quot;No&quot; ... ## $ ParentschoolSatisfaction: chr [1:480] &quot;Good&quot; &quot;Good&quot; &quot;Bad&quot; &quot;Bad&quot; .. ## $ StudentAbsenceDays : chr [1:480] &quot;Under-7&quot; &quot;Under-7&quot; &quot;Abov&quot;.. ## $ Class : Factor w/ 3 levels &quot;H&quot;,&quot;M&quot;,&quot;L&quot;: 2 2 3 .. ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. gender = col_character(), ## .. NationalITy = col_character(), ## .. PlaceofBirth = col_character(), ## .. StageID = col_character(), ## .. GradeID = col_character(), ## .. SectionID = col_character(), ## .. Topic = col_character(), ## .. Semester = col_character(), ## .. Relation = col_character(), ## .. raisedhands = col_double(), ## .. VisITedResources = col_double(), ## .. AnnouncementsView = col_double(), ## .. Discussion = col_double(), ## .. ParentAnsweringSurvey = col_character(), ## .. ParentschoolSatisfaction = col_character(), ## .. StudentAbsenceDays = col_character(), ## .. Class = col_character() ## .. ) ## - attr(*, &quot;problems&quot;)=&lt;externalptr&gt; 5.2 描述性分析 5.2.1 封装绘图函数 fun_bar &lt;- function(data, xlab, fillc, pos, xname, yname, legend){ data %&gt;% group_by({{xlab}}) %&gt;% # dplyr中的自定函数参数需要使用{{}}括起来 mutate(count = n()) %&gt;% ggplot(aes(reorder({{xlab}}, count), count, fill = {{fillc}})) + geom_col(position = pos) + #pos = &quot;stack&quot; or &quot;fill&quot; labs(x = xname, y = yname) + coord_flip() + theme_bw() + guides(fill = guide_legend(title = legend)) } 5.2.2 不同教育程度的学生选择课程主题 p1 &lt;- fun_bar(data = edudata, xlab = Topic, fillc = StageID, pos = &quot;stack&quot;, xname = &quot;Topic&quot;, yname = &quot;Student_Count&quot;, legend = &quot;教育程度&quot;) p2 &lt;- fun_bar(data = edudata, xlab = Topic, fillc = StageID, pos = &quot;fill&quot;, xname = &quot;Topic&quot;, yname = &quot;Per_Student_Count&quot;, legend = &quot;教育程度&quot;) p1/p2 图 5.1: 不同教育程度的学生选择课程主题 由图5.1可以看出： 课程主题最多的为IT、French和Arabic，其中选择IT的课程主题的学员远高于其他课。 无论哪种教育程度，IT、Science、Math和English四种课程都是必修的（三种颜色都有）。 5.2.3 不同课程主题监护人情况 这部分主要针对家长的情况进行分析，了解父母对学员学习的不同情况。对应在数据集中的变量为Relation。 p3 &lt;- fun_bar(data = edudata, xlab = Topic, fillc = Relation, pos = &quot;stack&quot;, xname = &quot;Topic&quot;, yname = &quot;Student_count&quot;, legend = &quot;监护人情况&quot;) p4 &lt;- fun_bar(data = edudata, xlab = Topic, fillc = Relation, pos = &quot;fill&quot;, xname = &quot;Topic&quot;, yname = &quot;Student_count&quot;, legend = &quot;监护人情况&quot;) p3/p4 图 5.2: 不同课程主题监护人情况 由图5.2可以看出： 总体而言，监护人为父亲的较多。其中，IT和Math课程中，负责人为父亲的超过75%。 French课程，监护人大多数为母亲，占70%左右。 5.2.4 不同课程学生学习成绩 p5 &lt;- fun_bar(data = edudata, xlab = Topic, fillc = Class, pos = &quot;stack&quot;, xname = &quot;Topic&quot;, yname = &quot;Student_count&quot;, legend = &quot;学生成绩&quot;) p6 &lt;- fun_bar(data = edudata, xlab = Topic, fillc = Class, pos = &quot;fill&quot;, xname = &quot;Topic&quot;, yname = &quot;Student_count&quot;, legend = &quot;学生成绩&quot;) p5/p6 图 5.3: 不同课程学生学习成绩 由图5.3: 所有课程中，只有Biology课程中，属于高水平的学生数超过了50%。 在Geology课程中，没有低水平的学生。 5.2.5 不同教室学生成绩水平 p7 &lt;- fun_bar(data = edudata, xlab = SectionID, fillc = Class, pos = &quot;stack&quot;, xname = &quot;Section_ID&quot;, yname = &quot;Student_count&quot;, legend = &quot;学生成绩&quot;) p8 &lt;- fun_bar(data = edudata, xlab = SectionID, fillc = Class, pos = &quot;fill&quot;, xname = &quot;Section_ID&quot;, yname = &quot;Student_count&quot;, legend = &quot;学生成绩&quot;) p7/p8 图 5.4: 不同教室学生成绩水平 由图5.4可以看出： 在A班的学生最多，C班的学生最少。 C班的低水平成绩的学生相对较多，其它两个班级的成绩水平基本一致。 5.2.6 不同学期、不同成绩水平与监护人的关系 # 封装函数，去掉坐标轴翻转 fun_bar2 &lt;- function(data, xlab, fillc, pos, xname, yname, legend){ data %&gt;% group_by({{xlab}}) %&gt;% # dplyr中的自定函数参数需要使用{{}}括起来 mutate(count = n()) %&gt;% ggplot(aes(reorder({{xlab}}, count), count, fill = {{fillc}})) + geom_col(position = pos) + #pos = &quot;stack&quot; or &quot;fill&quot; labs(x = xname, y = yname) + theme_bw() + guides(fill = guide_legend(title = legend)) } p9 &lt;- fun_bar2(edudata, Semester, Relation, pos = &quot;stack&quot;, xname = &quot;Semester&quot;, yname = &quot;Student_count&quot;, legend = &quot;监护人情况&quot;) p10 &lt;- fun_bar2(edudata, Semester, Relation, pos = &quot;fill&quot;, xname = &quot;Semester&quot;, yname = &quot;per_Student_count&quot;, legend = &quot;监护人情况&quot;) p11 &lt;- fun_bar2(edudata, Class, Relation, pos = &quot;stack&quot;, xname = &quot;Class&quot;, yname = &quot;Student_count&quot;, legend = &quot;监护人情况&quot;) p12 &lt;- fun_bar2(edudata, Class, Relation, pos = &quot;fill&quot;, xname = &quot;Class&quot;, yname = &quot;per_Student_count&quot;, legend = &quot;监护人情况&quot;) (p9|p10) / (p11|p12) 图 5.5: 不同学期、不同成绩水平与监护人的关系 由图5.5可知： 第一学期父亲作为监护人的学生数比第二学期多。 总体看，成绩水平较高的学生中，监护人为母亲的比较多；其它水平均是父亲较多。 5.2.7 家长是否回答调查问卷、成绩水平与家长对学校是否满意的关系 p13 &lt;- fun_bar2(edudata, ParentAnsweringSurvey, ParentschoolSatisfaction, pos = &quot;stack&quot;, xname = &quot;ParentAnsweringSurvey&quot;, yname = &quot;Student_count&quot;, legend = &quot;是否满意&quot;) p14 &lt;- fun_bar2(edudata, ParentAnsweringSurvey, ParentschoolSatisfaction, pos = &quot;fill&quot;, xname = &quot;ParentAnsweringSurvey&quot;, yname = &quot;Per_Student_count&quot;, legend = &quot;是否满意&quot;) p15 &lt;- fun_bar2(edudata, Class, ParentschoolSatisfaction, pos = &quot;stack&quot;, xname = &quot;Class&quot;, yname = &quot;Student_count&quot;, legend = &quot;是否满意&quot;) p16 &lt;- fun_bar2(edudata, Class, ParentschoolSatisfaction, pos = &quot;fill&quot;, xname = &quot;Class&quot;, yname = &quot;Per_Student_count&quot;, legend = &quot;是否满意&quot;) (p13|p14)/(p15|p16) 图 5.6: 家长是否回答调查问卷、成绩水平与家长对学校是否满意的关系 由图5.6可以看出： 有超过一半的家长回答了问卷，其中，回答问卷的家长大部分对学校满意，而未回答问卷的则大部分对学校不满。 成绩越高，家长对学校越满意。 5.2.8 性别、逃课次数与学生成绩水平的关系 p17 &lt;- fun_bar2(edudata, gender, Class, pos = &quot;stack&quot;, xname = &quot;Gender&quot;, yname = &quot;Student_count&quot;, legend = &quot;成绩水平&quot;) p18 &lt;- fun_bar2(edudata, gender, Class, pos = &quot;fill&quot;, xname = &quot;Gender&quot;, yname = &quot;Per_Student_count&quot;, legend = &quot;成绩水平&quot;) p19 &lt;- fun_bar2(edudata, StudentAbsenceDays, Class, pos = &quot;stack&quot;, xname = &quot;Class&quot;, yname = &quot;Student_count&quot;, legend = &quot;成绩水平&quot;) p20 &lt;- fun_bar2(edudata, StudentAbsenceDays, Class, pos = &quot;fill&quot;, xname = &quot;Class&quot;, yname = &quot;Per_Student_count&quot;, legend = &quot;成绩水平&quot;) (p17|p18)/(p19|p20) 图 5.7: 性别、逃课次数与学生成绩水平的关系 由图5.7可知： 女生比男生数量少很多，但高水平成绩的人数明显比男生多；中水平成绩男女比例基本持平。 逃课超过7天的的学生基本无法取得好的成绩。 5.2.9 举手次数和参加讨论次数与成绩水平关系 fun_bar3 &lt;- function(data, xlab, ylab, fillc, xname, yname){ data %&gt;% group_by({{xlab}}) %&gt;% summarise(Mcount = mean({{ylab}})) %&gt;% ggplot(aes({{xlab}}, Mcount, fill = {{fillc}})) + geom_col() + labs(x = xname, y = yname) + theme_bw() + theme(legend.position = &quot;none&quot;) } # edudata$Class &lt;- factor(edudata$Class, c(&quot;H&quot;, &quot;M&quot;, &quot;L&quot;), ordered = TRUE) p21 &lt;- fun_bar3(data = edudata, xlab = Class, ylab = raisedhands, fillc = Class, &quot;成绩水平&quot;, &quot;平均举手次数&quot; ) p22 &lt;- fun_bar3(data = edudata, xlab = Class, ylab = Discussion, fillc = Class, &quot;成绩水平&quot;, &quot;平均参与讨论次数&quot; ) p21|p22 图 5.8: 举手次数和参加讨论次数与成绩水平关系 由图5.8可知： 举手次数和参与讨论次数越多，成绩水平越高。 5.3 模型建立 5.3.1 回归树模型建立 set.seed(1234) # 按照数据目标8:2进行分层抽样，返回矩阵形式的抽样索引 index &lt;- createDataPartition(edudata$Class, p = 0.8, list = F) train &lt;- edudata[index, ] test &lt;- edudata[-index, ] # 建立回归树模型 rpart_model &lt;- rpart(Class ~., data = train) # type = &quot;class&quot;指定预测结果是具体的某个类别 pred_rp &lt;- predict(rpart_model, test[-17], type = &quot;class&quot;) confusionMatrix(pred_rp, test$Class) ## Confusion Matrix and Statistics ## ## Reference ## Prediction H M L ## H 18 3 0 ## M 9 29 3 ## L 1 10 22 ## ## Overall Statistics ## ## Accuracy : 0.7263 ## 95% CI : (0.6252, 0.8128) ## No Information Rate : 0.4421 ## P-Value [Acc &gt; NIR] : 1.882e-08 ## ## Kappa : 0.5806 ## ## Mcnemar&#39;s Test P-Value : 0.05103 ## ## Statistics by Class: ## ## Class: H Class: M Class: L ## Sensitivity 0.6429 0.6905 0.8800 ## Specificity 0.9552 0.7736 0.8429 ## Pos Pred Value 0.8571 0.7073 0.6667 ## Neg Pred Value 0.8649 0.7593 0.9516 ## Prevalence 0.2947 0.4421 0.2632 ## Detection Rate 0.1895 0.3053 0.2316 ## Detection Prevalence 0.2211 0.4316 0.3474 ## Balanced Accuracy 0.7990 0.7320 0.8614 prp(rpart_model) 5.3.2 随机数模型 set.seed(1234) # importance = T:稍后对变量进行重要性的可视化 rf_model &lt;- randomForest(Class~., data = train, importance = T) pred_rf &lt;- predict(rf_model, test[-17], type = &quot;class&quot;) confusionMatrix(pred_rf, test$Class) # 混淆矩阵判断模型准确率 ## Confusion Matrix and Statistics ## ## Reference ## Prediction H M L ## H 20 4 0 ## M 8 36 4 ## L 0 2 21 ## ## Overall Statistics ## ## Accuracy : 0.8105 ## 95% CI : (0.7172, 0.8837) ## No Information Rate : 0.4421 ## P-Value [Acc &gt; NIR] : 1.886e-13 ## ## Kappa : 0.7032 ## ## Mcnemar&#39;s Test P-Value : NA ## ## Statistics by Class: ## ## Class: H Class: M Class: L ## Sensitivity 0.7143 0.8571 0.8400 ## Specificity 0.9403 0.7736 0.9714 ## Pos Pred Value 0.8333 0.7500 0.9130 ## Neg Pred Value 0.8873 0.8723 0.9444 ## Prevalence 0.2947 0.4421 0.2632 ## Detection Rate 0.2105 0.3789 0.2211 ## Detection Prevalence 0.2526 0.5053 0.2421 ## Balanced Accuracy 0.8273 0.8154 0.9057 varImpPlot(rf_model) # 可视化变量重要性函数 阅读上图： 圆点越靠近右侧越重要。 我们重点观察排名前五的变量。通过左右两图的对比发现，两图中前四个变量相同（交叉），可以判定这四个变量是数据中最重要的变量。 5.3.3 SVM建模-支持向量机(需要再研究) set.seed(1234) library(kernlab) # Kernel-Based Machine Learning Lab svm_model &lt;- ksvm(Class~., data = test, kernel = &quot;rbfdot&quot;) # type = &quot;response&quot;:指定预测结果是具体的某个列别 pred_svm &lt;- predict(svm_model, test[-17], type = &quot;response&quot;) confusionMatrix(pred_svm, test$Class) ## Confusion Matrix and Statistics ## ## Reference ## Prediction H M L ## H 23 4 0 ## M 5 36 1 ## L 0 2 24 ## ## Overall Statistics ## ## Accuracy : 0.8737 ## 95% CI : (0.7897, 0.933) ## No Information Rate : 0.4421 ## P-Value [Acc &gt; NIR] : &lt; 2.2e-16 ## ## Kappa : 0.8053 ## ## Mcnemar&#39;s Test P-Value : NA ## ## Statistics by Class: ## ## Class: H Class: M Class: L ## Sensitivity 0.8214 0.8571 0.9600 ## Specificity 0.9403 0.8868 0.9714 ## Pos Pred Value 0.8519 0.8571 0.9231 ## Neg Pred Value 0.9265 0.8868 0.9855 ## Prevalence 0.2947 0.4421 0.2632 ## Detection Rate 0.2421 0.3789 0.2526 ## Detection Prevalence 0.2842 0.4421 0.2737 ## Balanced Accuracy 0.8809 0.8720 0.9657 5.3.4 模型融合 将各个模型的结果做一个融合（合并至一个数据框）。 result &lt;- data.frame(rpart = pred_rp, randomForest = pred_rf, svm = pred_svm, actual_class = test$Class, final_pred = rep(&quot;-&quot;, nrow(test))) head(result) ## rpart randomForest svm actual_class final_pred ## 1 M M M M - ## 2 L L L L - ## 3 L L L L - ## 4 M M L M - ## 5 L L L L - ## 6 M M M M - # 封装求众数函数 fun_pred &lt;- function(x){ names(which.max(table(x))) } result$final_pred &lt;- factor(apply(result[1:2], 1, fun_pred)) confusionMatrix(result$actual_class, result$final_pred) ## Confusion Matrix and Statistics ## ## Reference ## Prediction H L M ## H 21 1 6 ## L 0 23 2 ## M 7 10 25 ## ## Overall Statistics ## ## Accuracy : 0.7263 ## 95% CI : (0.6252, 0.8128) ## No Information Rate : 0.3579 ## P-Value [Acc &gt; NIR] : 3.029e-13 ## ## Kappa : 0.5887 ## ## Mcnemar&#39;s Test P-Value : 0.09327 ## ## Statistics by Class: ## ## Class: H Class: L Class: M ## Sensitivity 0.7500 0.6765 0.7576 ## Specificity 0.8955 0.9672 0.7258 ## Pos Pred Value 0.7500 0.9200 0.5952 ## Neg Pred Value 0.8955 0.8429 0.8491 ## Prevalence 0.2947 0.3579 0.3474 ## Detection Rate 0.2211 0.2421 0.2632 ## Detection Prevalence 0.2947 0.2632 0.4421 ## Balanced Accuracy 0.8228 0.8218 0.7417 head(result) ## rpart randomForest svm actual_class final_pred ## 1 M M M M M ## 2 L L L L L ## 3 L L L L L ## 4 M M L M M ## 5 L L L L L ## 6 M M M M M 5.4 mlr3模型建立 edudata &lt;- read_csv(&quot;data/xAPI-Edu-Data.csv&quot;, show_col_types = FALSE, col_types = &quot;fffffffffddddffff&quot;) spec(edudata) ## cols( ## gender = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), ## NationalITy = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), ## PlaceofBirth = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), ## StageID = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), ## GradeID = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), ## SectionID = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), ## Topic = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), ## Semester = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), ## Relation = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), ## raisedhands = col_double(), ## VisITedResources = col_double(), ## AnnouncementsView = col_double(), ## Discussion = col_double(), ## ParentAnsweringSurvey = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), ## ParentschoolSatisfaction = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), ## StudentAbsenceDays = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE), ## Class = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE) ## ) 5.4.1 回归树模型 library(mlr3verse) # 建立任务 set.seed(1234) task_rp &lt;- TaskClassif$new(id = &quot;edu_rp&quot;, backend = edudata, target = &quot;Class&quot;) task_rp ## &lt;TaskClassif:edu_rp&gt; (480 x 17) ## * Target: Class ## * Properties: multiclass ## * Features (16): ## - fct (12): GradeID, NationalITy, ParentAnsweringSurvey, ## ParentschoolSatisfaction, PlaceofBirth, Relation, ## SectionID, Semester, StageID, StudentAbsenceDays, Topic, ## gender ## - dbl (4): AnnouncementsView, Discussion, VisITedResources, ## raisedhands # 选择学习器 learner_rp &lt;- lrn(&quot;classif.rpart&quot;) # 划分测试集和训练集 train_set &lt;- sample(task_rp$nrow, 0.8 * task_rp$nrow) test_set &lt;- setdiff(seq_len(task_rp$nrow), train_set) # 模型训练 learner_rp$train(task_rp, row_ids = train_set) learner_rp$model ## n= 384 ## ## node), split, n, loss, yval, (yprob) ## * denotes terminal node ## ## 1) root 384 215 M (0.44010417 0.26562500 0.29427083) ## 2) StudentAbsenceDays=Above-7 157 64 L (0.38853503 0.59235669 0.01910828) ## 4) AnnouncementsView&gt;=30.5 62 16 M (0.74193548 0.20967742 0.04838710) * ## 5) AnnouncementsView&lt; 30.5 95 15 L (0.15789474 0.84210526 0.00000000) ## 10) ParentAnsweringSurvey=Yes 25 10 L (0.40000000 0.60000000 0.00000000) ## 20) raisedhands&gt;=15.5 11 3 M (0.72727273 0.27272727 0.00000000) * ## 21) raisedhands&lt; 15.5 14 2 L (0.14285714 0.85714286 0.00000000) * ## 11) ParentAnsweringSurvey=No 70 5 L (0.07142857 0.92857143 0.00000000) * ## 3) StudentAbsenceDays=Under-7 227 117 H (0.47577093 0.03964758 0.48458150) ## 6) Relation=Father 110 40 M (0.63636364 0.08181818 0.28181818) ## 12) VisITedResources&lt; 88.5 82 21 M (0.74390244 0.09756098 0.15853659) ## 24) GradeID=G-07,G-08,G-09,G-12,G-10 47 5 M (0.89361702 0.08510638 0.02127660) * ## 25) GradeID=G-04,G-06,G-11,G-02 35 16 M (0.54285714 0.11428571 0.34285714) ## 50) raisedhands&lt; 37.5 22 7 M (0.68181818 0.18181818 0.13636364) * ## 51) raisedhands&gt;=37.5 13 4 H (0.30769231 0.00000000 0.69230769) * ## 13) VisITedResources&gt;=88.5 28 10 H (0.32142857 0.03571429 0.64285714) ## 26) Topic=IT,Arabic,Science,English,French,History 16 7 M (0.56250000 0.06250000 0.37500000) * ## 27) Topic=Quran,Biology,Chemistry,Geology 12 0 H (0.00000000 0.00000000 1.00000000) * ## 7) Relation=Mum 117 38 H (0.32478632 0.00000000 0.67521368) ## 14) PlaceofBirth=KuwaIT,USA,Jordan,Iran,Morocco,Palestine 93 37 H (0.39784946 0.00000000 0.60215054) ## 28) VisITedResources&lt; 91.5 76 36 H (0.47368421 0.00000000 0.52631579) ## 56) Topic=IT,Arabic,Quran,Spanish,French,Chemistry,Geology 49 19 M (0.61224490 0.00000000 0.38775510) ## 112) gender=M 30 8 M (0.73333333 0.00000000 0.26666667) * ## 113) gender=F 19 8 H (0.42105263 0.00000000 0.57894737) * ## 57) Topic=Science,English,History,Biology 27 6 H (0.22222222 0.00000000 0.77777778) * ## 29) VisITedResources&gt;=91.5 17 1 H (0.05882353 0.00000000 0.94117647) * ## 15) PlaceofBirth=lebanon,Egypt,venzuela,Tunis,Syria,Iraq 24 1 H (0.04166667 0.00000000 0.95833333) * # 模型预测 pred_rp &lt;- learner_rp$predict(task_rp, row_ids = test_set) pred_rp ## &lt;PredictionClassif&gt; for 96 observations: ## row_ids truth response ## 1 M M ## 5 M L ## 7 L L ## --- ## 469 L L ## 470 L L ## 478 M M # 精度 pred_rp$confusion ## truth ## response M L H ## M 27 7 12 ## L 3 18 0 ## H 12 0 17 measure &lt;- msr(&quot;classif.acc&quot;) pred_rp$score(measure) # 预测精度 ## classif.acc ## 0.6458333 prp(learner_rp$model) # 作图 5.4.2 随机森林模型 # 建立任务 task_rf &lt;- TaskClassif$new(id = &quot;task_rf&quot;, backend = edudata, target = &quot;Class&quot;) # 选择学习器 learner_rf &lt;- lrn(&quot;classif.ranger&quot;) # 使用之前设定好的测试集和训练集进行模型训练和预测 learner_rf$train(task_rf, row_ids = train_set) learner_rf$model ## Ranger result ## ## Call: ## ranger::ranger(dependent.variable.name = task$target_names, data = task$data(), probability = self$predict_type == &quot;prob&quot;, case.weights = task$weights$weight, num.threads = 1L) ## ## Type: Classification ## Number of trees: 500 ## Sample size: 384 ## Number of independent variables: 16 ## Mtry: 4 ## Target node size: 1 ## Variable importance mode: none ## Splitrule: gini ## OOB prediction error: 22.40 % pred_rf &lt;- learner_rf$predict(task_rf, row_ids = test_set) pred_rf ## &lt;PredictionClassif&gt; for 96 observations: ## row_ids truth response ## 1 M M ## 5 M L ## 7 L L ## --- ## 469 L L ## 470 L L ## 478 M M # 精度预测 ## 建立混淆矩阵 pred_rf$confusion ## truth ## response M L H ## M 33 3 7 ## L 2 22 0 ## H 7 0 22 ## 设定精度预测方法 measure &lt;- msr(&quot;classif.acc&quot;) ## 预测精度 pred_rf$score(measure) ## classif.acc ## 0.8020833 5.4.3 支持向量机模型 完善内容 edudata1 &lt;- read_csv(“data/xAPI-Edu-Data.csv”, col_types = ““) str(edudata1) 建立任务 edudata1\\(Class &lt;- factor(edudata1\\)Class) task_svm &lt;- TaskClassif$new(id = “task_svm”, edudata1, target = “Class”) 选择学习器 learner_svm &lt;- lrn(“classif.svm”) 利用之前确定的训练集训练模型 learner_svm\\(train(task_svm, row_ids = train_set) learner_svm\\)model "],["6-mass-shoot.html", "第 6 章 美国大规模枪击案 6.1 变量说明 6.2 描述性分析 6.3 枪击发生地的可视化（地图） 6.4 枪击案发生地点（是否露天） 6.5 不同枪击案起因", " 第 6 章 美国大规模枪击案 6.1 变量说明 变量说明。 6.2 描述性分析 shoot &lt;- read_csv(&quot;data/Mass shooting/Mass Shootings Dataset Ver 3.csv&quot;) shoot &lt;- shoot %&gt;% rename(ID = `S#`, Open_Close = `Open/Close Location`, Total = `Total victims`, Mental = `Mental Health Issues`) shoot$Date &lt;- as.Date(shoot$Date, &quot;%m/%d/%Y&quot;) shoot$year &lt;- year(shoot$Date) shoot &lt;- shoot %&gt;% filter(year != 1966) glimpse(shoot) ## Rows: 318 ## Columns: 22 ## $ ID &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1~ ## $ Title &lt;chr&gt; &quot;Las Vegas Strip mass shooting&quot;, &quot;San Fr~ ## $ Location &lt;chr&gt; &quot;Las Vegas, NV&quot;, &quot;San Francisco, CA&quot;, &quot;T~ ## $ Date &lt;date&gt; 2017-10-01, 2017-06-14, 2017-06-07, 201~ ## $ `Incident Area` &lt;chr&gt; NA, &quot;UPS facility&quot;, &quot;Weis grocery&quot;, &quot;man~ ## $ Open_Close &lt;chr&gt; NA, &quot;Close&quot;, &quot;Close&quot;, &quot;Close&quot;, &quot;Close&quot;, ~ ## $ Target &lt;chr&gt; NA, &quot;coworkers&quot;, &quot;coworkers&quot;, &quot;coworkers~ ## $ Cause &lt;chr&gt; NA, NA, &quot;terrorism&quot;, &quot;unemployement&quot;, NA~ ## $ Summary &lt;chr&gt; NA, &quot;Jimmy Lam, 38, fatally shot three c~ ## $ Fatalities &lt;dbl&gt; 58, 3, 3, 5, 3, 3, 5, 5, 3, 5, 49, 0, 1,~ ## $ Injured &lt;dbl&gt; 527, 2, 0, 0, 0, 0, 6, 0, 3, 11, 53, 4, ~ ## $ Total &lt;dbl&gt; 585, 5, 3, 5, 3, 3, 11, 5, 6, 16, 102, 4~ ## $ `Policeman Killed` &lt;dbl&gt; NA, 0, NA, NA, 1, NA, NA, NA, 3, 5, 0, 0~ ## $ Age &lt;dbl&gt; NA, 38, 24, 45, 43, 39, 26, 20, NA, 25, ~ ## $ `Employeed (Y/N)` &lt;dbl&gt; NA, 1, 1, 1, 1, NA, NA, NA, NA, NA, NA, ~ ## $ `Employed at` &lt;chr&gt; NA, NA, &quot;Weis grocery&quot;, &quot;manufacturer Fi~ ## $ Mental &lt;chr&gt; &quot;Unclear&quot;, &quot;Yes&quot;, &quot;Unclear&quot;, &quot;Unclear&quot;, ~ ## $ Race &lt;chr&gt; &quot;White&quot;, &quot;Asian&quot;, &quot;White&quot;, NA, &quot;White&quot;, ~ ## $ Gender &lt;chr&gt; &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, ~ ## $ Latitude &lt;dbl&gt; 36.18127, NA, NA, NA, NA, NA, NA, NA, NA~ ## $ Longitude &lt;dbl&gt; -115.13413, NA, NA, NA, NA, NA, NA, NA, ~ ## $ year &lt;dbl&gt; 2017, 2017, 2017, 2017, 2017, 2017, 2017~ 6.2.1 枪击案中伤亡人数 # 封装条形图作图函数 fun_bar1 &lt;- function(data, xlab, ylab, xname, yname){ data %&gt;% group_by({{xlab}}) %&gt;% summarise(count = sum({{ylab}})) %&gt;% ggplot(aes(x = reorder(year, -count), y = count)) + geom_bar(stat = &quot;identity&quot;, fill = &quot;#63B8FF&quot;) + labs(x = xname, y = yname) + theme_bw() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) } p1 &lt;- fun_bar1(shoot, year, Total, &quot; &quot;, &quot;受害人数&quot;) + geom_text(aes(label = count), size = 2, angle = 45, vjust = 0.5) p2 &lt;- fun_bar1(shoot, year, Injured, &quot; &quot;, &quot;受伤人数&quot;)+ geom_text(aes(label = count), size = 2, angle = 45, vjust = 0.5) p3 &lt;- fun_bar1(shoot, year, Fatalities, &quot; &quot;, &quot;死亡人数&quot;)+ geom_text(aes(label = count), size = 2, angle = 45, vjust = 0.5) shoot %&gt;% select(year, Injured, Fatalities) %&gt;% pivot_longer(-year, names_to = &quot;Types&quot;, values_to = &quot;Values&quot;) %&gt;% ggplot(aes(x = year, y = Values, fill = Types)) + geom_col() + coord_flip() + theme_bw() p1/p2/p3 整体而言，总伤亡人数呈现增长趋势。 2015-2017年间，伤亡人数突然增多。 受害人数2017年最多，1971年最少。 除2017年外，其余年份受伤和死亡任务相对平衡 6.2.2 绘制枪击案频率、伤亡总人数和平均伤亡人数（月为单位） # 提取月份数据 shoot$month &lt;- month(shoot$Date) # 每月枪击频率 p4 &lt;- month_freq &lt;- shoot %&gt;% group_by(month) %&gt;% summarise(freq = n()) %&gt;% ggplot(aes(x = reorder(month, freq), y = freq)) + geom_bar(stat = &quot;identity&quot;, fill = &quot;#63B8FF&quot;) + geom_text(aes(label = freq), hjust = -0.1, size = 2) + labs(x = &quot; &quot;, y = &quot;月均枪击事件数&quot;) + coord_flip() + theme_bw() # 月伤亡总人数 p5 &lt;- month_total &lt;- shoot %&gt;% group_by(month) %&gt;% summarise(total = sum(Total))%&gt;% ggplot(aes(x = reorder(month, total), y = total)) + geom_bar(stat = &quot;identity&quot;, fill = &quot;#63B8FF&quot;) + geom_text(aes(label = total), hjust = -0.1, size = 2) + labs(x = &quot; &quot;, y = &quot;月伤亡总人数&quot;) + coord_flip() + theme_bw() # 月均伤亡人数 p6 &lt;- month_meantotal &lt;- shoot %&gt;% group_by(month) %&gt;% summarise(mean = mean(Total)) %&gt;% ggplot(aes(x = reorder(month, mean), y = mean)) + geom_bar(stat = &quot;identity&quot;, fill = &quot;#63B8FF&quot;) + geom_text(aes(label = round(mean,2)), hjust = -0.1, size = 2) + labs(x = &quot; &quot;, y = &quot;月均伤亡人数&quot;) + coord_flip() + theme_bw() p4/p5/p6 图 6.1: 绘制枪击案频率、伤亡总人数和平均伤亡人数（月为单位） 十月份至少发生过一起大型枪击案 6.2.3 枪手与种族之间的关系 table(shoot$Race) ## ## Asian ## 6 ## Asian American ## 11 ## Asian American/Some other race ## 1 ## black ## 3 ## Black ## 4 ## Black American or African American ## 76 ## Black American or African American/Unknown ## 1 ## Latino ## 5 ## Native American or Alaska Native ## 3 ## Other ## 2 ## Some other race ## 20 ## Two or more races ## 2 ## Unknown ## 42 ## white ## 12 ## White ## 7 ## White American or European American ## 120 ## White American or European American/Some other Race ## 1 # 将所有重复的数据重塑为统一 shoot &lt;- within(shoot,{ Race_new &lt;- &quot; &quot; Race_new[Race == &quot;Black&quot;| Race == &quot;black&quot;| Race == &quot;Black American or African American&quot;| Race == &quot;Black American or African American/Unknown&quot;] &lt;- &quot;Black&quot; Race_new[Race == &quot;White&quot;|Race == &quot;white&quot;| Race == &quot;White American or European American&quot;| Race == &quot;White American or European American/Some other Race &quot;] &lt;- &quot;White&quot; Race_new[Race == &quot;unclear&quot;| Race == &quot;&quot;| Race == &quot;Unknown&quot;] &lt;- &quot;Unknow&quot; Race_new[Race == &quot;Asian&quot;| Race == &quot;Asian American/Some other race&quot;| Race == &quot;Asian American&quot;] &lt;- &quot;Asian&quot; Race_new[Race == &quot;Latino&quot;|Race == &quot;Other&quot;| Race == &quot;Native American or Alaska Native&quot;| Race == &quot;Native American&quot;| Race == &quot;Some other race&quot;| Race == &quot;Two or more races&quot;] &lt;- &quot;Other&quot; }) # 统计不同Race_new的个数 shoot$Race_new[is.na(shoot$Race_new)] &lt;- &quot;Unknow&quot; p7 &lt;- shoot %&gt;% group_by(Race_new) %&gt;% summarise(freq = n()) %&gt;% ggplot(aes(x = reorder(Race_new, freq), y = freq)) + geom_bar(stat = &quot;identity&quot;, fill = &quot;#63B8FF&quot;) + geom_text(aes(label = round(freq, 2)), hjust = 0.7, size = 3) + labs(x = &quot;种族&quot;, y = &quot;频数&quot;) + coord_flip() + theme_bw() p8 &lt;- shoot %&gt;% group_by(Race_new) %&gt;% summarise(freq = n()) %&gt;% ggplot(aes(x = Race_new, y = freq, fill = Race_new)) + geom_bar(stat = &quot;identity&quot;, width = 1) + labs(x = &quot;种族&quot;, y = &quot;频数&quot;) + coord_polar(theta = &quot;y&quot;) + # 将角度映射到y轴 theme_bw() + guides(fill = guide_legend(title = NULL)) p7|p8 图 6.2: 枪手与种族之间的关系 枪手中白种人最多，黑种人次之，亚洲人最少。 6.2.4 杀手性别和精神状况 # 性别情况 table(shoot$Gender) ## ## Female M M/F Male Male/Female ## 5 17 1 270 4 ## Unknown ## 21 # 对数据进行重塑统一 shoot$Gender[shoot$Gender == &quot;M&quot;] &lt;- &quot;Male&quot; shoot$Gender[shoot$Gender == &quot;M/F&quot;] &lt;- &quot;Male/Female&quot; p9 &lt;- shoot %&gt;% group_by(Gender) %&gt;% summarise(count = n()) %&gt;% ggplot(aes(x = reorder(Gender, count), y = count)) + geom_bar(stat = &quot;identity&quot;, fill = &quot;#63B8FF&quot;) + geom_text(aes(label = count), hjust = 0.7, size = 3) + labs(x = &quot;性别&quot;, y = &quot; &quot;) + coord_flip() + theme_bw() # 精神情况 table(shoot$Mental) ## ## No Unclear unknown Unknown Yes ## 90 13 1 110 104 shoot$Mental[shoot$Mental == &quot;Unclear&quot;| shoot$Mental == &quot;Unknown&quot;| shoot$Mental == &quot;unknown&quot;] &lt;- &quot;Unknown&quot; p10 &lt;- shoot %&gt;% group_by(Mental) %&gt;% summarise(count = n()) %&gt;% ggplot(aes(x = reorder(Mental, count), y = count)) + geom_bar(stat = &quot;identity&quot;, fill = &quot;#63B8FF&quot;) + geom_text(aes(label = count), hjust = 0.7, size = 3) + labs(x = &quot;是否有精神问题&quot;, y = &quot;频数&quot;) + coord_flip() + theme_bw() p9/p10 图 6.3: 杀手性别和精神状况 由图6.3可知： 枪手中男性占绝大多数。 并不是每个枪手都有精神问题，相反有精神问题的与没有精神问题的枪手数量并未拉开差距。 6.2.5 伤亡水平和不同伤亡水平伤亡人数 # 按照伤亡人数确定伤亡水平 shoot &lt;- within(shoot,{ level &lt;- &quot;&quot; level[Total &lt; 5] &lt;- &quot;&lt;5&quot; level[Total&gt;=5] &lt;- &quot;5-10&quot; level[Total&gt;10] &lt;- &quot;&gt;10&quot; }) p11 &lt;- shoot %&gt;% group_by(level) %&gt;% summarise(count = sum(Total)) %&gt;% ggplot(aes(x = reorder(level, count), y = count)) + geom_bar(stat = &quot;identity&quot;, fill = &quot;#63B8FF&quot;) + #geom_label(aes(label = level), hjust = 0.7) + labs(x = &quot;伤亡水平&quot;, y = &quot;伤亡人数&quot;) + coord_flip() + theme_bw() p12 &lt;- shoot %&gt;% group_by(level) %&gt;% summarise(count = n()) %&gt;% ggplot(aes(x = reorder(level, count), y = count)) + geom_bar(stat = &quot;identity&quot;, fill = &quot;#63B8FF&quot;) + geom_label(aes(label = count), hjust = 0.7) + labs(x = &quot;伤亡水平&quot;, y = &quot;频数&quot;) + coord_flip() + theme_bw() p12/p11 图 6.4: 伤亡水平和不同伤亡水平伤亡人数 由图6.4可知： 大部分枪击事件为伤亡人数5-10之间的小规模枪击事件。 伤亡水平大于10的案件中总伤亡人数远多于小伤亡水平的枪击案件。 6.3 枪击发生地的可视化（地图） states_map &lt;- map_data(&quot;state&quot;) # 获取美国地图 p13 &lt;- ggplot() + geom_polygon(data= states_map, aes(x = long, y = lat, group = group), color = &quot;black&quot;, fill = &quot;white&quot;) + geom_point(data = shoot[shoot$Longitude &gt;= -140, ], aes(x = Longitude, y = Latitude, size = Total, color = Fatalities), alpha = 0.6) + scale_color_gradient(low = &quot;red&quot;, high = &quot;black&quot;) ggplotly(p13) 枪击案多发生在美国东部地区及西部边境地区。 6.4 枪击案发生地点（是否露天） table(shoot$Open_Close) ## ## Close Open Open+Close Open+CLose ## 193 76 19 1 shoot$Open_Close[is.na(shoot$Open_Close)] &lt;- &quot;Unknown&quot; shoot$Open_Close[shoot$Open_Close == &quot;Open+CLose&quot;] &lt;- &quot;Open+Close&quot; shoot_Op_Cl &lt;- shoot %&gt;% group_by(Open_Close) %&gt;% summarise(Count = n()) P14 &lt;- ggplot(shoot_Op_Cl, aes(x = reorder(Open_Close, Count), y = Count))+ geom_col(fill = &quot;#63B8FF&quot;) + geom_label(aes(label = Count), hjust = 0.7) + coord_flip()+ labs(x = &quot;Open&amp;Close&quot;, y = &quot;Count&quot;) + theme_bw() P14 枪击案件大多发生在室内，室外枪击的数量不到室内数量的一半。 6.5 不同枪击案起因 shoot_cause &lt;- shoot %&gt;% group_by(Cause) %&gt;% summarise(Count = n()) shoot_cause$Cause[is.na(shoot_cause$Cause)] &lt;- &quot;Unknown&quot; (P15 &lt;- ggplot(shoot_cause, aes(x = reorder(Cause, Count), y = Count))+ geom_col(fill = &quot;#63B8FF&quot;) + geom_text(aes(label = Count), hjust = 0.7, size = 3) + coord_flip()+ labs(x = &quot;Cause&quot;, y = &quot;Count&quot;) + theme_bw()) 枪击案的发生大都由于枪手存在精神问题。 恐怖主义、愤怒和挫折是除精神问题外引发枪击案最多的诱因。 plot(cars) 图 6.5: A template figure. "],["7-mushrooms.html", "第 7 章 毒蘑菇分析 7.1 变量说明 7.2 数据预处理-统计每列因子水品个数 7.3 统计建模", " 第 7 章 毒蘑菇分析 7.1 变量说明 knitr::include_graphics(&quot;images/mushrooms-data.jpg&quot;, dpi = FALSE) class为因变量。 files &lt;- &quot;data/mushrooms.csv&quot; mushrooms &lt;- read_csv(files,show_col_types = FALSE) %&gt;% mutate(across(everything(), factor)) %&gt;% as_tibble() str(mushrooms) # 查看数据基本结构 ## tibble [8,124 x 23] (S3: tbl_df/tbl/data.frame) ## $ class : Factor w/ 2 levels &quot;e&quot;,&quot;p&quot;: 2 1 1 2 1 .. ## $ cap-shape : Factor w/ 6 levels &quot;b&quot;,&quot;c&quot;,&quot;f&quot;,&quot;k&quot;,..:.. ## $ cap-surface : Factor w/ 4 levels &quot;f&quot;,&quot;g&quot;,&quot;s&quot;,&quot;y&quot;: 3 .. ## $ cap-color : Factor w/ 10 levels &quot;b&quot;,&quot;c&quot;,&quot;e&quot;,&quot;g&quot;,.... ## $ bruises : Factor w/ 2 levels &quot;FALSE&quot;,&quot;TRUE&quot;: 2 2.. ## $ odor : Factor w/ 9 levels &quot;a&quot;,&quot;c&quot;,&quot;f&quot;,&quot;l&quot;,..:.. ## $ gill-attachment : Factor w/ 2 levels &quot;a&quot;,&quot;f&quot;: 2 2 2 2 2 .. ## $ gill-spacing : Factor w/ 2 levels &quot;c&quot;,&quot;w&quot;: 1 1 1 1 2 .. ## $ gill-size : Factor w/ 2 levels &quot;b&quot;,&quot;n&quot;: 2 1 1 2 1 .. ## $ gill-color : Factor w/ 12 levels &quot;b&quot;,&quot;e&quot;,&quot;g&quot;,&quot;h&quot;,.... ## $ stalk-shape : Factor w/ 2 levels &quot;e&quot;,&quot;t&quot;: 1 1 1 1 2 .. ## $ stalk-root : Factor w/ 5 levels &quot;?&quot;,&quot;b&quot;,&quot;c&quot;,&quot;e&quot;,..:.. ## $ stalk-surface-above-ring: Factor w/ 4 levels &quot;f&quot;,&quot;k&quot;,&quot;s&quot;,&quot;y&quot;: 3 .. ## $ stalk-surface-below-ring: Factor w/ 4 levels &quot;f&quot;,&quot;k&quot;,&quot;s&quot;,&quot;y&quot;: 3 .. ## $ stalk-color-above-ring : Factor w/ 9 levels &quot;b&quot;,&quot;c&quot;,&quot;e&quot;,&quot;g&quot;,..:.. ## $ stalk-color-below-ring : Factor w/ 9 levels &quot;b&quot;,&quot;c&quot;,&quot;e&quot;,&quot;g&quot;,..:.. ## $ veil-type : Factor w/ 1 level &quot;p&quot;: 1 1 1 1 1 1 1 1.. ## $ veil-color : Factor w/ 4 levels &quot;n&quot;,&quot;o&quot;,&quot;w&quot;,&quot;y&quot;: 3 .. ## $ ring-number : Factor w/ 3 levels &quot;n&quot;,&quot;o&quot;,&quot;t&quot;: 2 2 2 .. ## $ ring-type : Factor w/ 5 levels &quot;e&quot;,&quot;f&quot;,&quot;l&quot;,&quot;n&quot;,..:.. ## $ spore-print-color : Factor w/ 9 levels &quot;b&quot;,&quot;h&quot;,&quot;k&quot;,&quot;n&quot;,..:.. ## $ population : Factor w/ 6 levels &quot;a&quot;,&quot;c&quot;,&quot;n&quot;,&quot;s&quot;,..:.. ## $ habitat : Factor w/ 7 levels &quot;d&quot;,&quot;g&quot;,&quot;l&quot;,&quot;m&quot;,..:.. table(mushrooms$class) # 统计样本种类个数 ## ## e p ## 4208 3916 prop.table(table(mushrooms$class)) # 统计样本种类占比 ## ## e p ## 0.5179714 0.4820286 7.2 数据预处理-统计每列因子水品个数 # levels()统计因子水平 # length()计算因子水平个数 mushrooms_factor &lt;- mushrooms %&gt;% mutate(across(everything(), factor)) %&gt;% as_tibble() %&gt;% janitor::clean_names() df1 &lt;- map_dfr(mushrooms_factor, function(x){ length(levels(x)) }) %&gt;% as.tibble() %&gt;% pivot_longer(cols = everything(), names_to = &quot;Factors&quot;, values_to = &quot;Total_Class&quot;) df1 ## # A tibble: 23 x 2 ## Factors Total_Class ## &lt;chr&gt; &lt;int&gt; ## 1 class 2 ## 2 cap_shape 6 ## 3 cap_surface 4 ## 4 cap_color 10 ## 5 bruises 2 ## 6 odor 9 ## 7 gill_attachment 2 ## 8 gill_spacing 2 ## 9 gill_size 2 ## 10 gill_color 12 ## # ... with 13 more rows 7.3 统计建模 7.3.1 随机森林模型-mlr3 # 建立任务 task_rf &lt;- TaskClassif$new(id = &quot;task_rf&quot;, backend = mushrooms_factor, target = &quot;class&quot;) # 选择学习器 learner_rf &lt;- lrn(&quot;classif.ranger&quot;) # 设定测试集和训练集 train_set &lt;- sample(task_rf$nrow, 0.7 * task_rf$nrow) test_set &lt;- setdiff(seq_len(task_rf$nrow), train_set) # 使用之前设定好的测试集和训练集进行模型训练和预测 learner_rf$train(task_rf, row_ids = train_set) learner_rf$model ## Ranger result ## ## Call: ## ranger::ranger(dependent.variable.name = task$target_names, data = task$data(), probability = self$predict_type == &quot;prob&quot;, case.weights = task$weights$weight, num.threads = 1L) ## ## Type: Classification ## Number of trees: 500 ## Sample size: 5686 ## Number of independent variables: 22 ## Mtry: 4 ## Target node size: 1 ## Variable importance mode: none ## Splitrule: gini ## OOB prediction error: 0.00 % pred_rf &lt;- learner_rf$predict(task_rf, row_ids = test_set) pred_rf ## &lt;PredictionClassif&gt; for 2438 observations: ## row_ids truth response ## 8 e e ## 11 e e ## 29 e e ## --- ## 8107 e e ## 8114 p p ## 8123 p p # 精度预测 ## 建立混淆矩阵 pred_rf$confusion ## truth ## response e p ## e 1244 0 ## p 0 1194 ## 设定精度预测方法 measure &lt;- msr(&quot;classif.acc&quot;) ## 预测精度 pred_rf$score(measure) ## classif.acc ## 1 可以看到，本例中模型的精确度达到了100%。 这是由于本例的数据集是一个经典的、已经经过多次改进的数据集，且数据量较少，导致数据集非常标准。 "],["8-World-Universities-Rankings.html", "第 8 章 世界大学排名评估 8.1 数据 8.2 世界大学排名中心-Center for World University Rankings (CWUR) 8.3 Shanghai Academic Rankings for World Universities (ARWU)", " 第 8 章 世界大学排名评估 8.1 数据 8.1.1 录入 cwurdata &lt;- read_csv(&quot;data/University/cwurData.csv&quot;, show_col_types = FALSE) educationExpenditure &lt;- read_csv( &quot;data/University/education_expenditure_supplementary_data.csv&quot;, show_col_types = FALSE) educationalAttainment &lt;- read_csv( &quot;data/University/educational_attainment_supplementary_data.csv&quot;, show_col_types = FALSE) schoolCountry &lt;- read_csv( &quot;data/University/school_and_country_table.csv&quot;, show_col_types = FALSE) shanghaiData &lt;- read_csv( &quot;data/University/shanghaiData.csv&quot;, show_col_types = FALSE) timesData &lt;- read_csv( &quot;data/University/timesData.csv&quot;, show_col_types = FALSE) 8.1.2 数据概览 现在我们有6个数据文件： cwurData.csv (2200 rows, 14 columns) education_expenditure_supplementary_data.csv (333 rows, 9 columns) educational_attainment_supplementary_data.csv (79055 rows, 29 columns) school_and_country_table.csv (818 rows, 2 columns) shanghaiData.csv (4897 rows, 11 columns) timesData.csv (2603 rows, 14 columns) 我们看一下数据的前几行及其基本概览： kable(head(cwurdata, 10), &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F, position = &quot;left&quot;) world_rank institution country national_rank quality_of_education alumni_employment quality_of_faculty publications influence citations broad_impact patents score year 1 Harvard University USA 1 7 9 1 1 1 1 NA 5 100.00 2012 2 Massachusetts Institute of Technology USA 2 9 17 3 12 4 4 NA 1 91.67 2012 3 Stanford University USA 3 17 11 5 4 2 2 NA 15 89.50 2012 4 University of Cambridge United Kingdom 1 10 24 4 16 16 11 NA 50 86.17 2012 5 California Institute of Technology USA 4 2 29 7 37 22 22 NA 18 85.21 2012 6 Princeton University USA 5 8 14 2 53 33 26 NA 101 82.50 2012 7 University of Oxford United Kingdom 2 13 28 9 15 13 19 NA 26 82.34 2012 8 Yale University USA 6 14 31 12 14 6 15 NA 66 79.14 2012 9 Columbia University USA 7 23 21 10 13 12 14 NA 5 78.86 2012 10 University of California, Berkeley USA 8 16 52 6 6 5 3 NA 16 78.55 2012 glimpse(cwurdata) ## Rows: 2,200 ## Columns: 14 ## $ world_rank &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,~ ## $ institution &lt;chr&gt; &quot;Harvard University&quot;, &quot;Massachusetts I~ ## $ country &lt;chr&gt; &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;United Kingdom&quot;,~ ## $ national_rank &lt;dbl&gt; 1, 2, 3, 1, 4, 5, 2, 6, 7, 8, 9, 10, 1~ ## $ quality_of_education &lt;dbl&gt; 7, 9, 17, 10, 2, 8, 13, 14, 23, 16, 15~ ## $ alumni_employment &lt;dbl&gt; 9, 17, 11, 24, 29, 14, 28, 31, 21, 52,~ ## $ quality_of_faculty &lt;dbl&gt; 1, 3, 5, 4, 7, 2, 9, 12, 10, 6, 8, 14,~ ## $ publications &lt;dbl&gt; 1, 12, 4, 16, 37, 53, 15, 14, 13, 6, 3~ ## $ influence &lt;dbl&gt; 1, 4, 2, 16, 22, 33, 13, 6, 12, 5, 20,~ ## $ citations &lt;dbl&gt; 1, 4, 2, 11, 22, 26, 19, 15, 14, 3, 28~ ## $ broad_impact &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA~ ## $ patents &lt;dbl&gt; 5, 1, 15, 50, 18, 101, 26, 66, 5, 16, ~ ## $ score &lt;dbl&gt; 100.00, 91.67, 89.50, 86.17, 85.21, 82~ ## $ year &lt;dbl&gt; 2012, 2012, 2012, 2012, 2012, 2012, 20~ 8.2 世界大学排名中心-Center for World University Rankings (CWUR) 该中心提供了世界最顶级大学的排名信息。中心根据National Rank, Quality of Education（教学质量）, Alumni Employment（毕业生就业情况）, Quality of Faculty（教师素质）, Publications（出版物）, Influence（影响力）, Citations（引用量）, Broad Impact（海外影响力）, Patents（专利）等指标计算每所大学的, Total Score（综合评分），并确定最终排名。e.g.，Harvard University以100分的Total Score和多项指标第一，名列2012年世界大学排名第一。 8.2.1 最好的大学 那么2012~2015年排名前5的大学情况如何？ cwurTop5 &lt;- cwurdata %&gt;% group_by(year) %&gt;% select(year, institution, world_rank) %&gt;% top_n(-5, wt = world_rank) cwurTop5 ## # A tibble: 20 x 3 ## # Groups: year [4] ## year institution world_rank ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2012 Harvard University 1 ## 2 2012 Massachusetts Institute of Technology 2 ## 3 2012 Stanford University 3 ## 4 2012 University of Cambridge 4 ## 5 2012 California Institute of Technology 5 ## 6 2013 Harvard University 1 ## 7 2013 Stanford University 2 ## 8 2013 University of Oxford 3 ## 9 2013 Massachusetts Institute of Technology 4 ## 10 2013 University of Cambridge 5 ## 11 2014 Harvard University 1 ## 12 2014 Stanford University 2 ## 13 2014 Massachusetts Institute of Technology 3 ## 14 2014 University of Cambridge 4 ## 15 2014 University of Oxford 5 ## 16 2015 Harvard University 1 ## 17 2015 Stanford University 2 ## 18 2015 Massachusetts Institute of Technology 3 ## 19 2015 University of Cambridge 4 ## 20 2015 University of Oxford 5 ggplot(cwurTop5, aes(x = year, y = world_rank, color = institution)) + geom_point(size = 5) + theme_bw() + labs(title = &quot;World Ranked Universities by CWUR (2012-2015)&quot;) 2012~2015年间世界排名前5的大学有：哈弗、MIT、斯坦福、加州理工、剑桥、牛津 2012~2015年间，哈弗大学始终排名第一。 MIT和斯坦福紧随其后。 接下来，我们看看每年排名前十的高校的情况，其中前三名分别使用金、银、铜表示，4~10采用绿色。几年的图形做法类似，为避免重复操作，我们应创建一个函数。 # 每年排名前十高校图形绘制函数 cwurPlotYear &lt;- function(nYear){ cwurdata %&gt;% filter(year == nYear) %&gt;% top_n(10, -world_rank) %&gt;% ggplot(aes(x = reorder(institution, -world_rank), y = world_rank)) + geom_bar(stat = &quot;identity&quot;, aes(fill = reorder(institution, -world_rank)), color = &quot;black&quot;) + theme_bw() + coord_flip() + scale_fill_manual(values = c(rep(&quot;lightgreen&quot;, 7), &quot;#CD7F32&quot;, &quot;grey&quot;, &quot;gold&quot;))+ guides(fill = &quot;none&quot;) + labs(x=&quot;Institution&quot;, y=&quot;World Rank&quot;, title=paste(nYear), subtitle=&quot;smaller better&quot;) } p1 &lt;- cwurPlotYear(2012) p2 &lt;- cwurPlotYear(2013) p3 &lt;- cwurPlotYear(2014) p4 &lt;- cwurPlotYear(2015) (p1|p2)/(p3|p4) 图 8.1: 2012~2015年排名前十高校 8.2.2 国家排名 cwurCountry &lt;- cwurdata %&gt;% group_by(country) %&gt;% summarise(n = length(publications)) %&gt;% top_n(10, n) %&gt;% ungroup() cwurCountry &lt;- cwurdata %&gt;% filter(country %in% cwurCountry$country) cwurCountryPlot &lt;- function(rankBy, By){ ggplot(cwurCountry, aes(x = country, y = {{rankBy}}, col = country)) + guides(col = &quot;none&quot;) + geom_boxplot() + theme_bw() + coord_flip() + labs(x = &quot;Country&quot;, y = paste(&quot;Rank by &quot;, By), title = paste(&quot;Rank by &quot;, By), subtitle = &quot;smaller is better&quot;) } p1 &lt;- cwurCountryPlot(publications, &quot;publications&quot;) p2 &lt;- cwurCountryPlot(citations, &quot;citations&quot;) p3 &lt;- cwurCountryPlot(patents, &quot;patents&quot;) p4 &lt;- cwurCountryPlot(quality_of_education, &quot;quality of education&quot;) p5 &lt;- cwurCountryPlot(alumni_employment, &quot;alumni employment&quot;) p6 &lt;- cwurCountryPlot(quality_of_faculty, &quot;quality of faculty&quot;) 8.3 Shanghai Academic Rankings for World Universities (ARWU) "],["24-references.html", "第 9 章 参考文献", " 第 9 章 参考文献 "],["23-appendix.html", "A 附录", " A 附录 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
