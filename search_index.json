[["index.html", "Kaggle数据项目实战 简介", " Kaggle数据项目实战 LEE 2021-09-08 简介 Kaggle成立于2010年，是一个进行数据发掘和预测竞赛的在线平台。从公司的角度来讲，可以提供一些数据，进而提出一个实际需要解决的问题；从参赛者的角度来讲，他们将组队参与项目，针对其中一个问题提出解决方案，最终由公司选出的最佳方案可以获得5K-10K美金的奖金。 除此之外，Kaggle官方每年还会举办一次大规模的竞赛，奖金高达一百万美金，吸引了广大的数据科学爱好者参与其中。从某种角度来讲，大家可以把它理解为一个众包平台，类似国内的猪八戒。但是不同于传统的低层次劳动力需求，Kaggle一直致力于解决业界难题，因此也创造了一种全新的劳动力市场——不再以学历和工作经验作为唯一的人才评判标准，而是着眼于个人技能，为顶尖人才和公司之间搭建了一座桥梁。 "],["Video-Games-Sales.html", "1 Video Games Sales 1.1 准备 1.2 缺失值处理 1.3 描述性分析 1.4 探索性分析 1.5 媒体打分与玩家打分的关系 1.6 玩家与媒体分别最喜欢哪个发行商", " 1 Video Games Sales 1.1 准备 file &lt;- &quot;D:/Tools/Rwork/0.Study R/kaggle-project/data/vgsales.csv&quot; df &lt;- read_csv(file) ## Rows: 19600 Columns: 9 ## -- Column specification -------------------------------------------------------- ## Delimiter: &quot;,&quot; ## chr (4): Name, Platform, Publisher, Developer ## dbl (5): Rank, Critic_Score, User_Score, Total_Shipped, Year ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. str(df) ## spec_tbl_df [19,600 x 9] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ Rank : num [1:19600] 1 2 3 4 5 6 7 8 9 10 ... ## $ Name : chr [1:19600] &quot;Wii Sports&quot; &quot;Super Mario Bros.&quot; &quot;Counter-Strike: Global Offensive&quot; &quot;Mario Kart Wii&quot; ... ## $ Platform : chr [1:19600] &quot;Wii&quot; &quot;NES&quot; &quot;PC&quot; &quot;Wii&quot; ... ## $ Publisher : chr [1:19600] &quot;Nintendo&quot; &quot;Nintendo&quot; &quot;Valve&quot; &quot;Nintendo&quot; ... ## $ Developer : chr [1:19600] &quot;Nintendo EAD&quot; &quot;Nintendo EAD&quot; &quot;Valve Corporation&quot; &quot;Nintendo EAD&quot; ... ## $ Critic_Score : num [1:19600] 7.7 10 8 8.2 8.6 10 8 9.4 9.1 8.6 ... ## $ User_Score : num [1:19600] 8 8.2 7.5 9.1 4.7 7.8 8.8 8.8 8.1 9.2 ... ## $ Total_Shipped: num [1:19600] 82.9 40.2 40 37.3 36.6 ... ## $ Year : num [1:19600] 2006 1985 2012 2008 2017 ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. Rank = col_double(), ## .. Name = col_character(), ## .. Platform = col_character(), ## .. Publisher = col_character(), ## .. Developer = col_character(), ## .. Critic_Score = col_double(), ## .. User_Score = col_double(), ## .. Total_Shipped = col_double(), ## .. Year = col_double() ## .. ) ## - attr(*, &quot;problems&quot;)=&lt;externalptr&gt; head(df, 3) ## # A tibble: 3 x 9 ## Rank Name Platform Publisher Developer Critic_Score User_Score Total_Shipped ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Wii ~ Wii Nintendo Nintendo~ 7.7 8 82.9 ## 2 2 Supe~ NES Nintendo Nintendo~ 10 8.2 40.2 ## 3 3 Coun~ PC Valve Valve Co~ 8 7.5 40 ## # ... with 1 more variable: Year &lt;dbl&gt; 数据共包括11列，包含了从1977年~2020年中的游戏销量数据，具体变量说明如下表所示： table_var &lt;- read_excel(&quot;data-intro.xlsx&quot;, sheet = 3) kable(table_var, align = &quot;c&quot;) %&gt;% kable_classic() 变量 说明 Rank 销量排名 Name 游戏名称 Platform 发型平台 Publisher 发行商 Develooper 开发商 Critic_Score 从业人评分 User_Score 用户评分 Total_shipped 总销量(百万套) Year 发型年份 1.2 缺失值处理 summary(df) ## Rank Name Platform Publisher ## Min. : 1 Length:19600 Length:19600 Length:19600 ## 1st Qu.: 4899 Class :character Class :character Class :character ## Median : 9798 Mode :character Mode :character Mode :character ## Mean : 9799 ## 3rd Qu.:14698 ## Max. :19598 ## ## Developer Critic_Score User_Score Total_Shipped ## Length:19600 Min. : 0.800 Min. : 1.000 Min. : 0.0100 ## Class :character 1st Qu.: 6.100 1st Qu.: 6.300 1st Qu.: 0.0500 ## Mode :character Median : 7.300 Median : 7.200 Median : 0.1600 ## Mean : 7.035 Mean : 6.995 Mean : 0.5511 ## 3rd Qu.: 8.200 3rd Qu.: 8.000 3rd Qu.: 0.4600 ## Max. :10.000 Max. :10.000 Max. :82.9000 ## NA&#39;s :9631 NA&#39;s :17377 ## Year ## Min. :1977 ## 1st Qu.:2004 ## Median :2008 ## Mean :2008 ## 3rd Qu.:2012 ## Max. :2020 ## sum(is.na(df)) ## [1] 27010 n_miss(df) ## [1] 27010 数据中有27010个缺失值，而缺失值主要存在与Critic_Score和User_Score，主要原因在于并不是每个用户和从业者都会对游戏进行评分。 需要对其进行一些处理，未打分的我们认为其打分为5.0分，即使用5.0代替所有缺失值。 # 采用每一列的众数替换该列的缺失值 df &lt;- df %&gt;% map_dfc(~replace_na(.x, rstatix::get_mode(.x)[1])) 1.3 描述性分析 描述性统计是一个统计范围，它应用各种技术来描述和总结任何数据集，并研究观察到的数据的一般行为，以促进问题的解决。这可以通过频率表、图形和集中趋势的度量来完成，例如平均值、中位数、众数、离散度量（例如标准偏差、百分位数和四分位数）。 由于2020年只有前半段的数据，我们分析时将2020年的数据剔除，以便更好的分析对比各年份的差异。同时剔除Rank列。 df &lt;- df %&gt;% filter(Year != 2020) %&gt;% select(-Rank) df$Year &lt;- factor(df$Year) 1.3.1 常规分析 1.3.1.1 哪一年的游戏总销量最高 df_shipped &lt;- df %&gt;% select(Year, Total_Shipped) %&gt;% group_by(Year) %&gt;% summarise(count = n()) %&gt;% arrange(desc(count)) p1 &lt;- ggplot(head(df_shipped,10), aes(x = Year, y = count, fill = Year)) + geom_bar(stat = &quot;identity&quot;, alpha = 0.7) + geom_label(aes(label = count), fontface = &quot;bold&quot;, fill = &quot;#006400&quot;, color = &quot;white&quot;, size = 3) + theme_bw() + labs(x = &quot; &quot;, y = &quot; &quot;) + ggtitle(&quot;销量排名前十的年份&quot;) + theme(legend.position = &quot;none&quot;, plot.background = element_rect(color = &quot;black&quot;, size = 1.1), axis.text.x = element_text(face = &quot;bold&quot;), axis.text.y = element_text(face = &quot;bold&quot;), axis.title = element_text(face = &quot;bold&quot;) ) p2 &lt;- ggplot(df_shipped, aes(x = Year, y = count, group = 1)) + geom_point() + geom_line() + theme_bw() + ggtitle(&quot;游戏销量变化&quot;) + labs(x = &quot; &quot;, y = &quot; &quot;) + theme(plot.background = element_rect(color = &quot;black&quot;, size = 1.1), axis.text.x = element_text(face = &quot;bold&quot;, angle = 90)) + geom_curve(x = 40, y = 450, xend = 42, yend = 500, angle = 35, arrow = arrow(length = unit(0.3, &quot;cm&quot;)), color = &quot;red&quot;) + annotate(&quot;text&quot;, x = 42, y = 550, label = &quot;COVID-19&quot;, color = &quot;red&quot;, size = 3) p1/p2 由图??可以看出： - 销量排名前十的年份均在21世纪，且2009年销量最高。2009年之后，游戏销量逐渐下滑，在2011年左右趋于平稳。 2018~2019年，游戏销量急剧下滑。猜测原因为新冠肺炎疫情的爆发导致的游戏产能下降、经济下滑，从而大幅影响了游戏的销量。 下面我们将具体看一下各游戏平台的表现。 1.3.1.2 游戏平台排名（销量、游戏数量） df_platform &lt;- df %&gt;% select(Platform, Total_Shipped) %&gt;% group_by(Platform) %&gt;% summarize(amount = sum(Total_Shipped)) %&gt;% arrange(desc(amount)) %&gt;% head(10) p3 &lt;- ggplot(df_platform, aes(x = reorder(Platform, amount), y = amount, fill = Platform)) + geom_bar(stat = &quot;identity&quot;, alpha = 0.7) + labs(x = &quot; &quot;, y = &quot; &quot;) + ggtitle(&quot;游戏平台排名&quot;, subtitle = &quot;平台销量排名&quot;) + coord_flip() + theme_bw() + theme(legend.position = &quot;none&quot;, axis.text = element_text(face = &quot;bold&quot;), plot.title = element_text(face = &quot;bold&quot;), plot.background = element_rect(color = &quot;black&quot;)) df_platform2 &lt;- as.data.frame(table(df$Platform)) %&gt;% rename(Platform = Var1) %&gt;% arrange(desc(Freq)) %&gt;% head(10) p4 &lt;- ggplot(df_platform2, aes(x = reorder(Platform, Freq), y = Freq, fill = Platform)) + geom_bar(stat = &quot;identity&quot;, alpha = 0.7) + labs(x = &quot; &quot;, y = &quot; &quot;) + ggtitle(&quot;游戏平台排名&quot;, subtitle = &quot;平台游戏数量排名&quot;) + coord_flip() + theme_bw() + theme(plot.background = element_rect(color = &quot;black&quot;), legend.position = &quot;none&quot;, plot.title = element_text(face = &quot;bold&quot;), axis.text = element_text(face = &quot;bold&quot;)) p3|p4 图1.1: 游戏平台排名 由图1.1可以看出： PS2不愧是有史以来最成功的的家用主机，发行在其上的游戏销量排名第一、游戏数量排名第二。 PC游戏仍有一定竞争力。 御三家统治了主机游戏。 下面我们看一下游戏开发商的情况。 1.3.1.3 开发商和发行商排名 df_developer &lt;- df %&gt;% select(Developer, Total_Shipped) %&gt;% group_by(Developer) %&gt;% summarise(amount = sum(Total_Shipped)) %&gt;% arrange(desc(amount)) %&gt;% head(10) p5 &lt;- ggplot(df_developer, aes(x = reorder(Developer, amount), y = amount, fill = Developer)) + geom_bar(stat = &quot;identity&quot;, alpha = 0.7) + coord_flip() + ggtitle(&quot;开发商销量排名&quot;) + labs(x = &quot; &quot;, y = &quot;&quot;) + theme_bw() + theme(legend.position = &quot;none&quot;, plot.background = element_rect(color = &quot;black&quot;)) df_publisher &lt;- df %&gt;% select(Publisher, Total_Shipped) %&gt;% group_by(Publisher) %&gt;% summarise(amount = sum(Total_Shipped)) %&gt;% arrange(desc(amount)) %&gt;% head(10) p6 &lt;- ggplot(df_publisher, aes(x = reorder(Publisher, amount), y = amount, fill = Publisher)) + geom_bar(stat = &quot;identity&quot;, alpha = 0.7) + coord_flip() + ggtitle(&quot;发行商销量排名&quot;) + labs(x = &quot; &quot;, y = &quot;&quot;) + theme_bw() + theme(legend.position = &quot;none&quot;, plot.background = element_rect(color = &quot;black&quot;)) p5|p6 - 任天堂作为开发商和发行商均独占鳌头。 - Game Freak依靠王牌IP精灵宝可梦占据开发商销量第三名。 - 大家耳熟能详的游戏开发商和发行商均有上榜。 1.4 探索性分析 在统计学中，探索性数据分析 (EAD) 是一种分析数据集以总结其主要特征的方法，通常使用可视化方法。 1.4.1 世界最畅销游戏 1.4.1.1 最畅销的5个游戏 那么，1977年~2019年间，到底哪个游戏销量是最高的呢？ options(repr.plot.width = 20, repr.plot.height = 8) df_games &lt;- df %&gt;% select(Name, Total_Shipped) %&gt;% group_by(Name) %&gt;% summarise(amount = sum(Total_Shipped)) %&gt;% arrange(desc(amount)) %&gt;% head(5) p7 &lt;- ggplot(df_games, aes(x = reorder(Name, amount), y = amount, fill = Name)) + geom_col(aes(alpha = 0.9)) + geom_label(aes(label = amount), size = 3, fontface = &quot;bold&quot;, color = &quot;white&quot;) + labs(x = &quot; &quot;, y = &quot; &quot;) + coord_flip() + theme_bw() + theme(legend.position = &quot;none&quot;, plot.background = element_rect(color = &quot;black&quot;, size = 1.1), axis.text.x = element_text( face = &quot;bold&quot;), axis.text.y = element_text(face = &quot;bold&quot;)) p8 &lt;- ggplot(df_games, aes(x = Name, y = amount)) + geom_line(alpha = 0.7, group = 1) + geom_point(aes(fill = Name), shape = 2) + theme_bw()+ theme(legend.position = &quot;none&quot;, plot.background = element_rect(color = &quot;black&quot;), axis.text.x = element_text(face = &quot;bold&quot;)) + labs(x = &quot;&quot;, y = &quot;&quot;) + coord_polar() p7|p8 图1.2: 游戏总销量排名 由图1.2可知： 游戏销量排名前3的游戏为：Wii Sports、GTA5和我的世界。 GTV5和我的世界在多个游戏平台均有发售，Wii Sports为任天堂平台独占。 任天堂游戏平台发售的游戏占前十的大多数，任天堂就是世界的主宰！ 1.4.1.2 最畅销的5个游戏逐年分布 df_games_top5 &lt;- df %&gt;% filter(Name == &quot;Wii Sports&quot; | Name == &quot;Grand Theft Auto V&quot;| Name == &quot;Minecraft&quot;| Name == &quot;Super Mario Bros.&quot;| Name == &quot;Counter-Strike: Global Offensive&quot;) %&gt;% select(Name, Year, Total_Shipped) ggplot(df_games_top5, aes(x = Year, y = Total_Shipped)) + geom_bar(stat = &quot;identity&quot;, aes(fill = Name, color = Name), alpha = 8) + facet_wrap(~Name) + labs(x = &quot;&quot;, y = &quot;总销量（百万套）&quot;) + theme_bw()+ theme(legend.position = &quot;none&quot;, strip.text.x = element_text( margin = margin(7, 7, 7, 7), size = 7, face = &quot;bold&quot;, color = &quot;white&quot;), strip.background = element_rect(fill = &quot;#B45F04&quot;, color = &quot;black&quot;), plot.title = element_text(face = &quot;bold&quot;), axis.text.x = element_text(face = &quot;bold&quot;, angle = 90, vjust = 0.5), axis.text.y = element_text(face = &quot;bold&quot;)) 1.5 媒体打分与玩家打分的关系 俗话说，“低分信媒体，高分信自己”。如果一款游戏媒体打分低，那肯定不行，但如果一个游戏媒体打高分，也不一定好玩（有可能是塞了钱）。 下面我们就分析一下媒体打分与玩家打分的关系。 df_score &lt;- df %&gt;% select(Name, User_Score, Critic_Score) cor &lt;- cor.test(df_score$User_Score, df_score$Critic_Score, method = &quot;pearson&quot;) p.value &lt;- cor$p.value coef &lt;- cor$estimate ggplot(df_score, aes(x = User_Score, y = Critic_Score)) + geom_smooth(method = lm) ## `geom_smooth()` using formula &#39;y ~ x&#39; 可以看到两个打分的相关系数为0.16，且p值小于0.05，表明两者呈现显著的正相关。看来游戏媒体和玩家对游戏的口味还是一样的，某种程度上说，高分也可以信媒体。 1.6 玩家与媒体分别最喜欢哪个发行商 1.6.1 玩家 那么，玩家最喜欢（打分最高）的游戏发行商是谁呢？ df_player &lt;- df %&gt;% select(Publisher, User_Score) df_player$Publisher &lt;- df_player$Publisher %&gt;% map(~ str_detect(.x,&quot;Sony&quot;) %&gt;% ifelse(&quot;Sony&quot;, .x)) %&gt;% unlist() df_player &lt;- df_player%&gt;% group_by(Publisher) %&gt;% summarise(count = n(), mean_score = mean(User_Score)) %&gt;% filter(count &gt;= 50) %&gt;% select(Publisher, mean_score) %&gt;% arrange(desc(mean_score)) df_player ## # A tibble: 62 x 2 ## Publisher mean_score ## &lt;chr&gt; &lt;dbl&gt; ## 1 Rockstar Games 7.84 ## 2 Microsoft Game Studios 7.77 ## 3 Nintendo 7.77 ## 4 Sierra Entertainment 7.72 ## 5 DreamCatcher Interactive 7.71 ## 6 5pb 7.71 ## 7 Sony 7.70 ## 8 Eidos Interactive 7.70 ## 9 Acclaim Entertainment 7.7 ## 10 Agetec 7.7 ## # ... with 52 more rows 在发行过50个以上游戏的老牌发行商中： R星凭借GTA、荒野大镖客等重量级IP以7.842的评分独占鳌头。 所有发行商的评分均超过7分，说明现代游戏的质量还是有保障的。 "],["Olympic-history.html", "2 Olympic history 2.1 介绍 2.2 运动员、国家和时间 2.3 艺术竞赛（The Art Competitions） 2.4 奥林匹克中的女将们 2.5 奖牌榜（Medal Count） 2.6 地理信息地图 2.7 参赛运动员身高体重", " 2 Olympic history 2.1 介绍 本项目的主要目标是阐明奥运会历史的主要模式，例如运动员、运动、参与国家的数量，哪些国家的运动员最多，赢得奖牌情况，运动员的特性（eg：性别、身体特征等）。 我将一些你可能不知道的奥运历史上特别有趣的方面进行放大化。你知道纳粹德国举办了1936年奥运会，而那届奥运会他们打败了所有人？你知道绘画和诗歌曾经是奥运会项目吗？这些历史小花絮同样是我的关注点。 首先，我们读取数据，并对每列的数据类型进行定义。 file&lt;- &quot;D:/Tools/Rwork/0.Study R/kaggle-project/data/olympics/athlete_events.csv&quot; data &lt;- read_csv(file, col_types = cols( ID = col_character(), Name = col_character(), Sex = col_factor(levels = c(&quot;M&quot;,&quot;F&quot;)), Age = col_integer(), Height = col_double(), Weight = col_double(), Team = col_character(), NOC = col_character(), Games = col_character(), Year = col_integer(), Season = col_factor(levels = c(&quot;Summer&quot;,&quot;Winter&quot;)), City = col_character(), Sport = col_character(), Event = col_character(), Medal = col_factor(levels = c(&quot;Gold&quot;,&quot;Silver&quot;,&quot;Bronze&quot;)) )) head(data) ## # A tibble: 6 x 15 ## ID Name Sex Age Height Weight Team NOC Games Year Season City ## &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;fct&gt; &lt;chr&gt; ## 1 1 A Diji~ M 24 180 80 China CHN 1992 ~ 1992 Summer Barc~ ## 2 2 A Lamu~ M 23 170 60 China CHN 2012 ~ 2012 Summer Lond~ ## 3 3 Gunnar~ M 24 NA NA Denma~ DEN 1920 ~ 1920 Summer Antw~ ## 4 4 Edgar ~ M 34 NA NA Denma~ DEN 1900 ~ 1900 Summer Paris ## 5 5 Christ~ F 21 185 82 Nethe~ NED 1988 ~ 1988 Winter Calg~ ## 6 5 Christ~ F 21 185 82 Nethe~ NED 1988 ~ 1988 Winter Calg~ ## # ... with 3 more variables: Sport &lt;chr&gt;, Event &lt;chr&gt;, Medal &lt;fct&gt; 2.2 运动员、国家和时间 2.2.1 随着时间的推移，运动员、国家和赛事的数量是否发生了变化？ counts &lt;- data %&gt;% filter(Sport != &quot;Art Competitions&quot;) %&gt;% # 去掉艺术类的运动类别 group_by(Year, Season) %&gt;% summarize( Athletes = length(unique(ID)), Nations = length(unique(NOC)), Events = length(unique(Event)) ) ## `summarise()` has grouped output by &#39;Year&#39;. You can override using the `.groups` argument. counts ## # A tibble: 51 x 5 ## # Groups: Year [35] ## Year Season Athletes Nations Events ## &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1896 Summer 176 12 43 ## 2 1900 Summer 1224 31 90 ## 3 1904 Summer 650 15 95 ## 4 1906 Summer 841 21 74 ## 5 1908 Summer 2024 22 109 ## 6 1912 Summer 2377 27 102 ## 7 1920 Summer 2665 29 153 ## 8 1924 Summer 3067 44 126 ## 9 1924 Winter 313 19 17 ## 10 1928 Summer 2877 46 109 ## # ... with 41 more rows # 作图 # 运动员数量及关键时间点 p1 &lt;- ggplot(counts, aes(x = Year, y = Athletes, group = Season, color = Season)) + geom_point(size = 2) + geom_line() + scale_color_manual(values = c(&quot;darkorange&quot;, &quot;darkblue&quot;)) + # 手动设置图形颜色 xlab(&quot; &quot;) + annotate(&quot;text&quot;, x = c(1932, 1956, 1976, 1980), y = c(2000, 2750, 6800, 4700), label = c( &quot;L.A. 1932&quot;, &quot;Melbourne 1956&quot;, &quot;Montreal 1976&quot;, &quot;Moscow 1980&quot;), size=3) + # 对几个临界拐点进行标记。 # 针对两次世界大战的时间做出标记 annotate(&quot;text&quot;, x = c(1916,1942), y = c(10000,10000), label = c(&quot;WWI&quot;, &quot;WWII&quot;), size = 4, color = &quot;red&quot;) + geom_segment(aes(x = 1914, y = 8000, xend = 1918, yend = 8000), color = &quot;red&quot;, size = 2) + geom_segment(aes(x = 1939,y = 8000, xend = 1945, yend = 8000), color = &quot;red&quot;, size=2) + scale_x_continuous(breaks = seq(1890, 2020, 4)) + scale_y_continuous(breaks = seq(0, 15000, 5000)) + theme_bw() + theme(axis.text.x = element_text(size = 10, angle = 90, vjust = 0.4, face = &quot;bold&quot;)) # 参与国家数量及关键时间点 p2 &lt;- ggplot(counts, aes(x = Year, y = Nations, group = Season, color = Season)) + geom_point(size = 2) + geom_line() + scale_color_manual(values = c(&quot;darkorange&quot;, &quot;darkblue&quot;)) + xlab(&quot;&quot;) + annotate(&quot;text&quot;, x = c(1932, 1976, 1980), y = c(60, 105, 70), label = c(&quot;L.A. 1932&quot;, &quot;Montreal 1976&quot;, &quot;Moscow 1980&quot;)) + scale_x_continuous(breaks = seq(1890, 2020, 4)) + scale_y_continuous(breaks = seq(0, 250, 50)) + theme_bw() + theme(axis.text.x = element_text(size = 10, angle = 90, vjust = 0.4, face = &quot;bold&quot;)) # 参赛项目 p3 &lt;- ggplot(counts, aes(x = Year, y = Events, group = Season, color = Season)) + geom_point(size = 2) + geom_line() + scale_color_manual(values = c(&quot;darkorange&quot;, &quot;darkblue&quot;)) + scale_x_continuous(breaks = seq(1890, 2020, 4)) + scale_y_continuous(breaks = seq(0, 350, 50)) + theme_bw() + theme(axis.text.x = element_text(size = 10, angle = 90, vjust = 0.4, face = &quot;bold&quot;)) grid.arrange(p1, p2, p3, ncol = 1) 图2.1: 随着时间的推移，运动员、国家和赛事的数量的变化情况 从图2.1 可以看出两次世界大战期间，奥运会基本处于停滞状态（WWI:1912-1920，WWII:1936-1948）。此外，有几届值得注意的奥运会上发生了一些事件，在图形中呈现为明显的下降趋势： L.A., 1932: 1932年洛杉矶奥运会，当时的美国正处于大萧条期间，许多运动员没办法负担到奥运会的差旅费用，导致参加本届奥运会的国家机器运动员数量骤降。 Melbourne, 1956：1956年墨尔本奥运会是事端最多的一届奥运会：1、由于战争立场不同，包括埃及、以色列、伊拉克和黎巴嫩在内的一些中东及非洲国家，西班牙、荷兰、瑞士、哥伦比亚等欧洲国家均抵制本届奥运会；2.由于台湾问题，我国也未参加本届奥运会。 Montreal, 1976：1976年蒙特利尔奥运会，由于发生了抵制运动，25个国家（大部分为非洲国家）未参加本届奥运会。 Moscow, 1980：1980年莫斯科奥运会，由于苏联军队对阿富汗的入侵，包括美国在内的66个国家对本届奥运会进行了抵制，本届奥运会最终仅有80个国家参加，是自1956年以来最少国家参加的一届，而许多参赛的国家也只派一名旗手，以奥运会会旗代替国旗进场。这是奥运历史上最严重的一次危机，从一定程度上威胁了奥林匹克运动的发展。 从2000年开始，奥运会的增长势头（比赛项目额参赛运动员数量）趋于平缓，夏季奥运会迎来了它的饱和点。而冬季奥运会处于虽然还有一定上升空间，但冰雪运动受限于气候和场地，在很多国家并不普吉，所以其涨势并不明显。 2.3 艺术竞赛（The Art Competitions） 2.3.1 运动员、时间、参赛项目 art &lt;- data %&gt;% filter(Sport == &quot;Art Competitions&quot;) %&gt;% select(Name, Sex, Age, Team, NOC, Year, City, Event, Medal) head(art) ## # A tibble: 6 x 9 ## Name Sex Age Team NOC Year City Event Medal ## &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; ## 1 Win Valdemar Aaltonen M 54 Finland FIN 1948 London Art C~ &lt;NA&gt; ## 2 Adolf Gaston Abel M 45 Germany GER 1928 Amsterdam Art C~ &lt;NA&gt; ## 3 Adolf Gaston Abel M 45 Germany GER 1928 Amsterdam Art C~ &lt;NA&gt; ## 4 Georges Achille-Fould F 55 France FRA 1924 Paris Art C~ &lt;NA&gt; ## 5 Dsir Antoine Acket M 27 Belgium BEL 1932 Los Angeles Art C~ &lt;NA&gt; ## 6 Dsir Antoine Acket M 27 Belgium BEL 1932 Los Angeles Art C~ &lt;NA&gt; # 基础计算 count_art &lt;- art %&gt;% group_by(Year) %&gt;% summarize( Events = length(unique(Event)), Nations = length(unique(Team)), Artists = length(unique(Name)) ) head(count_art) ## # A tibble: 6 x 4 ## Year Events Nations Artists ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1912 5 12 33 ## 2 1920 5 5 11 ## 3 1924 5 24 189 ## 4 1928 13 19 370 ## 5 1932 13 36 588 ## 6 1936 19 24 527 在最初的奥运会中，还存在艺术竞赛（Art Competition）项目的比拼，准确的说从1912年至1948年间的几届奥运会。 1954年，国际奥委会决定艺术竞赛不再作为奥运会的比赛项目。 虽然艺术竞赛的数据仅占本数据集的1.3%，但考虑到其在奥运会理事上的特殊意义，仍有必要对其进行探索分析。 # 提取有关艺术竞赛的数据 art &lt;- data %&gt;% filter(Sport == &quot;Art Competitions&quot;) %&gt;% select(Name, Sex, Age, Team, NOC, Year, City, Event, Medal) # 计算每年的Events, Nations, Artists数量 counts_art &lt;- art %&gt;% filter(Team != &quot;Unknow&quot;) %&gt;% # 剔除国籍不确定的运动员 group_by(Year) %&gt;% summarize( Events = length(unique(Event)), Nations = length(unique(Team)), Artisit = length(unique(Name)) ) p4 &lt;- ggplot(counts_art, aes(x = Year, y = Events)) + geom_point(size = 2) + geom_line() + xlab(&quot; &quot;) + scale_x_continuous(breaks = seq(min(counts_art[&quot;Year&quot;]), max(counts_art[&quot;Year&quot;]), 4)) + scale_y_continuous(breaks = seq(0, 20, 2)) + theme_bw() + theme(axis.text.x = element_text(size = 10, vjust = 0.4, face = &quot;bold&quot;)) p5 &lt;- ggplot(counts_art, aes(x = Year, y = Nations)) + geom_point(size = 2) + geom_line() + xlab(&quot; &quot;) + scale_x_continuous(breaks = seq(min(counts_art[&quot;Year&quot;]), max(counts_art[&quot;Year&quot;]), 4)) + scale_y_continuous(breaks = seq(0, 40, 5)) + theme_bw() + theme(axis.text.x = element_text(size = 10, vjust = 0.4, face = &quot;bold&quot;)) p6 &lt;- ggplot(counts_art, aes(x = Year, y = Artisit)) + geom_point(size = 2) + geom_line() + xlab(&quot; &quot;) + scale_x_continuous(breaks = seq(min(counts_art[&quot;Year&quot;]), max(counts_art[&quot;Year&quot;]), 4)) + scale_y_continuous(breaks = seq(0, 600, 100)) + theme_bw() + theme(axis.text.x = element_text(size = 10, vjust = 0.4, face = &quot;bold&quot;)) grid.arrange(p4, p5, p6, ncol = 1) 图2.2: 历届奥运会艺术竞赛随时间变化图（参与国家、参赛运动员、比赛项目） 如图2.2所示，艺术竞赛的数据变化呈不规则的增长趋势。可以看到，与1920年相比，1924年奥运会参与艺术竞赛的国家和运动员数量均有相对较大幅度的增长，这或许是1928年奥运会艺术竞赛比赛项目增多的一个原因。 2.3.2 获得奖牌情况-哪个国家获得的艺术竞赛类奖牌数量最多 # 计算每个国家所获奖牌数量 medal_counts_arts &lt;- art %&gt;% filter(!is.na(Medal)) %&gt;% group_by(Team, Medal) %&gt;% summarize(Count = length(Medal)) ## `summarise()` has grouped output by &#39;Team&#39;. You can override using the `.groups` argument. # 根据奖牌数量对国家进行排序 levs_art &lt;- medal_counts_arts %&gt;% group_by(Team) %&gt;% summarize(Total = sum(Count)) %&gt;% arrange(Total) %&gt;% select(Team) medal_counts_arts$Team &lt;- factor(medal_counts_arts$Team, levels = levs_art$Team) ggplot(medal_counts_arts, aes(x = Team, y = Count, fill = Medal)) + geom_col() + coord_flip() + scale_y_continuous(breaks = seq(0, 30, 5)) + scale_fill_manual(values = c(&quot;gold1&quot;, &quot;gray70&quot;, &quot;gold4&quot;)) + ggtitle(&quot;艺术竞赛奖牌榜&quot;) + theme(plot.title = element_text(hjust = 0.5)) 图2.3: 各国艺术竞赛奖牌榜 art_country &lt;- nrow(unique(art[&quot;Team&quot;])) art_country_medal &lt;- nrow(medal_counts_arts %&gt;% summarize(country = length(unique(Team))) ) 共有51个国家参加了奥运会的艺术竞赛类项目，仅有不到一半数量的国家（23）获得了奖牌（如图2.3所示），排名前三位的为德国、法国、意大利。 2.4 奥林匹克中的女将们 现代奥林匹克之父顾拜旦曾今极力反对女性参加奥运会。其后的IOC主席也同样支持这个观点。尽管有多方面的阻力，从第一届奥运会（1896年）开始的每届奥运会均有女性参与其中。所以我们在这里探索一下女性参加奥运会的历史趋势：多少人？从哪里来？她们如何找到途经参加的？ 本部分中，对数据集进行如下处理： 将第@sec:art-com节中讨论过的艺术竞赛数据剔除。 将夏季和冬季奥运会合并为“Olympiads”列，即每四年期内包括一届夏季奥运会和一届冬季奥运会。 让我们开始！ 2.4.1 男女运动员数量比较 # 剔除艺术竞赛项目数据 data &lt;- data %&gt;% filter(Sport != &quot;Art Competition&quot;) # 对Year列数据重新编码（1992年之后，与夏季奥运会匹配） # 处理后，冬季和夏季奥运会举办时间的已匹配 original &lt;- c(1994, 1998, 2002, 2006, 2010, 2014) new &lt;- c(1996, 2000, 2004, 2008, 2012, 2016) for (i in 1:length(original)) { data$Year &lt;- gsub(original[i], new[i], data$Year) } data$Year &lt;- as.integer(data$Year) counts_sex &lt;- data %&gt;% group_by(Year, Sex) %&gt;% summarize(Athletes = length(unique(ID))) ## `summarise()` has grouped output by &#39;Year&#39;. You can override using the `.groups` argument. counts_sex$Year &lt;- as.integer(counts_sex$Year) ggplot(counts_sex, aes(x = Year, y = Athletes, group = Sex, color = Sex)) + geom_point(size = 2) + geom_line() + scale_color_manual(values = c(&quot;darkblue&quot;, &quot;red&quot;)) + scale_x_continuous(breaks = seq(1896, 2016, 4)) + scale_y_continuous(breaks = seq(0, 9000, 500)) + labs(title = &quot;Number of male and female Olympians over time&quot;) + theme_bw() + theme(plot.title= element_text(hjust = 0.5), axis.text.x = element_text(angle = 90, face = &quot;bold&quot;, vjust = 0.5)) 图2.4: 历届奥运会南云运动员数量 counts_sex_latest &lt;- counts_sex %&gt;% filter(Year == 2016) counts_sex_latest ## # A tibble: 2 x 3 ## # Groups: Year [1] ## Year Sex Athletes ## &lt;int&gt; &lt;fct&gt; &lt;int&gt; ## 1 2016 M 7788 ## 2 2016 F 6133 如图2.4所示，直到1996年，参加奥运会的女运动员数量的变化趋势都与男运动员相同，此时男运动员的数量达到8000人的最顶点，而此时女运动员的数量还在以一个较高的增长率上升。最近的一届奥运会（2014年索契冬奥会和2016年里约奥运会中），女运动的数量已经超过了0.4405574。 2.4.2 各国参赛男女运动员间数量关系 选择1936，1956，1976，1996，2016五个年份的数据进行分析。这五年的数据互相间隔20年，可以独立的展示独立的回归曲线。 # Count M/F Total per country per Olympics counts_NOC &lt;- data %&gt;% filter(Year %in% c(1936, 1956, 1976, 1996, 2016)) %&gt;% group_by(Year, NOC, Sex) %&gt;% summarize(Count = length(unique(ID))) %&gt;% spread(Sex, Count) %&gt;% # 按照Sex为key，Count为value的规则进行pivot_wider()操作。 mutate(Total = sum(M, F, na.rm = T)) # 计算运动员总数 ## `summarise()` has grouped output by &#39;Year&#39;, &#39;NOC&#39;. You can override using the `.groups` argument. names(counts_NOC)[3: 4] &lt;- c(&quot;Male&quot;, &quot;Female&quot;) # 将缺失值变为0 counts_NOC$Male[is.na(counts_NOC$Male)] &lt;- 0 counts_NOC$Female[is.na(counts_NOC$Female)] &lt;- 0 counts_NOC$Year &lt;- as.factor(counts_NOC$Year) # 将Year列转化为因子 counts_NOC ## # A tibble: 622 x 5 ## # Groups: Year, NOC [622] ## Year NOC Male Female Total ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1936 AFG 15 0 15 ## 2 1936 ARG 50 1 51 ## 3 1936 AUS 29 4 33 ## 4 1936 AUT 265 27 292 ## 5 1936 BEL 168 8 176 ## 6 1936 BER 5 0 5 ## 7 1936 BOL 2 0 2 ## 8 1936 BRA 67 6 73 ## 9 1936 BUL 33 0 33 ## 10 1936 CAN 101 25 126 ## # ... with 612 more rows ggplot(counts_NOC, aes(x = Male, y = Female, group = Year, color = Year)) + geom_point(alpha = 0.5) + geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;) + geom_smooth(method = &quot;lm&quot;, se = FALSE) ## `geom_smooth()` using formula &#39;y ~ x&#39; 图2.5: 各国参加奥运会男女运动员比例关系 从图2.5可以看出，与1936-1956年间女运动员的数量增长数量较为缓慢相比，1956-2016年间，女运动员的参赛人数有了明显的提升。从回归曲线（虚线）可以看出，在1996年及2016年，部分国家甚至派出了女性占大多数的参赛代表团。 2.5 奖牌榜（Medal Count） # 按奖牌多少的顺序计算各国奖牌榜 medalCount &lt;- data %&gt;% filter(!is.na(Medal)) %&gt;% filter(Sport != &quot;Art Competitions&quot;) %&gt;% group_by(Team, Medal) %&gt;% summarize(Count = length(Medal)) ## `summarise()` has grouped output by &#39;Team&#39;. You can override using the `.groups` argument. medalCountLevs &lt;- medalCount %&gt;% group_by(Team) %&gt;% summarize(Total = sum(Count)) %&gt;% arrange(Total) %&gt;% select(Team) %&gt;% tail(25) medalCount$Team &lt;- factor(medalCount$Team, levels = medalCountLevs$Team) medalCount &lt;- medalCount %&gt;% filter(Team != &quot;NA&quot;) ggplot(medalCount, aes(x = Team, y = Count, fill = Medal)) + geom_col() + coord_flip() + scale_fill_manual(values = c(&quot;gold1&quot;, &quot;gray70&quot;, &quot;gold4&quot;)) + ggtitle(&quot;Olympics Medal Tally&quot;) + theme(plot.title = element_text(hjust = 0.5)) 图2.6: 各国历史奖牌榜前50名的国家 图2.6显示，美国所获的奖牌数最多，而且远多于第二名的苏联。中国排在日本之后，排名第16位。进一步我们看一下中国的奖牌数变化。 medalChina &lt;- data %&gt;% filter(!is.na(Medal)&amp;Sport != &quot;Art Competitions&quot;&amp;Team == &quot;China&quot;) %&gt;% group_by(Year, Medal) %&gt;% summarize(Count = length(Medal)) ## `summarise()` has grouped output by &#39;Year&#39;. You can override using the `.groups` argument. ggplot(medalChina, aes(x = reorder(Year, -Count), y = Count, fill = Medal)) + geom_col() + scale_fill_manual(values = c(&quot;gold1&quot;, &quot;gray70&quot;, &quot;gold4&quot;)) + xlab(&quot; &quot;) + ylab(&quot;奖牌数&quot;) + theme_bw() 图2.7: 历届奥运会中国奖牌数量变化 图2.7显示，2008年北京奥运会，中国获得奖牌数最多。1988年汉城奥运会，由于苏联、德国等国家重新参加比赛，竞争明显大于1984年奥运会，导致中国获得奖牌数最少，仅5枚金牌。 2.6 地理信息地图 本部分我们聚焦夏季奥运会，在世界地图上呈现各国参加奥运会人数的变化情况。选取最近的一届2016年奥运会以及分别相隔44年的1972年慕尼黑奥运会和1928年阿姆斯特丹奥运会。 2.6.1 1928年奥运会情况 # 读取NOC数据 noc &lt;- read_csv(&quot;D:/Tools/Rwork/0.Study R/kaggle-project/data/olympics/noc_regions.csv&quot;, col_types = cols( NOC = col_character(), region = col_character() )) ## New names: ## * Australia -&gt; Australia...18 ## * Australia -&gt; Australia...28 ## * `Czech Republic` -&gt; `Czech Republic...56` ## * Canada -&gt; Canada...76 ## * China -&gt; China...86 ## * ... # 增加regions数据，去除缺失值 dataRegions &lt;- data %&gt;% left_join(noc, by = &quot;NOC&quot;) %&gt;% filter(!is.na(region)) # 将选择的三届奥运会的数据筛选出来 amsterdam &lt;- dataRegions %&gt;% filter(Games== &quot;1928 Summer&quot;) %&gt;% group_by(region) %&gt;% summarize(Amsterdam = length(unique(ID))) munich &lt;- dataRegions %&gt;% filter(Games == &quot;1972 Summer&quot;) %&gt;% group_by(region) %&gt;% summarize(Munich = length(unique(ID))) rio &lt;- dataRegions %&gt;% filter(Games == &quot;2016 Summer&quot;) %&gt;% group_by(region) %&gt;% summarize(Rio = length(unique(ID))) # 建立地图 world &lt;- map_data(&quot;world&quot;) mapdat &lt;- tibble(region = unique(world$region)) # 提取国家列 mapdat &lt;- mapdat %&gt;% left_join(amsterdam, by = &quot;region&quot;) %&gt;% left_join(munich, by = &quot;region&quot;) %&gt;% left_join(rio, by = &quot;region&quot;) mapdat$Amsterdam[is.na(mapdat$Amsterdam)] &lt;- 0 mapdat$Munich[is.na(mapdat$Munich)] &lt;- 0 mapdat$Rio[is.na(mapdat$Rio)] &lt;- 0 world &lt;- left_join(world, mapdat, by = &quot;region&quot;) # 1928 ggplot(world, aes(x = long, y = lat, group = group)) + geom_polygon(aes(fill = Amsterdam)) + labs(title = &quot;Amsterdam 1928&quot;, x = NULL, y = NULL) + theme(axis.ticks = element_blank(), axis.text = element_blank(), panel.background = element_rect(fill = &quot;navy&quot;), plot.title = element_text(hjust = 0.5)) + guides(fill = guide_colorbar(title = &quot;Athletes&quot;)) + scale_fill_gradient(low = &quot;white&quot;, high = &quot;red&quot;) 2.6.2 1972年奥运会情况 ggplot(world, aes(x = long, y = lat, group = group)) + geom_polygon(aes(fill = Munich)) + labs(title = &quot;Munich 1972&quot;, x = NULL, y = NULL) + theme(axis.ticks = element_blank(), axis.text = element_blank(), panel.background = element_rect(fill = &quot;navy&quot;), plot.title = element_text(hjust = 0.5)) + guides(fill = guide_colorbar(title = &quot;Athletes&quot;)) + scale_fill_gradient2(low = &quot;white&quot;, high = &quot;red&quot;) 2.6.3 2016年奥运会情况 ggplot(world, aes(x = long, y = lat, group = group)) + geom_polygon(aes(fill = Rio)) + labs(title = &quot;Rio 2016&quot;, x = NULL, y = NULL) + theme(axis.ticks = element_blank(), axis.text =element_blank(), panel.background = element_rect(fill = &quot;navy&quot;), plot.title = element_text(hjust = 0.5)) + guides(fill = guide_colorbar(title = &quot;Athletes&quot;)) + scale_fill_gradient2(low = &quot;white&quot;, high = &quot;red&quot;) 2.7 参赛运动员身高体重 更高、更快、更强是奥运会的座右铭，而每届奥运会的参赛运动员似乎也比之前奥运会更快更强。要验证这个观点，我们需要通过本数据探索历届奥运会运动员身高及体重的变化趋势。 2.7.1 数据完整性及可用性检测 data %&gt;% group_by(Year, Sex) %&gt;% summarize(Present = length(unique(ID[which(!is.na(Height)&amp;!is.na(Weight))])), Total = length(unique(ID))) %&gt;% mutate(Proportion = Present/Total) %&gt;% ggplot(aes(x = Year, y = Proportion, group = Sex, color = Sex)) + geom_point() + geom_line() + scale_color_manual(values = c(&quot;darkblue&quot;, &quot;red&quot;)) + theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(face = &quot;bold&quot;, angle = 90)) + labs(title = &quot;Height/Weight data completeness from each Olympics&quot;) + scale_x_continuous(breaks = seq(1896, 2016, 4)) ## `summarise()` has grouped output by &#39;Year&#39;. You can override using the `.groups` argument. 图2.8: Height/Weight data completeness from each Olympics 图2.8所示，1960年，数据的完整性有一个巨大的飞跃，且从本届奥运会开始，数据的完整性均超过了85%（除1992年外）。鉴于此，我们选取从1960年开始的数据，共包括56年间的15届奥运会。 data &lt;- data %&gt;% filter(!is.na(Height), !is.na(Weight), Year&gt; 1959) 2.7.2 身高体重 pHeight &lt;- ggplot(data, aes(x = as.factor(Year), y = Height, fill = Sex)) + geom_boxplot(alpha = 0.75) + xlab(&quot;Olympiad Year&quot;) + ylab(&quot;Height(cm)&quot;) + scale_fill_manual(values = c(&quot;blue&quot;, &quot;red&quot;)) pWeight &lt;- ggplot(data, aes(x = as.factor(Year), y = Weight, fill = Sex)) + geom_boxplot(alpha = 0.75) + xlab(&quot;Olympiad Year&quot;) + ylab(&quot;Weight(kg)&quot;) + scale_fill_manual(values = c(&quot;blue&quot;, &quot;red&quot;)) grid.arrange(pHeight, pWeight,ncol = 1) 图2.9: Athlete height &amp; weight over time 图2.9显示，运动员身高体重（包括男女）均呈现稳步上升的趋势。但是，由于不同运动项目要求体型不同，图2.9可能隐藏了一些重要的变化规律。因此，必须进一步深入探索不同项目中身高体重数据变化的趋势。然而，在奥运会的历史上，运动项目是不断变化的，首先，必须筛选出1960~2016年间奥运会都设立的比赛项目。 # 筛选1960年奥运会的项目 events &lt;- data[data$Year == 1960, &quot;Event&quot;] %&gt;% unique %&gt;% .$Event years &lt;- data$Year %&gt;% unique %&gt;% sort %&gt;% tail(-1) for (i in 1:length(years)) { nxt &lt;- data[data$Year == years[i], &quot;Event&quot;] %&gt;% unique %&gt;% .$Event events &lt;- intersect(events, nxt) } # 按照1960年项目对之后的项目进行筛选 data &lt;- data %&gt;% filter(Event %in% events) # get list of sports matching events sportsEvents &lt;- data %&gt;% select(Sport, Event) %&gt;% unique 2.7.3 change in Weight VS change in Height over times across men’s sports # 剔除摔跤、举重、拳击、马术 sportsEvents &lt;- sportsEvents %&gt;% filter(!Sport %in% c(&quot;Wrestling&quot;, &quot;Weightlifting&quot;, &quot;Boxing&quot;, &quot;Equestrianism&quot;)) %&gt;% filter(!Event %in% c(&quot;Figure Skating Mixed Pairs&quot;)) %&gt;% arrange(Sport) # 增加一列 men/women/mixed 区分男女项目 sportsEvents$Sex &lt;- ifelse(grepl(&quot;Women&quot;, sportsEvents$Event), &quot;Women&quot;, &quot;Men&quot;) # 创建循环，进行回归 s.height &lt;- s.weight &lt;- c() for (i in 1:nrow(sportsEvents)) { temp &lt;- data %&gt;% filter(Event == sportsEvents$Event[i]) lm.height &lt;- lm(Height ~ Year, data = temp) lm.weight &lt;- lm(Weight ~ Year, data = temp) s.height[i] &lt;- lm.height$coefficients[&quot;Year&quot;] s.weight[i] &lt;- lm.weight$coefficients[&quot;Year&quot;] } slopes &lt;- tibble(Sport = sportsEvents$Sport, Event = sportsEvents$Event, Sex = sportsEvents$Sex, Height = s.height, Weight = s.weight) "],["HR-comma-sep.html", "3 员工离职分析 3.1 描述性分析 3.2 建模预测1-回归树+混淆矩阵 3.3 建模预测2-朴素贝叶斯 3.4 模型评估及应用 3.5 模型应用", " 3 员工离职分析 3.1 描述性分析 3.1.1 数据概览 hr &lt;- read.csv(&quot;data/HR_comma_sep.csv&quot;) summary(hr) ## satisfaction_level last_evaluation number_project average_montly_hours ## Min. :0.0900 Min. :0.3600 Min. :2.000 Min. : 96.0 ## 1st Qu.:0.4400 1st Qu.:0.5600 1st Qu.:3.000 1st Qu.:156.0 ## Median :0.6400 Median :0.7200 Median :4.000 Median :200.0 ## Mean :0.6128 Mean :0.7161 Mean :3.803 Mean :201.1 ## 3rd Qu.:0.8200 3rd Qu.:0.8700 3rd Qu.:5.000 3rd Qu.:245.0 ## Max. :1.0000 Max. :1.0000 Max. :7.000 Max. :310.0 ## time_spend_company Work_accident left promotion_last_5years ## Min. : 2.000 Min. :0.0000 Min. :0.0000 Min. :0.00000 ## 1st Qu.: 3.000 1st Qu.:0.0000 1st Qu.:0.0000 1st Qu.:0.00000 ## Median : 3.000 Median :0.0000 Median :0.0000 Median :0.00000 ## Mean : 3.498 Mean :0.1446 Mean :0.2381 Mean :0.02127 ## 3rd Qu.: 4.000 3rd Qu.:0.0000 3rd Qu.:0.0000 3rd Qu.:0.00000 ## Max. :10.000 Max. :1.0000 Max. :1.0000 Max. :1.00000 ## sales salary ## Length:14999 Length:14999 ## Class :character Class :character ## Mode :character Mode :character ## ## ## 观察各个变量的主要描述统计量，可知： 离职率（left）平均将近24%。 对公司的满意度（satisfaction_level）仅有62%左右。 平均每个人参加过的项目数（number_project）仅为3~4个。 员工每月平均工作时间（average_montly_hours）达到201.1小时，按照每月工作20天（去除8天双休）计算，每个员工平均每天工作超过10小时。 3.1.2 员工离职情况与员工满意度、月均工作时间、绩效评估和在职年限的关系 我们通过绘图观察离职员工的特点。 hr$left &lt;- factor(hr$left, levels = c(&quot;0&quot;, &quot;1&quot;)) # 离职率与公司满意度关系 boxSat &lt;- ggplot(hr, aes(x = left, y = satisfaction_level, fill = left)) + geom_boxplot() + theme_bw() + labs(x = &quot;离职情况&quot;, y = &quot;员工满意度&quot;) + guides(fill = guide_legend(title = &quot;离职情况&quot;)) # 离职率与绩效评估的关系 boxEva &lt;- ggplot(hr, aes(x = left, y = last_evaluation, fill = left)) + geom_boxplot() + theme_bw() + labs(x = &quot;离职情况&quot;, y = &quot;绩效评估&quot;) + guides(fill = guide_legend(title = &quot;离职情况&quot;)) # 离职率与月均工作时间的关系 boxMonth &lt;- ggplot(hr, aes(x = left, y = average_montly_hours, fill = left)) + geom_boxplot() + theme_bw()+ labs(x = &quot;离职率&quot;, y = &quot;月均工作时间&quot;) + guides(fill = guide_legend(title = &quot;离职情况&quot;)) # 离职率与工作年限的关系 boxTime &lt;- ggplot(hr, aes(x = left, y = time_spend_company, fill = left)) + geom_boxplot() + theme_bw() + labs(x = &quot;离职率&quot;, y = &quot;在职年限&quot;) + guides(fill = guide_legend(title = &quot;离职情况&quot;)) boxSat/boxEva |boxMonth/boxTime 图3.1: 员工离职情况与员工满意度、月均工作时间、绩效评估和在职年限的关系。 由图3.1可以看出，离职员工的几个特点： 左上图：离职员工的满意度明显低于未离职的满意度，大都集中于0.4左右。 左下图：离职员工的绩效评估较高。推测离职员工倾向于寻找待遇更好的工作。 右上图：离职员工的月均工作时长较高，大部分超过了平均水平（200小时）。 右下图：工作年限均在4年左右。 3.1.3 员工离职情况与项目参与个数、五年内升职情况和薪资的关系 hr$number_project &lt;- factor(hr$number_project, levels = c(&quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;)) # 离职与参与项目数关系 barProject &lt;- ggplot(hr, aes(x = number_project, fill = left)) + geom_bar(position = &quot;fill&quot;) + # fill为百分比条形图 theme_bw() + labs(x = &quot;参与项目数&quot;, y = &quot;比例&quot;) + guides(fill = guide_legend(title = &quot;离职情况&quot;)) # 离职与升职情况关系 hr$promotion_last_5years[hr$promotion_last_5years == 1] &lt;- &quot;已升职&quot; hr$promotion_last_5years[hr$promotion_last_5years == 0] &lt;- &quot;未升职&quot; bar5years &lt;- ggplot(hr, aes(x = as.factor(promotion_last_5years), fill = left)) + geom_bar(position = &quot;fill&quot;) + theme_bw() + labs(x = &quot;5年内升职情况&quot;, y = &quot;比例&quot;) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + guides(fill = guide_legend(title = &quot;离职情况&quot;)) # 离职与薪资关系 barSalary &lt;- ggplot(hr, aes(x = factor(salary, levels = c(&quot;low&quot;, &quot;medium&quot;, &quot;high&quot;), ordered=TRUE), fill = left)) + geom_bar(position = &quot;fill&quot;) + theme_bw() + labs(x = &quot;薪资情况&quot;, y = &quot;比例&quot;) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + guides(fill = guide_legend(title = &quot;离职情况&quot;)) barProject|bar5years |barSalary 图3.2: 员工离职情况与项目参与个数、五年内升职情况和薪资的关系。 由图3.2可以看出，离职员工的几个特点： 参与项目过少（2个）与过多（7个）的员工离职率均比较高。且参与项目在3个及以上时，参与项目越多，离职率越高。 5年内未升职的员工离职率较高。 薪资越低，离职率越高。 3.2 建模预测1-回归树+混淆矩阵 建模的思路： 提取所需数据。 定义交叉验证方法。 进行分层抽样，提取出想要的训练集和测试集。 实际建模。 对数据进行预测（利用混淆矩阵的方式）。 3.2.1 提取数据 选择符合条件的样本。通过绩效评估、在职时间和参与项目数筛选出更有代表性的样本数据进行分析。 按照绩效评估、在职时间、参与项目数量 hr_model &lt;- hr %&gt;% filter(last_evaluation &gt;= 0.70 | time_spend_company&gt;=4 | number_project&gt;=5) ## Warning in Ops.factor(number_project, 5): &#39;&gt;=&#39; not meaningful for factors 3.2.2 确定交叉验证方法 # cv为设置交叉验证方法，number = 5为5折交叉验证。 train_control &lt;- trainControl(method = &quot;cv&quot;, number = 5) 3.2.3 分层抽样1 # 设定随机种子，确保每次抽样结果一致。 set.seed(1234) # 根据数据因变量进行7:3的分层抽样，返回行索引向量 p = 0.7为按照7：3进行抽样 # 参数list表示返回值是否为列表 index &lt;- createDataPartition(hr_model$left, p = 0.7, list = F) # 以index为索引的数据为训练集 # 剩余的数据为测试集 trainData &lt;- hr_model[index, ] testData &lt;- hr_model[-index, ] 3.2.4 实际建模 使用carte包中的train函数对训练集进行5折交叉验证建立回归树模型。 # left~. 代表因变量left与所有自变量进行建模。 rpartmodel &lt;- train(left~., data = trainData, trControl = train_control, method = &quot;rpart&quot;) 利用建立好的模型rpartmodel对测试集进行预测。 # testdata[-7]剔除left列。 predRpart &lt;- predict(rpartmodel, testData[-7]) 建立混淆矩阵，验证建立的模型。 conPart &lt;- table(predRpart, testData$left) conPart ## ## predRpart 0 1 ## 0 2246 72 ## 1 51 528 混淆矩阵：混淆矩阵的每一列代表了预测类别，每一列的总数表示预测为该类别的数据的数目；每一行代表了数据的真实归属类别，每一行的数据总数表示该类别的数据实例的数目。根据查全率和查准率两个参数判断模型拟合结果是否够好。 混淆矩阵的查准率和查全率是两个重要的参数，具体计算公式如下式(3.1)： \\[\\begin{align} 查准率=\\frac{真正例}{真正例+假正例} \\\\ 查全率=\\frac{真正例}{真正例+假反例} \\tag{3.1} \\end{align}\\] 根据混淆矩阵结果，可以得到回归树模型的： 查准率为91.19 %。 查全率为88 %。 回归模型的拟合效果不错。 3.3 建模预测2-朴素贝叶斯 建模步骤与第3.2小结基本相同，下面只列出代码及结果。 nbModel &lt;- train(left~., data = trainData, trControl = train_control, method = &quot;nb&quot;) ## Warning: model fit failed for Fold1: usekernel=FALSE, fL=0, adjust=1 Error in NaiveBayes.default(x, y, usekernel = FALSE, fL = param$fL, ...) : ## Zero variances for at least one class in variables: number_project7 ## Warning: model fit failed for Fold2: usekernel=FALSE, fL=0, adjust=1 Error in NaiveBayes.default(x, y, usekernel = FALSE, fL = param$fL, ...) : ## Zero variances for at least one class in variables: number_project7 ## Warning: model fit failed for Fold3: usekernel=FALSE, fL=0, adjust=1 Error in NaiveBayes.default(x, y, usekernel = FALSE, fL = param$fL, ...) : ## Zero variances for at least one class in variables: number_project7 ## Warning: model fit failed for Fold4: usekernel=FALSE, fL=0, adjust=1 Error in NaiveBayes.default(x, y, usekernel = FALSE, fL = param$fL, ...) : ## Zero variances for at least one class in variables: number_project7 ## Warning: model fit failed for Fold5: usekernel=FALSE, fL=0, adjust=1 Error in NaiveBayes.default(x, y, usekernel = FALSE, fL = param$fL, ...) : ## Zero variances for at least one class in variables: number_project7 ## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, : ## There were missing values in resampled performance measures. ## Warning in train.default(x, y, weights = w, ...): missing values found in ## aggregated results predNb &lt;- predict(nbModel, testData[-7]) conNb &lt;- table(predNb, testData$left) conNb ## ## predNb 0 1 ## 0 2248 146 ## 1 49 454 根据公式(3.1)，计算得到朴素贝叶斯模型的： 查准率为90.26 %。 查全率为75.67 %。 通过两种模型的评估，我们发现回归树模型的拟合度比朴素贝叶斯更好，所以接下来我们采用回归数模型进行进一步分析。 3.4 模型评估及应用 本部分使用ROC曲线的方法对模型进行评估。具体步骤如下： 根据建模预测的结果对样例进行排序。 按照排序逐个把样本作为正例进行预测，每次计算出两个重要的值（分别为假正例率和真正例率，具体计算公式见下式(3.2)。 \\[\\begin{align} 假正例率 = \\frac{假正例}{假正例+真反例} \\\\ 真正例率 = \\frac{真正例}{真正例+假反例}(查全率) \\tag{3.2} \\end{align}\\] 分别以计算的两个值作为横纵坐标，就得到了ROC曲线。 ROC曲线的评估方法： 如果一个模型的ROC曲线被另一个模型的ROC曲线完全“包住”，说明后者的性能优于前者。 如果两个ROC曲线发生交叉，则难以一般性的断言两者的优劣。如果一定要进行比较，较为合理的判断依据是比较ROC曲线下的面积（AUC）。一般情况下，如果 3.4.1 ROC曲线绘制 绘制ROC曲线的数据必须是数值型。 predRpart &lt;- as.numeric(as.character(predRpart)) predNb &lt;- as.numeric(predNb) 转换后绘制图形。 # 获取后续绘图使用的信息 rocPart &lt;- roc(testData$left, predRpart) ## Setting levels: control = 0, case = 1 ## Setting direction: controls &lt; cases # 计算两个关键值 # 假正例率 specificityRp &lt;- rocPart$specificities # 查全率，即真正利率 sensitivityRp &lt;- rocPart$sensitivities # 获取后续绘图使用的信息 rocNb &lt;- roc(testData$left, predNb) ## Setting levels: control = 0, case = 1 ## Setting direction: controls &lt; cases # 计算两个关键值 # 假正例率 specificityNb &lt;- rocNb$specificities # 查全率，即真正利率 sensitivityNb &lt;- rocNb$sensitivities 绘制ROC图形。 # 定义data = NULL声明未用任何数据 pRpart &lt;- ggplot(data = NULL, aes( x = 1 - specificityRp, y = sensitivityRp)) + geom_line(color = &quot;red&quot;) + geom_abline() + annotate(&quot;text&quot;, x = 0.4, y = 0.5, label = paste(&quot;AUC = &quot;, round(rocPart$auc, 3))) + theme_bw() + labs(x = &quot;1 - Specificity&quot;, y = &quot;Sensitivities&quot;) pNb &lt;- ggplot(data = NULL, aes( x = 1 - specificityNb, y = sensitivityNb)) + geom_line(color = &quot;red&quot;) + geom_abline() + annotate(&quot;text&quot;, x = 0.4, y = 0.5, label = paste(&quot;AUC = &quot;, round(rocNb$auc, 3))) + theme_bw() + labs(x = &quot;1 - Specificity&quot;, y = &quot; &quot;) pRpart|pNb 图3.3: 回归树模型和朴素贝叶斯模型ROC曲线 (ref:fig-ROC) 从AUC值来看，同样是回归树模型的拟合效果好于朴素贝叶斯模型。 3.5 模型应用 使用回归树模型预测分类的概率，绘制交互预测表 # type = &quot;prob&quot;表示结果显示为概率 # predEnd &lt;- predict(rpartmodel, testData[-7], # type = &quot;prob&quot;) # 合并预测结果及概率 # dataEnd &lt;- cbind(round(predEnd, 3), predRpart) # 重命名预测结果表列名。 # names(dataEnd) &lt;- c(&quot;pred.0&quot;, &quot;pred.1&quot;, &quot;pred&quot;) # head(dataEnd) # 生成交互式表格 # datatable(dataEnd) 分层抽样法也叫类型抽样法。它是从一个可以分成不同子总体（或称为层）的总体中，按规定的比例从不同层中随机抽取样品（个体）的方法。这种方法的优点是，样本的代表性比较好，抽样误差比较小。缺点是抽样手续较简单随机抽样还要繁杂些。定量调查中的分层抽样是一种卓越的概率抽样方式，在调查中经常被使用。↩︎ "],["creditcard.html", "4 信用卡欺诈识别 4.1 数据变量说明 4.2 数据预处理 4.3 描述性分析 4.4 自动参数调整调参-使用caret包 4.5 kNN建模 4.6 模型评估", " 4 信用卡欺诈识别 4.1 数据变量说明 变量说明 class变量：0表示非欺诈，1表示非欺诈。 4.2 数据预处理 card &lt;- read_csv(&quot;data/creditcard.csv&quot;) ## Rows: 284807 Columns: 31 ## -- Column specification -------------------------------------------------------- ## Delimiter: &quot;,&quot; ## dbl (31): Time, V1, V2, V3, V4, V5, V6, V7, V8, V9, V10, V11, V12, V13, V14,... ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. card &lt;- as.data.frame(card) str(card) # 查看数据基本结构和数据类型 ## &#39;data.frame&#39;: 284807 obs. of 31 variables: ## $ Time : num 0 0 1 1 2 2 4 7 7 9 ... ## $ V1 : num -1.36 1.192 -1.358 -0.966 -1.158 ... ## $ V2 : num -0.0728 0.2662 -1.3402 -0.1852 0.8777 ... ## $ V3 : num 2.536 0.166 1.773 1.793 1.549 ... ## $ V4 : num 1.378 0.448 0.38 -0.863 0.403 ... ## $ V5 : num -0.3383 0.06 -0.5032 -0.0103 -0.4072 ... ## $ V6 : num 0.4624 -0.0824 1.8005 1.2472 0.0959 ... ## $ V7 : num 0.2396 -0.0788 0.7915 0.2376 0.5929 ... ## $ V8 : num 0.0987 0.0851 0.2477 0.3774 -0.2705 ... ## $ V9 : num 0.364 -0.255 -1.515 -1.387 0.818 ... ## $ V10 : num 0.0908 -0.167 0.2076 -0.055 0.7531 ... ## $ V11 : num -0.552 1.613 0.625 -0.226 -0.823 ... ## $ V12 : num -0.6178 1.0652 0.0661 0.1782 0.5382 ... ## $ V13 : num -0.991 0.489 0.717 0.508 1.346 ... ## $ V14 : num -0.311 -0.144 -0.166 -0.288 -1.12 ... ## $ V15 : num 1.468 0.636 2.346 -0.631 0.175 ... ## $ V16 : num -0.47 0.464 -2.89 -1.06 -0.451 ... ## $ V17 : num 0.208 -0.115 1.11 -0.684 -0.237 ... ## $ V18 : num 0.0258 -0.1834 -0.1214 1.9658 -0.0382 ... ## $ V19 : num 0.404 -0.146 -2.262 -1.233 0.803 ... ## $ V20 : num 0.2514 -0.0691 0.525 -0.208 0.4085 ... ## $ V21 : num -0.01831 -0.22578 0.248 -0.1083 -0.00943 ... ## $ V22 : num 0.27784 -0.63867 0.77168 0.00527 0.79828 ... ## $ V23 : num -0.11 0.101 0.909 -0.19 -0.137 ... ## $ V24 : num 0.0669 -0.3398 -0.6893 -1.1756 0.1413 ... ## $ V25 : num 0.129 0.167 -0.328 0.647 -0.206 ... ## $ V26 : num -0.189 0.126 -0.139 -0.222 0.502 ... ## $ V27 : num 0.13356 -0.00898 -0.05535 0.06272 0.21942 ... ## $ V28 : num -0.0211 0.0147 -0.0598 0.0615 0.2152 ... ## $ Amount: num 149.62 2.69 378.66 123.5 69.99 ... ## $ Class : num 0 0 0 0 0 0 0 0 0 0 ... summary(card) # 查看数据的主要描述性统计量 ## Time V1 V2 V3 ## Min. : 0 Min. :-56.40751 Min. :-72.71573 Min. :-48.3256 ## 1st Qu.: 54202 1st Qu.: -0.92037 1st Qu.: -0.59855 1st Qu.: -0.8904 ## Median : 84692 Median : 0.01811 Median : 0.06549 Median : 0.1799 ## Mean : 94814 Mean : 0.00000 Mean : 0.00000 Mean : 0.0000 ## 3rd Qu.:139321 3rd Qu.: 1.31564 3rd Qu.: 0.80372 3rd Qu.: 1.0272 ## Max. :172792 Max. : 2.45493 Max. : 22.05773 Max. : 9.3826 ## V4 V5 V6 V7 ## Min. :-5.68317 Min. :-113.74331 Min. :-26.1605 Min. :-43.5572 ## 1st Qu.:-0.84864 1st Qu.: -0.69160 1st Qu.: -0.7683 1st Qu.: -0.5541 ## Median :-0.01985 Median : -0.05434 Median : -0.2742 Median : 0.0401 ## Mean : 0.00000 Mean : 0.00000 Mean : 0.0000 Mean : 0.0000 ## 3rd Qu.: 0.74334 3rd Qu.: 0.61193 3rd Qu.: 0.3986 3rd Qu.: 0.5704 ## Max. :16.87534 Max. : 34.80167 Max. : 73.3016 Max. :120.5895 ## V8 V9 V10 V11 ## Min. :-73.21672 Min. :-13.43407 Min. :-24.58826 Min. :-4.79747 ## 1st Qu.: -0.20863 1st Qu.: -0.64310 1st Qu.: -0.53543 1st Qu.:-0.76249 ## Median : 0.02236 Median : -0.05143 Median : -0.09292 Median :-0.03276 ## Mean : 0.00000 Mean : 0.00000 Mean : 0.00000 Mean : 0.00000 ## 3rd Qu.: 0.32735 3rd Qu.: 0.59714 3rd Qu.: 0.45392 3rd Qu.: 0.73959 ## Max. : 20.00721 Max. : 15.59500 Max. : 23.74514 Max. :12.01891 ## V12 V13 V14 V15 ## Min. :-18.6837 Min. :-5.79188 Min. :-19.2143 Min. :-4.49894 ## 1st Qu.: -0.4056 1st Qu.:-0.64854 1st Qu.: -0.4256 1st Qu.:-0.58288 ## Median : 0.1400 Median :-0.01357 Median : 0.0506 Median : 0.04807 ## Mean : 0.0000 Mean : 0.00000 Mean : 0.0000 Mean : 0.00000 ## 3rd Qu.: 0.6182 3rd Qu.: 0.66251 3rd Qu.: 0.4931 3rd Qu.: 0.64882 ## Max. : 7.8484 Max. : 7.12688 Max. : 10.5268 Max. : 8.87774 ## V16 V17 V18 ## Min. :-14.12985 Min. :-25.16280 Min. :-9.498746 ## 1st Qu.: -0.46804 1st Qu.: -0.48375 1st Qu.:-0.498850 ## Median : 0.06641 Median : -0.06568 Median :-0.003636 ## Mean : 0.00000 Mean : 0.00000 Mean : 0.000000 ## 3rd Qu.: 0.52330 3rd Qu.: 0.39968 3rd Qu.: 0.500807 ## Max. : 17.31511 Max. : 9.25353 Max. : 5.041069 ## V19 V20 V21 ## Min. :-7.213527 Min. :-54.49772 Min. :-34.83038 ## 1st Qu.:-0.456299 1st Qu.: -0.21172 1st Qu.: -0.22839 ## Median : 0.003735 Median : -0.06248 Median : -0.02945 ## Mean : 0.000000 Mean : 0.00000 Mean : 0.00000 ## 3rd Qu.: 0.458949 3rd Qu.: 0.13304 3rd Qu.: 0.18638 ## Max. : 5.591971 Max. : 39.42090 Max. : 27.20284 ## V22 V23 V24 ## Min. :-10.933144 Min. :-44.80774 Min. :-2.83663 ## 1st Qu.: -0.542350 1st Qu.: -0.16185 1st Qu.:-0.35459 ## Median : 0.006782 Median : -0.01119 Median : 0.04098 ## Mean : 0.000000 Mean : 0.00000 Mean : 0.00000 ## 3rd Qu.: 0.528554 3rd Qu.: 0.14764 3rd Qu.: 0.43953 ## Max. : 10.503090 Max. : 22.52841 Max. : 4.58455 ## V25 V26 V27 ## Min. :-10.29540 Min. :-2.60455 Min. :-22.565679 ## 1st Qu.: -0.31715 1st Qu.:-0.32698 1st Qu.: -0.070840 ## Median : 0.01659 Median :-0.05214 Median : 0.001342 ## Mean : 0.00000 Mean : 0.00000 Mean : 0.000000 ## 3rd Qu.: 0.35072 3rd Qu.: 0.24095 3rd Qu.: 0.091045 ## Max. : 7.51959 Max. : 3.51735 Max. : 31.612198 ## V28 Amount Class ## Min. :-15.43008 Min. : 0.00 Min. :0.000000 ## 1st Qu.: -0.05296 1st Qu.: 5.60 1st Qu.:0.000000 ## Median : 0.01124 Median : 22.00 Median :0.000000 ## Mean : 0.00000 Mean : 88.35 Mean :0.001728 ## 3rd Qu.: 0.07828 3rd Qu.: 77.17 3rd Qu.:0.000000 ## Max. : 33.84781 Max. :25691.16 Max. :1.000000 round(prop.table(table(card$Class)),4)# 查看数据类别比例 ## ## 0 1 ## 0.9983 0.0017 4.2.1 分层抽样 处理类别不平衡的数据需要了解的几个概念点： 类别不平衡：指分类任务重不同类别的训练样本树木差别很大的情况。 欠抽样：指某类（样本数占比很大）的样本中抽取出与另一类样本（样本数占比很小）个数一样的样本。即从大类别中抽取与小类别数目一样的样本。 过抽样：指针对样本数占比很小的类别，重新塑造一些数据，使其与另一类数据接近。 对数据进行一些基本转化。 # 把Time列转换为小时 card &lt;- card %&gt;% mutate(Time_Hour = round(card[, 1]/3600, 0)) # 把Class列转化为因子型 card$Class &lt;- factor(card$Class) card_1 &lt;- card[card$Class == &quot;1&quot;, ] # 欺诈样本 card_0 &lt;- card[card$Class == &quot;0&quot;, ] # 非欺诈样本 随机抽取与诈骗样本个数相同的非欺诈样本数据，并与元欺诈样本合并为新的数据。此处使用的欠抽样的方法。 set.seed(1234) index &lt;- sample(x = 1:nrow(card_0), size = nrow(card_1)) card_0_new &lt;- card_0[index, ] card_end &lt;- rbind(card_0_new, card_1) # 剔除Time列，用Time_Hour列代替。everything()选择所有的变量 card_end &lt;- card_end[-1] %&gt;% select(Time_Hour, everything()) 按照类别进行分层抽样，建立训练集和测试集。 set.seed(1234) # 按照新数据的目标变量进行8：2 index2 &lt;- createDataPartition(card_end$Class, p = 0.8, list = F) train_data &lt;- card_end[index2, ] # 创建训练集 test_data &lt;- card_end[-index2, ] # 创建测试集 # 验证抽样结果，统计三个数据集中正反样本比例是否一致 table(card_end$Class) ## ## 0 1 ## 492 492 table(train_data$Clas) ## ## 0 1 ## 394 394 table(test_data$Class) ## ## 0 1 ## 98 98 4.2.2 标准化 standard &lt;- preProcess(card_end, method = &quot;range&quot;) card_s &lt;- predict(standard, card_end) train_data2 &lt;- card_s[index2, ] test_data2 &lt;- card_s[-index2, ] 4.3 描述性分析 4.3.1 不同时间诈骗次数-条形图 ggplot(card_1, aes(x = factor(Time_Hour), fill = factor(Time_Hour)))+ geom_bar(stat = &quot;count&quot;) + theme_classic() + labs(x = &quot;Time_Hour&quot;, y = &quot;Count&quot;) + theme(legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 90, vjust = 0.5)) 图4.1: 不同时间诈骗次数 由图4.1可知： 第一天（024h）的诈骗总次数大于第二天（2548h）。 诈骗发生次数最多的三个时间段分别是： 第二天凌晨2点左右。 第一天上午11点左右。 第一天凌晨2点左右。 4.3.2 不同时间诈骗金额-箱线图 ggplot(card_1, aes(x = factor(Time_Hour), y = Amount, fill = factor(Time_Hour))) + geom_boxplot() + geom_hline(aes(yintercept =250, color = &quot;red&quot;)) + annotate(&quot;text&quot;, x = 6, y = 500, label = &quot;Amount = 250&quot;, color = &quot;red&quot;) + geom_curve(x = 3, y = 450, xend = 5, yend = 250, angle = 25, color = &quot;red&quot;, arrow = arrow(length = unit(0.25, &quot;cm&quot;))) + theme_classic() + labs(x = &quot;Time_Hour&quot;, y = &quot;Amount&quot;) + theme(legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 90, vjust = 0.5)) 图4.2: 不同时间诈骗金额 由图4.2可知： 诈骗金额最多的一次发生在第二天下午1点作用（34h），诈骗金额达到2000欧元左右。 诈骗金额普遍在250欧元之内。 4.3.3 不同时间平均诈骗金额-条形图 # 提取所需数据 card_1_mean &lt;- card_1 %&gt;% group_by(Time_Hour) %&gt;% summarise(MeanAmount = mean(Amount)) ggplot(card_1_mean, aes(x = factor(Time_Hour), y = MeanAmount, fill = factor(Time_Hour))) + geom_bar(stat = &quot;identity&quot;) + geom_hline(aes(yintercept = 200, color = &quot;red&quot;)) + annotate(&quot;text&quot;, x = 26, y = 240, label = &quot;Mean_Amount = 200&quot;, color = &quot;red&quot;) + geom_curve(x = 23, y = 220, xend = 24, yend = 200, curvature = 0.3, arrow = arrow(length = unit(0.2, &quot;cm&quot;)), color = &quot;red&quot;) + theme_classic() + theme(legend.position = &quot;none&quot;, axis.text.x = element_text(angle = 90, vjust = 0.5)) + labs(x = &quot;Time_Hour&quot;, y = &quot;Mean_Amount&quot;) 图4.3: 不同时间平均诈骗金额-条形图 如图4.3所示： 平均诈骗金额最多的时间段为第二天下午1点，此时间点包含诈骗金额最多的观测。 总体而言，平均诈骗金额普遍在200欧元以内。 4.4 自动参数调整调参-使用caret包 参数调整是提升模型性能的一个重要过程，而大多数机器学习算法都可以至少调整一个参数。复杂的模型通常可以通过调节多个参数值来调整模型从而达到更好的拟合效果。 e.g.，寻找最合适的k值来调整k近邻模型、调节隐藏层层数和隐藏层的节点数来优化神经网络模型；又如支持向量机模型中的调节核函数以及“软边界”惩罚大小等优化。 值得注意的是，如果对所有可能的调参选项均进行尝试，其复杂度非常大，耗时且不科学，需要一种更系统、科学的方式对模型的参数进行调节。 下表列举了使用caret包进行自动参数调整的模型及其参数： 模型 方法名 参数 k近邻 knn k 朴素贝叶斯 nb fL、usekernel 决策树 C5.0 model、trials、winnow OneR规则学习器 OneR 无 线性回归 lm 无 回归树 rpart cp 模型树 M5 pruned、smoothed、rules 支持向量机（径向基核） svmRadial C, sigma 随机森林 rf mtry 更多可调节参数的详细信息 本案例我们使用knn和随机森林两个模型。 我们用iris数据对自动调参的步骤进行演示。 创建简单的调整的模型 set.seed(1234) m_C50 &lt;- train(Species~., data = iris, method = &quot;C5.0&quot;) ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 8 for this object. Predictions generated using 8 ## trials ## Warning: &#39;trials&#39; should be &lt;= 4 for this object. Predictions generated using 4 ## trials ## Warning: &#39;trials&#39; should be &lt;= 8 for this object. Predictions generated using 8 ## trials ## Warning: &#39;trials&#39; should be &lt;= 4 for this object. Predictions generated using 4 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 4 for this object. Predictions generated using 4 ## trials ## Warning: &#39;trials&#39; should be &lt;= 4 for this object. Predictions generated using 4 ## trials ## Warning: &#39;trials&#39; should be &lt;= 8 for this object. Predictions generated using 8 ## trials ## Warning: &#39;trials&#39; should be &lt;= 6 for this object. Predictions generated using 6 ## trials ## Warning: &#39;trials&#39; should be &lt;= 8 for this object. Predictions generated using 8 ## trials ## Warning: &#39;trials&#39; should be &lt;= 6 for this object. Predictions generated using 6 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 6 for this object. Predictions generated using 6 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 8 for this object. Predictions generated using 8 ## trials ## Warning: &#39;trials&#39; should be &lt;= 9 for this object. Predictions generated using 9 ## trials ## Warning: &#39;trials&#39; should be &lt;= 9 for this object. Predictions generated using 9 ## trials ## Warning: &#39;trials&#39; should be &lt;= 9 for this object. Predictions generated using 9 ## trials ## Warning: &#39;trials&#39; should be &lt;= 9 for this object. Predictions generated using 9 ## trials ## Warning: &#39;trials&#39; should be &lt;= 4 for this object. Predictions generated using 4 ## trials ## Warning: &#39;trials&#39; should be &lt;= 4 for this object. Predictions generated using 4 ## trials ## Warning: &#39;trials&#39; should be &lt;= 4 for this object. Predictions generated using 4 ## trials ## Warning: &#39;trials&#39; should be &lt;= 3 for this object. Predictions generated using 3 ## trials ## Warning: &#39;trials&#39; should be &lt;= 4 for this object. Predictions generated using 4 ## trials ## Warning: &#39;trials&#39; should be &lt;= 3 for this object. Predictions generated using 3 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 8 for this object. Predictions generated using 8 ## trials ## Warning: &#39;trials&#39; should be &lt;= 1 for this object. Predictions generated using 1 ## trials ## Warning: &#39;trials&#39; should be &lt;= 8 for this object. Predictions generated using 8 ## trials m_C50 ## C5.0 ## ## 150 samples ## 4 predictor ## 3 classes: &#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39; ## ## No pre-processing ## Resampling: Bootstrapped (25 reps) ## Summary of sample sizes: 150, 150, 150, 150, 150, 150, ... ## Resampling results across tuning parameters: ## ## model winnow trials Accuracy Kappa ## rules FALSE 1 0.9353579 0.9019696 ## rules FALSE 10 0.9370844 0.9045424 ## rules FALSE 20 0.9325835 0.8976068 ## rules TRUE 1 0.9382311 0.9062975 ## rules TRUE 10 0.9407392 0.9099910 ## rules TRUE 20 0.9385430 0.9066136 ## tree FALSE 1 0.9347127 0.9009924 ## tree FALSE 10 0.9369888 0.9044013 ## tree FALSE 20 0.9332286 0.8985820 ## tree TRUE 1 0.9375860 0.9053246 ## tree TRUE 10 0.9399845 0.9088007 ## tree TRUE 20 0.9392443 0.9076915 ## ## Accuracy was used to select the optimal model using the largest value. ## The final values used for the model were trials = 10, model = rules and ## winnow = TRUE. 由上面的结果可以看出，基于model、trials和winnow三个参数，建立并测试了12个决策树（C5.0）模型，每个模型均给出了精度及Kappa统计量，最下方同时展示了最佳候选模型所对应的参数值。其中Kappa统计量用来衡量模型的稳定性： 很差的一致性： &lt;0.2 尚可的一致性： 0.2~0.4 中等的一致性： 0.4~0.6 不错的一致性： 0.6~0.8 很好的一致性： 0.8~1 定制调参 使用trainCotrol()函数创建一些列配置选项，这些选项考虑了包括重抽样策略以及用于选择最佳模型的度量这些模型评价标准的管理。主要专注于两个重要的参数：method和selectionFuncio。 method为冲抽样的方法。 selectionFunction参数可以设定一个函数，用于在各个候选者中选取特定的模型，共3个函数： best函数：默认选项，简单的选择具有最好的某特定度量值的候选者。 oneSE函数：选择最好性能标准差之内的最简单的候选者。 Tolerance函数：选择某个用户制定比例之内最简单的候选者。 set.seed(1234) model_rf &lt;- train(Class~., data = train_data, method = &quot;rf&quot;, trControl = trainControl(method = &quot;cv&quot;, number = 5, selectionFunction = &quot;oneSE&quot;)) model_rf ## Random Forest ## ## 788 samples ## 30 predictor ## 2 classes: &#39;0&#39;, &#39;1&#39; ## ## No pre-processing ## Resampling: Cross-Validated (5 fold) ## Summary of sample sizes: 631, 631, 630, 630, 630 ## Resampling results across tuning parameters: ## ## mtry Accuracy Kappa ## 2 0.9276465 0.8552977 ## 16 0.9314521 0.8628921 ## 30 0.9276627 0.8553120 ## ## Accuracy was used to select the optimal model using the one SE rule. ## The final value used for the model was mtry = 2. # 进行预测 pred_rf &lt;- predict(model_rf, test_data[-31]) # 建立混淆矩阵 confusionMatrix(data = pred_rf, reference = test_data$Class, positive = &quot;1&quot;) ## Confusion Matrix and Statistics ## ## Reference ## Prediction 0 1 ## 0 98 7 ## 1 0 91 ## ## Accuracy : 0.9643 ## 95% CI : (0.9278, 0.9855) ## No Information Rate : 0.5 ## P-Value [Acc &gt; NIR] : &lt; 2e-16 ## ## Kappa : 0.9286 ## ## Mcnemar&#39;s Test P-Value : 0.02334 ## ## Sensitivity : 0.9286 ## Specificity : 1.0000 ## Pos Pred Value : 1.0000 ## Neg Pred Value : 0.9333 ## Prevalence : 0.5000 ## Detection Rate : 0.4643 ## Detection Prevalence : 0.4643 ## Balanced Accuracy : 0.9643 ## ## &#39;Positive&#39; Class : 1 ## plot(varImp(model_rf)) # 查看变量的重要性 4.5 kNN建模 4.5.1 原理 knn，即邻近分类器，就是把未标记的案例归类为与他们最相似的带有标记的案例所在的类。 算法流程： 依次计算测试样本与哥哥训练样本间的距离（常用欧式距离）； 将这些距离按照升序排列； 选取距离最小的k（3~10）个训练样本点； 确定这k个点中不同类别的占比； 返回这k个点中占比最大的类别作为测试样本的预测分类。 4.5.2 模型建立 # 创建空向量 results &lt;- c() for (i in 3:10){ set.seed(1234) pred_knn &lt;- knn(train_data2[-31], test_data2[-31], train_data2$Class, i) Table &lt;- table(pred_knn, test_data2$Class) # 得到混淆矩阵 accuracy &lt;- sum(diag(Table))/sum(Table) # diag()提取对角线的值 results &lt;- c(results, accuracy) } ggplot(as.data.frame(results), aes(x = 3:10, y = results)) + geom_point()+ geom_line() + theme_bw() + labs(xlab = &quot; &quot;) set.seed(1234) pred_knn &lt;- knn(train = train_data2[-31], test = test_data2[-31], cl = train_data2$Class, k = 4) confusionMatrix(pred_knn,test_data2$Class, positive = &quot;1&quot;) ## Confusion Matrix and Statistics ## ## Reference ## Prediction 0 1 ## 0 97 7 ## 1 1 91 ## ## Accuracy : 0.9592 ## 95% CI : (0.9212, 0.9822) ## No Information Rate : 0.5 ## P-Value [Acc &gt; NIR] : &lt;2e-16 ## ## Kappa : 0.9184 ## ## Mcnemar&#39;s Test P-Value : 0.0771 ## ## Sensitivity : 0.9286 ## Specificity : 0.9898 ## Pos Pred Value : 0.9891 ## Neg Pred Value : 0.9327 ## Prevalence : 0.5000 ## Detection Rate : 0.4643 ## Detection Prevalence : 0.4694 ## Balanced Accuracy : 0.9592 ## ## &#39;Positive&#39; Class : 1 ## 4.6 模型评估 # 建立一个数据框，将两个模型预测的结果和真实值放进去。并展示不同预测值 pred_results &lt;- data.frame(knn = pred_knn, rf = pred_rf, class = test_data$Class) index3 &lt;- which(pred_results$knn != pred_rf) pred_results[index3, ] ## knn rf class ## 25 1 0 0 ## 159 1 0 1 ## 160 0 1 1 ## 168 1 0 1 ## 182 0 1 1 "],["scoreClass.html", "5 Student performance level classification 5.1 数据变量说明 5.2 描述性分析 5.3 模型建立", " 5 Student performance level classification 5.1 数据变量说明 变量说明。 变量中最重要的的为Class学生等级变量，是我们建模的目标变量。 edudata &lt;- read_csv(&quot;data/xAPI-Edu-Data.csv&quot;) ## Rows: 480 Columns: 17 ## -- Column specification -------------------------------------------------------- ## Delimiter: &quot;,&quot; ## chr (13): gender, NationalITy, PlaceofBirth, StageID, GradeID, SectionID, To... ## dbl (4): raisedhands, VisITedResources, AnnouncementsView, Discussion ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. edudata$Class &lt;- factor(edudata$Class, levels = c(&quot;H&quot;, &quot;M&quot;, &quot;L&quot;)) str(edudata) ## spec_tbl_df [480 x 17] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ gender : chr [1:480] &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;M&quot; ... ## $ NationalITy : chr [1:480] &quot;KW&quot; &quot;KW&quot; &quot;KW&quot; &quot;KW&quot; ... ## $ PlaceofBirth : chr [1:480] &quot;KuwaIT&quot; &quot;KuwaIT&quot; &quot;KuwaIT&quot; &quot;KuwaIT&quot; ... ## $ StageID : chr [1:480] &quot;lowerlevel&quot; &quot;lowerlevel&quot; &quot;lowerlevel&quot; &quot;lowerlevel&quot; ... ## $ GradeID : chr [1:480] &quot;G-04&quot; &quot;G-04&quot; &quot;G-04&quot; &quot;G-04&quot; ... ## $ SectionID : chr [1:480] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ... ## $ Topic : chr [1:480] &quot;IT&quot; &quot;IT&quot; &quot;IT&quot; &quot;IT&quot; ... ## $ Semester : chr [1:480] &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;F&quot; ... ## $ Relation : chr [1:480] &quot;Father&quot; &quot;Father&quot; &quot;Father&quot; &quot;Father&quot; ... ## $ raisedhands : num [1:480] 15 20 10 30 40 42 35 50 12 70 ... ## $ VisITedResources : num [1:480] 16 20 7 25 50 30 12 10 21 80 ... ## $ AnnouncementsView : num [1:480] 2 3 0 5 12 13 0 15 16 25 ... ## $ Discussion : num [1:480] 20 25 30 35 50 70 17 22 50 70 ... ## $ ParentAnsweringSurvey : chr [1:480] &quot;Yes&quot; &quot;Yes&quot; &quot;No&quot; &quot;No&quot; ... ## $ ParentschoolSatisfaction: chr [1:480] &quot;Good&quot; &quot;Good&quot; &quot;Bad&quot; &quot;Bad&quot; ... ## $ StudentAbsenceDays : chr [1:480] &quot;Under-7&quot; &quot;Under-7&quot; &quot;Above-7&quot; &quot;Above-7&quot; ... ## $ Class : Factor w/ 3 levels &quot;H&quot;,&quot;M&quot;,&quot;L&quot;: 2 2 3 3 2 2 3 2 2 2 ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. gender = col_character(), ## .. NationalITy = col_character(), ## .. PlaceofBirth = col_character(), ## .. StageID = col_character(), ## .. GradeID = col_character(), ## .. SectionID = col_character(), ## .. Topic = col_character(), ## .. Semester = col_character(), ## .. Relation = col_character(), ## .. raisedhands = col_double(), ## .. VisITedResources = col_double(), ## .. AnnouncementsView = col_double(), ## .. Discussion = col_double(), ## .. ParentAnsweringSurvey = col_character(), ## .. ParentschoolSatisfaction = col_character(), ## .. StudentAbsenceDays = col_character(), ## .. Class = col_character() ## .. ) ## - attr(*, &quot;problems&quot;)=&lt;externalptr&gt; 5.2 描述性分析 5.2.1 封装绘图函数 fun_bar &lt;- function(data, xlab, fillc, pos, xname, yname, legend){ data %&gt;% group_by({{xlab}}) %&gt;% # dplyr中的自定函数参数需要使用{{}}括起来 mutate(count = n()) %&gt;% ggplot(aes(reorder({{xlab}}, count), count, fill = {{fillc}})) + geom_col(position = pos) + #pos = &quot;stack&quot; or &quot;fill&quot; labs(x = xname, y = yname) + coord_flip() + theme_bw() + guides(fill = guide_legend(title = legend)) } 5.2.2 不同教育程度的学生选择课程主题 p1 &lt;- fun_bar(data = edudata, xlab = Topic, fillc = StageID, pos = &quot;stack&quot;, xname = &quot;Topic&quot;, yname = &quot;Student_Count&quot;, legend = &quot;教育程度&quot;) p2 &lt;- fun_bar(data = edudata, xlab = Topic, fillc = StageID, pos = &quot;fill&quot;, xname = &quot;Topic&quot;, yname = &quot;Per_Student_Count&quot;, legend = &quot;教育程度&quot;) p1/p2 图5.1: 不同教育程度的学生选择课程主题 由图5.1可以看出： 课程主题最多的为IT、French和Arabic，其中选择IT的课程主题的学员远高于其他课。 无论哪种教育程度，IT、Science、Math和English四种课程都是必修的（三种颜色都有）。 5.2.3 不同课程主题监护人情况 这部分主要针对家长的情况进行分析，了解父母对学员学习的不同情况。对应在数据集中的变量为Relation。 p3 &lt;- fun_bar(data = edudata, xlab = Topic, fillc = Relation, pos = &quot;stack&quot;, xname = &quot;Topic&quot;, yname = &quot;Student_count&quot;, legend = &quot;监护人情况&quot;) p4 &lt;- fun_bar(data = edudata, xlab = Topic, fillc = Relation, pos = &quot;fill&quot;, xname = &quot;Topic&quot;, yname = &quot;Student_count&quot;, legend = &quot;监护人情况&quot;) p3/p4 图5.2: 不同课程主题监护人情况 由图5.2可以看出： 总体而言，监护人为父亲的较多。其中，IT和Math课程中，负责人为父亲的超过75%。 French课程，监护人大多数为母亲，占70%左右。 5.2.4 不同课程学生学习成绩 p5 &lt;- fun_bar(data = edudata, xlab = Topic, fillc = Class, pos = &quot;stack&quot;, xname = &quot;Topic&quot;, yname = &quot;Student_count&quot;, legend = &quot;学生成绩&quot;) p6 &lt;- fun_bar(data = edudata, xlab = Topic, fillc = Class, pos = &quot;fill&quot;, xname = &quot;Topic&quot;, yname = &quot;Student_count&quot;, legend = &quot;学生成绩&quot;) p5/p6 图5.3: 不同课程学生学习成绩 由图5.3: 所有课程中，只有Biology课程中，属于高水平的学生数超过了50%。 在Geology课程中，没有低水平的学生。 5.2.5 不同教室学生成绩水平 p7 &lt;- fun_bar(data = edudata, xlab = SectionID, fillc = Class, pos = &quot;stack&quot;, xname = &quot;Section_ID&quot;, yname = &quot;Student_count&quot;, legend = &quot;学生成绩&quot;) p8 &lt;- fun_bar(data = edudata, xlab = SectionID, fillc = Class, pos = &quot;fill&quot;, xname = &quot;Section_ID&quot;, yname = &quot;Student_count&quot;, legend = &quot;学生成绩&quot;) p7/p8 图5.4: 不同教室学生成绩水平 由图5.4可以看出： 在A班的学生最多，C班的学生最少。 C班的低水平成绩的学生相对较多，其它两个班级的成绩水平基本一致。 5.2.6 不同学期、不同成绩水平与监护人的关系 # 封装函数，去掉坐标轴翻转 fun_bar2 &lt;- function(data, xlab, fillc, pos, xname, yname, legend){ data %&gt;% group_by({{xlab}}) %&gt;% # dplyr中的自定函数参数需要使用{{}}括起来 mutate(count = n()) %&gt;% ggplot(aes(reorder({{xlab}}, count), count, fill = {{fillc}})) + geom_col(position = pos) + #pos = &quot;stack&quot; or &quot;fill&quot; labs(x = xname, y = yname) + theme_bw() + guides(fill = guide_legend(title = legend)) } p9 &lt;- fun_bar2(edudata, Semester, Relation, pos = &quot;stack&quot;, xname = &quot;Semester&quot;, yname = &quot;Student_count&quot;, legend = &quot;监护人情况&quot;) p10 &lt;- fun_bar2(edudata, Semester, Relation, pos = &quot;fill&quot;, xname = &quot;Semester&quot;, yname = &quot;per_Student_count&quot;, legend = &quot;监护人情况&quot;) p11 &lt;- fun_bar2(edudata, Class, Relation, pos = &quot;stack&quot;, xname = &quot;Class&quot;, yname = &quot;Student_count&quot;, legend = &quot;监护人情况&quot;) p12 &lt;- fun_bar2(edudata, Class, Relation, pos = &quot;fill&quot;, xname = &quot;Class&quot;, yname = &quot;per_Student_count&quot;, legend = &quot;监护人情况&quot;) (p9|p10) / (p11|p12) 图5.5: 不同学期、不同成绩水平与监护人的关系 由图5.5可知： 第一学期父亲作为监护人的学生数比第二学期多。 总体看，成绩水平较高的学生中，监护人为母亲的比较多；其它水平均是父亲较多。 5.2.7 家长是否回答调查问卷、成绩水平与家长对学校是否满意的关系 p13 &lt;- fun_bar2(edudata, ParentAnsweringSurvey, ParentschoolSatisfaction, pos = &quot;stack&quot;, xname = &quot;ParentAnsweringSurvey&quot;, yname = &quot;Student_count&quot;, legend = &quot;是否满意&quot;) p14 &lt;- fun_bar2(edudata, ParentAnsweringSurvey, ParentschoolSatisfaction, pos = &quot;fill&quot;, xname = &quot;ParentAnsweringSurvey&quot;, yname = &quot;Per_Student_count&quot;, legend = &quot;是否满意&quot;) p15 &lt;- fun_bar2(edudata, Class, ParentschoolSatisfaction, pos = &quot;stack&quot;, xname = &quot;Class&quot;, yname = &quot;Student_count&quot;, legend = &quot;是否满意&quot;) p16 &lt;- fun_bar2(edudata, Class, ParentschoolSatisfaction, pos = &quot;fill&quot;, xname = &quot;Class&quot;, yname = &quot;Per_Student_count&quot;, legend = &quot;是否满意&quot;) (p13|p14)/(p15|p16) 图5.6: 家长是否回答调查问卷、成绩水平与家长对学校是否满意的关系 由图5.6可以看出： 有超过一半的家长回答了问卷，其中，回答问卷的家长大部分对学校满意，而未回答问卷的则大部分对学校不满。 成绩越高，家长对学校越满意。 5.2.8 性别、逃课次数与学生成绩水平的关系 p17 &lt;- fun_bar2(edudata, gender, Class, pos = &quot;stack&quot;, xname = &quot;Gender&quot;, yname = &quot;Student_count&quot;, legend = &quot;成绩水平&quot;) p18 &lt;- fun_bar2(edudata, gender, Class, pos = &quot;fill&quot;, xname = &quot;Gender&quot;, yname = &quot;Per_Student_count&quot;, legend = &quot;成绩水平&quot;) p19 &lt;- fun_bar2(edudata, StudentAbsenceDays, Class, pos = &quot;stack&quot;, xname = &quot;Class&quot;, yname = &quot;Student_count&quot;, legend = &quot;成绩水平&quot;) p20 &lt;- fun_bar2(edudata, StudentAbsenceDays, Class, pos = &quot;fill&quot;, xname = &quot;Class&quot;, yname = &quot;Per_Student_count&quot;, legend = &quot;成绩水平&quot;) (p17|p18)/(p19|p20) 图5.7: 性别、逃课次数与学生成绩水平的关系 由图5.7可知： 女生比男生数量少很多，但高水平成绩的人数明显比男生多；中水平成绩男女比例基本持平。 逃课超过7天的的学生基本无法取得好的成绩。 5.2.9 举手次数和参加讨论次数与成绩水平关系 fun_bar3 &lt;- function(data, xlab, ylab, fillc, xname, yname){ data %&gt;% group_by({{xlab}}) %&gt;% summarise(Mcount = mean({{ylab}})) %&gt;% ggplot(aes({{xlab}}, Mcount, fill = {{fillc}})) + geom_col() + labs(x = xname, y = yname) + theme_bw() + theme(legend.position = &quot;none&quot;) } # edudata$Class &lt;- factor(edudata$Class, c(&quot;H&quot;, &quot;M&quot;, &quot;L&quot;), ordered = TRUE) p21 &lt;- fun_bar3(data = edudata, xlab = Class, ylab = raisedhands, fillc = Class, &quot;成绩水平&quot;, &quot;平均举手次数&quot; ) p22 &lt;- fun_bar3(data = edudata, xlab = Class, ylab = Discussion, fillc = Class, &quot;成绩水平&quot;, &quot;平均参与讨论次数&quot; ) p21|p22 图5.8: 举手次数和参加讨论次数与成绩水平关系 由图5.8可知： 举手次数和参与讨论次数越多，成绩水平越高。 5.3 模型建立 5.3.1 回归树模型建立 set.seed(1234) # 按照数据目标8:2进行分层抽样，返回矩阵形式的抽样索引 index &lt;- createDataPartition(edudata$Class, p = 0.8, list = F) train &lt;- edudata[index, ] test &lt;- edudata[-index, ] # 建立回归树模型 rpart_model &lt;- rpart(Class ~., data = train) # type = &quot;class&quot;指定预测结果是具体的某个类别 pred_rp &lt;- predict(rpart_model, test[-17], type = &quot;class&quot;) confusionMatrix(pred_rp, test$Class) ## Confusion Matrix and Statistics ## ## Reference ## Prediction H M L ## H 18 3 0 ## M 9 29 3 ## L 1 10 22 ## ## Overall Statistics ## ## Accuracy : 0.7263 ## 95% CI : (0.6252, 0.8128) ## No Information Rate : 0.4421 ## P-Value [Acc &gt; NIR] : 1.882e-08 ## ## Kappa : 0.5806 ## ## Mcnemar&#39;s Test P-Value : 0.05103 ## ## Statistics by Class: ## ## Class: H Class: M Class: L ## Sensitivity 0.6429 0.6905 0.8800 ## Specificity 0.9552 0.7736 0.8429 ## Pos Pred Value 0.8571 0.7073 0.6667 ## Neg Pred Value 0.8649 0.7593 0.9516 ## Prevalence 0.2947 0.4421 0.2632 ## Detection Rate 0.1895 0.3053 0.2316 ## Detection Prevalence 0.2211 0.4316 0.3474 ## Balanced Accuracy 0.7990 0.7320 0.8614 prp(rpart_model) 5.3.2 随机数模型 set.seed(1234) # importance = T:稍后对变量进行重要性的可视化 rf_model &lt;- randomForest(Class~., data = train, importance = T) pred_rf &lt;- predict(rf_model, test[-17], type = &quot;class&quot;) confusionMatrix(pred_rf, test$Class) # 混淆矩阵判断模型准确率 ## Confusion Matrix and Statistics ## ## Reference ## Prediction H M L ## H 20 5 0 ## M 8 36 4 ## L 0 1 21 ## ## Overall Statistics ## ## Accuracy : 0.8105 ## 95% CI : (0.7172, 0.8837) ## No Information Rate : 0.4421 ## P-Value [Acc &gt; NIR] : 1.886e-13 ## ## Kappa : 0.7031 ## ## Mcnemar&#39;s Test P-Value : NA ## ## Statistics by Class: ## ## Class: H Class: M Class: L ## Sensitivity 0.7143 0.8571 0.8400 ## Specificity 0.9254 0.7736 0.9857 ## Pos Pred Value 0.8000 0.7500 0.9545 ## Neg Pred Value 0.8857 0.8723 0.9452 ## Prevalence 0.2947 0.4421 0.2632 ## Detection Rate 0.2105 0.3789 0.2211 ## Detection Prevalence 0.2632 0.5053 0.2316 ## Balanced Accuracy 0.8198 0.8154 0.9129 varImpPlot(rf_model) # 可视化变量重要性函数 阅读上图： 圆点越靠近右侧越重要。 我们重点观察排名前五的变量。通过左右两图的对比发现，两图中前四个变量相同（交叉），可以判定这四个变量是数据中最重要的变量。 5.3.3 SVM建模-支持向量机(需要再研究) set.seed(1234) library(kernlab) # Kernel-Based Machine Learning Lab svm_model &lt;- ksvm(Class~., data = train, kernel = &quot;rbfdot&quot;) # type = &quot;response&quot;:指定预测结果是具体的某个列别 pred_svm &lt;- predict(svm_model, train[-17], type = &quot;response&quot;) confusionMatrix(pred_svm, train$Class) ## Confusion Matrix and Statistics ## ## Reference ## Prediction H M L ## H 88 8 0 ## M 26 152 10 ## L 0 9 92 ## ## Overall Statistics ## ## Accuracy : 0.8623 ## 95% CI : (0.8238, 0.8952) ## No Information Rate : 0.439 ## P-Value [Acc &gt; NIR] : &lt; 2.2e-16 ## ## Kappa : 0.7857 ## ## Mcnemar&#39;s Test P-Value : NA ## ## Statistics by Class: ## ## Class: H Class: M Class: L ## Sensitivity 0.7719 0.8994 0.9020 ## Specificity 0.9705 0.8333 0.9682 ## Pos Pred Value 0.9167 0.8085 0.9109 ## Neg Pred Value 0.9100 0.9137 0.9648 ## Prevalence 0.2961 0.4390 0.2649 ## Detection Rate 0.2286 0.3948 0.2390 ## Detection Prevalence 0.2494 0.4883 0.2623 ## Balanced Accuracy 0.8712 0.8664 0.9351 5.3.4 模型融合 将各个模型的结果做一个融合（合并至一个数据框）。 result &lt;- data.frame(rpart = pred_rp, randomForest = pred_rf, # svm = pred_svm, actual_class = test$Class, final_pred = rep(&quot;-&quot;, nrow(test))) head(result) ## rpart randomForest actual_class final_pred ## 1 M M M - ## 2 L L L - ## 3 L L L - ## 4 M M M - ## 5 L L L - ## 6 M M M - # 封装求众数函数 fun_pred &lt;- function(x){ names(which.max(table(x))) } result$final_pred &lt;- factor(apply(result[1:2], 1, fun_pred)) confusionMatrix(result$actual_class, result$final_pred) ## Warning in confusionMatrix.default(result$actual_class, result$final_pred): ## Levels are not in the same order for reference and data. Refactoring data to ## match. ## Confusion Matrix and Statistics ## ## Reference ## Prediction H L M ## H 21 1 6 ## L 0 23 2 ## M 8 10 24 ## ## Overall Statistics ## ## Accuracy : 0.7158 ## 95% CI : (0.614, 0.8036) ## No Information Rate : 0.3579 ## P-Value [Acc &gt; NIR] : 1.408e-12 ## ## Kappa : 0.5738 ## ## Mcnemar&#39;s Test P-Value : 0.08508 ## ## Statistics by Class: ## ## Class: H Class: L Class: M ## Sensitivity 0.7241 0.6765 0.7500 ## Specificity 0.8939 0.9672 0.7143 ## Pos Pred Value 0.7500 0.9200 0.5714 ## Neg Pred Value 0.8806 0.8429 0.8491 ## Prevalence 0.3053 0.3579 0.3368 ## Detection Rate 0.2211 0.2421 0.2526 ## Detection Prevalence 0.2947 0.2632 0.4421 ## Balanced Accuracy 0.8090 0.8218 0.7321 "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
